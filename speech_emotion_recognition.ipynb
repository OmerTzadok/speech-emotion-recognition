{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9d62f9-500f-42a4-be40-481e2b1bfcd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16245d3-8a8a-4d97-b1e4-7845ac5a789f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae651683-fc37-4077-8fed-f076fa8cdcda",
   "metadata": {},
   "source": [
    "# 2. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7782d9d5-b4d1-4460-a716-1ddda02e5b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAVDESS = \"./data/ravdess-emotional-speech-audio/\"\n",
    "CREMA = \"./data/cremad/\"\n",
    "TESS = \"./data/toronto-emotional-speech-set-tess/\"\n",
    "SAVEE = \"./data/surrey-audiovisual-expressed-emotion-savee/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c58262",
   "metadata": {},
   "source": [
    "## 2.1. Ravdess dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e3ddabe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotions</th>\n",
       "      <th>genders</th>\n",
       "      <th>audio_intensity</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>male</td>\n",
       "      <td>normal</td>\n",
       "      <td>./data/ravdess-emotional-speech-audio/Actor_01...</td>\n",
       "      <td>ravdess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>male</td>\n",
       "      <td>normal</td>\n",
       "      <td>./data/ravdess-emotional-speech-audio/Actor_01...</td>\n",
       "      <td>ravdess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>male</td>\n",
       "      <td>normal</td>\n",
       "      <td>./data/ravdess-emotional-speech-audio/Actor_01...</td>\n",
       "      <td>ravdess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>male</td>\n",
       "      <td>normal</td>\n",
       "      <td>./data/ravdess-emotional-speech-audio/Actor_01...</td>\n",
       "      <td>ravdess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calm</td>\n",
       "      <td>male</td>\n",
       "      <td>normal</td>\n",
       "      <td>./data/ravdess-emotional-speech-audio/Actor_01...</td>\n",
       "      <td>ravdess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>surprised</td>\n",
       "      <td>female</td>\n",
       "      <td>normal</td>\n",
       "      <td>./data/ravdess-emotional-speech-audio/Actor_24...</td>\n",
       "      <td>ravdess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>surprised</td>\n",
       "      <td>female</td>\n",
       "      <td>strong</td>\n",
       "      <td>./data/ravdess-emotional-speech-audio/Actor_24...</td>\n",
       "      <td>ravdess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>surprised</td>\n",
       "      <td>female</td>\n",
       "      <td>strong</td>\n",
       "      <td>./data/ravdess-emotional-speech-audio/Actor_24...</td>\n",
       "      <td>ravdess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>surprised</td>\n",
       "      <td>female</td>\n",
       "      <td>strong</td>\n",
       "      <td>./data/ravdess-emotional-speech-audio/Actor_24...</td>\n",
       "      <td>ravdess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>surprised</td>\n",
       "      <td>female</td>\n",
       "      <td>strong</td>\n",
       "      <td>./data/ravdess-emotional-speech-audio/Actor_24...</td>\n",
       "      <td>ravdess</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotions genders audio_intensity  \\\n",
       "0       neutral    male          normal   \n",
       "1       neutral    male          normal   \n",
       "2       neutral    male          normal   \n",
       "3       neutral    male          normal   \n",
       "4          calm    male          normal   \n",
       "...         ...     ...             ...   \n",
       "1435  surprised  female          normal   \n",
       "1436  surprised  female          strong   \n",
       "1437  surprised  female          strong   \n",
       "1438  surprised  female          strong   \n",
       "1439  surprised  female          strong   \n",
       "\n",
       "                                             audio_path  dataset  \n",
       "0     ./data/ravdess-emotional-speech-audio/Actor_01...  ravdess  \n",
       "1     ./data/ravdess-emotional-speech-audio/Actor_01...  ravdess  \n",
       "2     ./data/ravdess-emotional-speech-audio/Actor_01...  ravdess  \n",
       "3     ./data/ravdess-emotional-speech-audio/Actor_01...  ravdess  \n",
       "4     ./data/ravdess-emotional-speech-audio/Actor_01...  ravdess  \n",
       "...                                                 ...      ...  \n",
       "1435  ./data/ravdess-emotional-speech-audio/Actor_24...  ravdess  \n",
       "1436  ./data/ravdess-emotional-speech-audio/Actor_24...  ravdess  \n",
       "1437  ./data/ravdess-emotional-speech-audio/Actor_24...  ravdess  \n",
       "1438  ./data/ravdess-emotional-speech-audio/Actor_24...  ravdess  \n",
       "1439  ./data/ravdess-emotional-speech-audio/Actor_24...  ravdess  \n",
       "\n",
       "[1440 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ravdess_actors_list = os.listdir(RAVDESS)\n",
    "audio_emotion = []\n",
    "audio_path = []\n",
    "audio_gender = []\n",
    "audio_intensity = []\n",
    "for file in ravdess_actors_list:\n",
    "    actor = os.listdir(RAVDESS+file)\n",
    "    for audio in actor:\n",
    "        list_audio = audio.split('.')[0] # splitting by the '.' into '**-**-**' . 'wav' and grab the first element\n",
    "        list_audio = list_audio.split('-') # splitting by the dash\n",
    "        gender_code = int(list_audio[6])\n",
    "        \n",
    "        audio_emotion.append(int(list_audio[2])) # the third element describes the emotion class\n",
    "        audio_gender.append('female' if gender_code & 1 == 0 else 'male') # the sixth element describes the voice gender \n",
    "        audio_intensity.append('normal' if int(list_audio[3]) == 1 else 'high')\n",
    "        audio_path.append(RAVDESS + file + '/' + audio)\n",
    "\n",
    "ravdess_df = pd.DataFrame({'emotions': audio_emotion, 'genders': audio_gender, 'audio_intensity': audio_intensity, 'audio_path': audio_path,})\n",
    "\n",
    "# Mapping the values to emotions\n",
    "emotions2str = {\n",
    "    1: 'neutral',\n",
    "    2: 'calm',\n",
    "    3: 'happy',\n",
    "    4: 'sad',\n",
    "    5: 'angry',\n",
    "    6: 'fearful',\n",
    "    7: 'disgust',\n",
    "    8: 'surprised',\n",
    "}\n",
    "\n",
    "# Replace the values in the column with emotions\n",
    "ravdess_df['emotions'] = ravdess_df['emotions'] .replace(emotions2str)\n",
    "ravdess_df['dataset'] = 'ravdess'\n",
    "ravdess_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fdd96c",
   "metadata": {},
   "source": [
    "## 2.2. Crema dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd16ae41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotions</th>\n",
       "      <th>audio_intensity</th>\n",
       "      <th>audio_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>normal</td>\n",
       "      <td>./data/cremad/1001_DFA_ANG_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>normal</td>\n",
       "      <td>./data/cremad/1001_DFA_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>normal</td>\n",
       "      <td>./data/cremad/1001_DFA_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>normal</td>\n",
       "      <td>./data/cremad/1001_DFA_HAP_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>./data/cremad/1001_DFA_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7437</th>\n",
       "      <td>disgust</td>\n",
       "      <td>normal</td>\n",
       "      <td>./data/cremad/1091_WSI_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7438</th>\n",
       "      <td>fear</td>\n",
       "      <td>normal</td>\n",
       "      <td>./data/cremad/1091_WSI_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7439</th>\n",
       "      <td>happy</td>\n",
       "      <td>normal</td>\n",
       "      <td>./data/cremad/1091_WSI_HAP_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7440</th>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>./data/cremad/1091_WSI_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7441</th>\n",
       "      <td>sad</td>\n",
       "      <td>normal</td>\n",
       "      <td>./data/cremad/1091_WSI_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7442 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     emotions audio_intensity                         audio_path\n",
       "0       angry          normal  ./data/cremad/1001_DFA_ANG_XX.wav\n",
       "1     disgust          normal  ./data/cremad/1001_DFA_DIS_XX.wav\n",
       "2        fear          normal  ./data/cremad/1001_DFA_FEA_XX.wav\n",
       "3       happy          normal  ./data/cremad/1001_DFA_HAP_XX.wav\n",
       "4     neutral          normal  ./data/cremad/1001_DFA_NEU_XX.wav\n",
       "...       ...             ...                                ...\n",
       "7437  disgust          normal  ./data/cremad/1091_WSI_DIS_XX.wav\n",
       "7438     fear          normal  ./data/cremad/1091_WSI_FEA_XX.wav\n",
       "7439    happy          normal  ./data/cremad/1091_WSI_HAP_XX.wav\n",
       "7440  neutral          normal  ./data/cremad/1091_WSI_NEU_XX.wav\n",
       "7441      sad          normal  ./data/cremad/1091_WSI_SAD_XX.wav\n",
       "\n",
       "[7442 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crema_list = os.listdir(CREMA)\n",
    "audio_emotion = []\n",
    "audio_path = []\n",
    "audio_intensity = []\n",
    "for audio in crema_list:\n",
    "    list_audio = audio.split('.')[0] # splitting by the '.' into '**-**-**' . 'wav' and grab the first element\n",
    "    list_audio = list_audio.split('_') # splitting by the underline\n",
    "    \n",
    "    # the third element describes the emotion class\n",
    "    if list_audio[2] == 'ANG': \n",
    "        audio_emotion.append('angry')\n",
    "    elif list_audio[2] == 'SAD': \n",
    "        audio_emotion.append('sad')\n",
    "    elif list_audio[2] == 'DIS': \n",
    "        audio_emotion.append('disgust')\n",
    "    elif list_audio[2] == 'FEA': \n",
    "        audio_emotion.append('fear')\n",
    "    elif list_audio[2] == 'HAP': \n",
    "        audio_emotion.append('happy')\n",
    "    elif list_audio[2] == 'NEU': \n",
    "        audio_emotion.append('neutral')\n",
    "    else:\n",
    "        audio_emotion.append('unknown')\n",
    "\n",
    "    # the forth element describes the intensity of the voice\n",
    "    if list_audio[3] == 'XX':\n",
    "        audio_intensity.append('normal')\n",
    "    elif list_audio[3] == 'LO':\n",
    "        audio_intensity.append('low')\n",
    "    elif list_audio[3] == 'MD':\n",
    "        audio_intensity.append('medium')\n",
    "    elif list_audio[3] == 'HI':\n",
    "        audio_intensity.append('high')\n",
    "    else:\n",
    "        audio_intensity.append('normal')\n",
    "\n",
    "    audio_path.append(CREMA + audio)\n",
    "\n",
    "crema_df = pd.DataFrame({'emotions': audio_emotion, 'audio_intensity': audio_intensity, 'audio_path': audio_path})\n",
    "crema_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8255373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
