{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9d62f9-500f-42a4-be40-481e2b1bfcd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d16245d3-8a8a-4d97-b1e4-7845ac5a789f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import glob\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "from shutil import move\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import soundfile as sf\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow \n",
    "from keras.applications import MobileNetV2, MobileNetV3Small\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae651683-fc37-4077-8fed-f076fa8cdcda",
   "metadata": {},
   "source": [
    "# 2. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7782d9d5-b4d1-4460-a716-1ddda02e5b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAVDESS = \"./data/ravdess-emotional-speech-audio/\"\n",
    "CREMA = \"./data/cremad/\"\n",
    "TESS = \"./data/toronto-emotional-speech-set-tess/\"\n",
    "SAVEE = \"./data/surrey-audiovisual-expressed-emotion-savee/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c58262",
   "metadata": {},
   "source": [
    "## 2.1. Ravdess dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e3ddabe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m durations \u001b[39m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m ravdess_actors_list:\n\u001b[1;32m----> 9\u001b[0m     actor \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(RAVDESS,file))\n\u001b[0;32m     10\u001b[0m     \u001b[39mfor\u001b[39;00m audio \u001b[39min\u001b[39;00m actor:\n\u001b[0;32m     11\u001b[0m         list_audio \u001b[39m=\u001b[39m audio\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m# splitting by the '.' into '**-**-**' . 'wav' and grab the first element\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ravdess_actors_list = os.listdir(RAVDESS)\n",
    "audio_emotion = []\n",
    "audio_path = []\n",
    "audio_gender = []\n",
    "audio_intensity = []\n",
    "durations = []\n",
    "\n",
    "for file in ravdess_actors_list:\n",
    "    actor = os.listdir(os.path.join(RAVDESS,file))\n",
    "    for audio in actor:\n",
    "        list_audio = audio.split('.')[0] # splitting by the '.' into '**-**-**' . 'wav' and grab the first element\n",
    "        list_audio = list_audio.split('-') # splitting by the dash\n",
    "        gender_code = int(list_audio[6])\n",
    "        \n",
    "        audio_emotion.append(int(list_audio[2])) # the third element describes the emotion class\n",
    "        audio_gender.append('female' if gender_code & 1 == 0 else 'male') # the sixth element describes the voice gender \n",
    "        audio_intensity.append('normal' if int(list_audio[3]) == 1 else 'high')\n",
    "        audio_path.append(os.path.join(RAVDESS,file,audio))\n",
    "        \n",
    "        audio, sr = librosa.load(os.path.join(RAVDESS,file,audio))\n",
    "        durations.append(librosa.get_duration(y=audio, sr=sr))\n",
    "\n",
    "ravdess_df = pd.DataFrame({'emotions': audio_emotion, 'genders': audio_gender, 'audio_intensity': audio_intensity, 'audio_path': audio_path, 'duration':durations})\n",
    "\n",
    "# Mapping the values to emotions\n",
    "emotion_dict = {\n",
    "    1: 'neutral',\n",
    "    2: 'neutral', # originally - - > 'calm'\n",
    "    3: 'happy',\n",
    "    4: 'sad',\n",
    "    5: 'angry',\n",
    "    6: 'fear',\n",
    "    7: 'disgust',\n",
    "    8: 'surprised',\n",
    "}\n",
    "\n",
    "# Replace the values in the column with emotions\n",
    "ravdess_df['emotions'] = ravdess_df['emotions'] .replace(emotion_dict)\n",
    "ravdess_df['dataset'] = 'ravdess'\n",
    "ravdess_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fdd96c",
   "metadata": {},
   "source": [
    "## 2.2. Crema dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd16ae41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crema_list = os.listdir(CREMA)\n",
    "audio_emotion = []\n",
    "audio_path = []\n",
    "audio_intensity = []\n",
    "gender_list = []\n",
    "durations = []\n",
    "\n",
    "female_id_list = [\n",
    "    '1002', '1003', '1004', '1006', '1007', '1008', '1009', '1010', '1012', '1013', '1018', \n",
    "    '1020', '1021', '1024', '1025', '1028', '1029', '1030', '1037', '1043', '1046', '1047', \n",
    "    '1049', '1052', '1053', '1054', '1055', '1056', '1058', '1060', '1061', '1063', '1072', \n",
    "    '1073', '1074', '1075', '1076', '1078', '1079', '1082', '1084', '1089', '1091',\n",
    "]\n",
    "\n",
    "emotion_dict = {\n",
    "    'HAP' : 'happy',\n",
    "    'NEU' : 'neutral',\n",
    "    'SAD' : 'sad',\n",
    "    'ANG' : 'angry',\n",
    "    'FEA' : 'fear',\n",
    "    'DIS' : 'disgust',\n",
    "}\n",
    "\n",
    "intensity_dict = {\n",
    "    'XX' : 'normal',\n",
    "    'X' : 'normal',\n",
    "    'LO' : 'low',\n",
    "    'MD' : 'normal',\n",
    "    'HI': 'high'\n",
    "}\n",
    "\n",
    "for audio in crema_list:\n",
    "    list_audio = audio.split('.')[0] # splitting by the '.' into '**-**-**' . 'wav' and grab the first element\n",
    "    list_audio = list_audio.split('_') # splitting by the underline\n",
    "    audio_emotion.append(list_audio[2])\n",
    "    audio_intensity.append(list_audio[3])\n",
    "    audio_path.append(os.path.join(CREMA,audio))\n",
    "    gender_list.append('female' if list_audio[0] in female_id_list else 'male')\n",
    "    \n",
    "    audio, sr = librosa.load(os.path.join(CREMA,audio))\n",
    "    durations.append(librosa.get_duration(y=audio, sr=sr))\n",
    "    \n",
    "crema_df = pd.DataFrame({'emotions': audio_emotion, 'genders': gender_list, 'audio_intensity': audio_intensity, 'audio_path': audio_path, 'duration':durations})\n",
    "crema_df['emotions'] = crema_df['emotions'].replace(emotion_dict)\n",
    "crema_df['audio_intensity'] = crema_df['audio_intensity'].replace(intensity_dict)\n",
    "crema_df['dataset'] = 'crema'\n",
    "crema_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a0a6b1-22a9-40c4-b52d-21afe81c80d9",
   "metadata": {},
   "source": [
    "## 2.3. TESS dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4e2bcb-99e0-4c90-8dbc-aad074ff9882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tess_dir_list = os.listdir(TESS)\n",
    "path_list = []\n",
    "gender_list = []\n",
    "emotion_list = [] \n",
    "audio_intensity = []\n",
    "durations = []\n",
    "\n",
    "emotion_dict = {\n",
    "    'happy'   : 'happy',\n",
    "    'neutral' : 'neutral',\n",
    "    'sad'     : 'sad',\n",
    "    'ps'     : 'surprised',\n",
    "    'angry'   : 'angry',\n",
    "    'fear'    : 'fear',\n",
    "    'disgust'  : 'disgust',\n",
    "}\n",
    "\n",
    "for directory in tess_dir_list:\n",
    "    audio_files = os.listdir(os.path.join(TESS, directory))\n",
    "    for audio_file in audio_files:\n",
    "        part = audio_file.split('.')[0]\n",
    "        path_list.append(os.path.join(TESS,directory,audio_file))\n",
    "        gender_list.append('female') # female only dataset\n",
    "        audio_intensity.append('normal') # normal only dataset\n",
    "        emotion_list.append(part.split('_')[2])\n",
    "        \n",
    "        audio, sr = librosa.load(os.path.join(TESS,directory,audio_file))\n",
    "        durations.append(librosa.get_duration(y=audio, sr=sr))\n",
    "            \n",
    "tess_df = pd.DataFrame({'emotions': emotion_list, 'genders': gender_list, 'audio_intensity': audio_intensity, 'audio_path': path_list, 'duration':durations})\n",
    "tess_df['emotions'] = tess_df['emotions'].replace(emotion_dict)\n",
    "tess_df['dataset'] = 'tess'\n",
    "tess_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbc0eef-7e88-48b6-a78a-73c97bcdd82e",
   "metadata": {},
   "source": [
    "## 2.3. SAVEE dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79812cdc-6f33-496a-a76a-1f5d8687ccaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "savee_dir_list = os.listdir(SAVEE)\n",
    "path_list = []\n",
    "gender_list = []\n",
    "emotion_list = []\n",
    "audio_intensity = []\n",
    "durations = []\n",
    "\n",
    "emotion_dict = {\n",
    "    'h'  : 'happy',\n",
    "    'n'  : 'neutral',\n",
    "    'sa' : 'sad',\n",
    "    'a'  : 'angry',\n",
    "    'f'  : 'fear',\n",
    "    'd'  : 'disgust',\n",
    "    'su' : 'surprised'\n",
    "}\n",
    "\n",
    "for audio_file in savee_dir_list:\n",
    "    part = audio_file.split('_')[1]\n",
    "    path_list.append(os.path.join(SAVEE,audio_file))\n",
    "    gender_list.append('male') # male only dataset\n",
    "    emotion_list.append(part[:-6])\n",
    "    audio_intensity.append('normal') # normal only dataset\n",
    "    \n",
    "    audio, sr = librosa.load(os.path.join(SAVEE,audio_file))\n",
    "    durations.append(librosa.get_duration(y=audio, sr=sr))\n",
    "        \n",
    "savee_df = pd.DataFrame({'emotions': emotion_list, 'genders': gender_list, 'audio_intensity': audio_intensity, 'audio_path': path_list,'duration':durations})\n",
    "savee_df['emotions'] = savee_df['emotions'].replace(emotion_dict)\n",
    "savee_df['dataset'] = 'savee'\n",
    "\n",
    "savee_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4eea19-f752-4a55-928d-48313195d15c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = pd.concat([ravdess_df, crema_df, tess_df, savee_df], axis=0)\n",
    "merged_df.reset_index(inplace=True, drop=True)\n",
    "merged_df.to_csv('merged_df.csv',index=False)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f3bf9c-7f3a-46a3-9bd0-da850193229c",
   "metadata": {},
   "source": [
    "# 3. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa979fb",
   "metadata": {},
   "source": [
    "## 3.1. Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3937684",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "emotion_percent = merged_df['emotions'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Set a threshold for small percentage slices\n",
    "threshold = 5\n",
    "\n",
    "# Identify emotions below the threshold\n",
    "small_emotions = emotion_percent[emotion_percent < threshold]\n",
    "\n",
    "# Create a list of explode values\n",
    "explode = [0.1 if emotion in small_emotions else 0 for emotion in emotion_percent.index]\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Define a custom color palette\n",
    "color_palette = [\"#0bb4ff\", \"#50e991\", \"#e6d800\", \"#9b19f5\", \"#e60049\"] \n",
    "\n",
    "# Create the pie chart with explode values\n",
    "plt.pie(emotion_percent, labels=emotion_percent.index, autopct='%1.1f%%', colors=color_palette, explode=explode)\n",
    "\n",
    "# Set the title\n",
    "plt.title('Distribution of Emotions', size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4724b559",
   "metadata": {},
   "source": [
    "The pie chart represents the distribution of emotion types in the dataset. <br>\n",
    "It is evident that apart from the surprised tone with 5.4% , the other types of tones are around 14-16%. <br>\n",
    "Worth mentioning that the tone 'calm' with its 1.6% distribution in the dataset, was merged with the neutral tone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a739197-466f-4398-89bf-72b5f3a47f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of each emotion by gender\n",
    "emotions_by_gender = merged_df.groupby('genders')['emotions'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Reset the index to convert the result into a DataFrame\n",
    "emotions_by_gender = emotions_by_gender.reset_index(name='percentage')\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "sns.barplot(emotions_by_gender, x='emotions', y='percentage', hue='genders', palette='Set2')\n",
    "\n",
    "plt.title('Distribution of Emotions by Gender', size=16)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "plt.ylabel('Percent, %', size=12)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "sns.despine() # Remove the top and right spines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9601592",
   "metadata": {},
   "source": [
    "The distribution of emotions in the entire dataset by the gender is relatively uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811336b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of each emotion by gender\n",
    "emotions_by_gender = merged_df.groupby('audio_intensity')['emotions'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Reset the index to convert the result into a DataFrame\n",
    "emotions_by_gender = emotions_by_gender.reset_index(name='percentage')\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "sns.barplot(emotions_by_gender, x='emotions', y='percentage', hue='audio_intensity', hue_order=['high', 'normal', 'low'], palette='Set2')\n",
    "\n",
    "plt.title('Distribution of Emotions by Audio Intensity', size=16)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "plt.ylabel('Percent, %', size=12)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "sns.despine() # Remove the top and right spines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf57ee",
   "metadata": {},
   "source": [
    "The audio intensity distribution is divided by high, normal, and low. Neutral and surprised tones have only two intensities, normal and high. <br>\n",
    "The total distribution is uniform between all the modes of the tone intensity (15%-20%), where only in neutral tone there is a higher percentage of normal intensity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97073800-0471-4a2e-b9ed-61a799f223cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a histogram using seaborn\n",
    "sns.histplot(data=merged_df, x='duration', hue='dataset')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Duration')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Sound Durations')\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d6d7a-73d1-4fba-b4c5-429133ad0feb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"max input audion duration is {round(merged_df['duration'].max(),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38409777-9555-46fa-bf1b-b1a62ca8a0ba",
   "metadata": {},
   "source": [
    "The audio duration distribution of each dataset is slightly different, with the SAVEE dataset having the biggest spread.\n",
    "This means that as part of the data preparation for the model, we'll need to pad the audio files with zeroes based on the longest audio files in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2694ecc",
   "metadata": {},
   "source": [
    "## 3.2. Demonstration of various audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd954beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_random_audio(dataframe, gender, emotion, intensity, preprocess=False):\n",
    "    # Filter the DataFrame based on the given criteria\n",
    "    filtered_df = dataframe[(dataframe['genders'] == gender) & (dataframe['emotions'] == emotion) & (dataframe['audio_intensity'] == intensity)]\n",
    "    \n",
    "    # Randomly select an audio file path\n",
    "    file_path = random.choice(np.array(filtered_df['audio_path']))\n",
    "    \n",
    "    # Load the audio file using librosa\n",
    "    audio, sr = librosa.load(file_path)\n",
    "\n",
    "    # Applying preprocess\n",
    "    if preprocess:\n",
    "        audio = preprocess_audio(audio)\n",
    "        \n",
    "    # Display the waveform plot\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Waveform plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    librosa.display.waveshow(audio, sr=sr)\n",
    "    plt.title(f'Waveform')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "\n",
    "    # Spectrogram plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "    spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    img = librosa.display.specshow(spectrogram_db, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.title('Spectrogram')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Mel frequency')\n",
    "    plt.colorbar(format='%+2.0f dB')  # A colorbar with dB format\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.4)  #  Horizontal spacing between subplots\n",
    "    plt.suptitle(f'Dataset: {dataframe[dataframe[\"audio_path\"]==file_path][\"dataset\"].values[0]}, Gender: {gender}, Emotion: {emotion}, Intensity: {intensity}', weight='bold', size=16)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Play the audio\n",
    "    return ipd.Audio(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef2c23",
   "metadata": {},
   "source": [
    "Examples of random audio samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c229d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_random_audio(merged_df, gender=\"female\", emotion=\"fear\", intensity=\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c37840",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_random_audio(merged_df, gender=\"female\", emotion=\"happy\", intensity=\"low\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c356b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_random_audio(merged_df, gender=\"male\", emotion=\"angry\", intensity=\"normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d7dd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_random_audio(merged_df, gender=\"male\", emotion=\"disgust\", intensity=\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_random_audio(merged_df, gender=\"female\", emotion=\"surprised\", intensity=\"high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df24dba",
   "metadata": {},
   "source": [
    "Each of the imported datasets originated from a different location, i.e., some with background noise, different sentences, gender of speakers, etc... <br>\n",
    "This contributes to the quality of the whole data frame and thereafter to the ability of the model to classify an emotion of an unseen dataset. <br>\n",
    "From the samples above, one can qualitatively distinguish between the various emotions, despite being recorded in different environments (e.g., a studio or with a sort of environmental noise) or if the speaker says a different sentence. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb4d46",
   "metadata": {},
   "source": [
    "The Mel-frequency spectrogram is designed to better approximate the perception of sound by humans, especially in terms of the frequency resolution. It captures more details in the lower frequencies where human hearing is more sensitive and provides a more perceptually relevant representation compared to the regular spectrogram with a linear frequency scale.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c66dc0d",
   "metadata": {},
   "source": [
    "# 4. Feature Extraction & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e3ac3e-0a72-4638-bfa4-3256e72ff7a0",
   "metadata": {},
   "source": [
    "## 4.1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de1dfaf-8643-4250-a32e-da67a80d7aef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_audio(audio):\n",
    "    \n",
    "    # waveform final samples length set to 160000 (~7.2 seconds) for SAVEE dataset compatability\n",
    "    samples_count = 160000\n",
    "    \n",
    "    # maximum decibles considered silence to be removed from start and end of audio\n",
    "    silence_db = 25\n",
    "    \n",
    "    trimmed_audio, _ = librosa.effects.trim(audio, top_db=silence_db)\n",
    "    padded_trimmed_audio = np.pad(trimmed_audio, (0, samples_count-len(trimmed_audio)), 'constant')\n",
    "    \n",
    "    return padded_trimmed_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bd36d4-215a-44ba-a177-498e4d5c48ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "play_random_audio(merged_df, gender=\"male\", emotion=\"disgust\", intensity=\"high\", preprocess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064a7255",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799817bf",
   "metadata": {},
   "source": [
    "## 2D Convolution on Mel-spectrum images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f2631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramDataCreator:\n",
    "    def __init__(self, num_mels=224):\n",
    "        self.num_mels = num_mels\n",
    "        self.max_length = 0\n",
    "\n",
    "    def create_data(self, df, save_folder):\n",
    "        X_spectrogram = []\n",
    "        y = []\n",
    "        \n",
    "        os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "        for i, row in df.iterrows():\n",
    "            audio_path = row['audio_path']\n",
    "            emotion = row['emotions']\n",
    "            dataset = row['dataset']\n",
    "            spectrogram = self._extract_spectrogram(audio_path)\n",
    "            X_spectrogram.append(spectrogram)\n",
    "            y.append(emotion)\n",
    "\n",
    "            # Save the spectrogram as an image\n",
    "            filename = f\"{dataset}_index{i}_{emotion}.png\"\n",
    "            filepath = os.path.join(save_folder, filename)\n",
    "            self._save_spectrogram_image(spectrogram, filepath)\n",
    "\n",
    "            # Update maximum length if needed\n",
    "            if spectrogram.shape[1] > self.max_length:\n",
    "                self.max_length = spectrogram.shape[1]\n",
    "\n",
    "        # Apply padding or truncation with the computed maximum length\n",
    "        for i in range(len(X_spectrogram)):\n",
    "            if X_spectrogram[i].shape[1] < self.max_length:\n",
    "                pad_width = self.max_length - X_spectrogram[i].shape[1]\n",
    "                X_spectrogram[i] = np.pad(X_spectrogram[i], pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "            else:\n",
    "                X_spectrogram[i] = X_spectrogram[i][:, :self.max_length]\n",
    "\n",
    "        X_spectrogram = np.array(X_spectrogram)\n",
    "        y = np.array(y)\n",
    "\n",
    "        return X_spectrogram, y, self.max_length\n",
    "\n",
    "    def _extract_spectrogram(self, audio_path):\n",
    "        audio, sr = librosa.load(audio_path)\n",
    "        spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=self.num_mels)\n",
    "        return spectrogram\n",
    "\n",
    "    def _save_spectrogram_image(self, spectrogram, filepath):\n",
    "        plt.figure(figsize=(96 / 100, 64 / 100), dpi=100)  # Set the figure size to 224x224\n",
    "        librosa.display.specshow(librosa.power_to_db(spectrogram, ref=np.max), y_axis='mel', x_axis='time')\n",
    "        plt.axis('off')  # Remove axis ticks and labels\n",
    "        plt.subplots_adjust(left=0, right=1, top=1, bottom=0)  # Remove unnecessary margins\n",
    "        plt.savefig(filepath, bbox_inches='tight', pad_inches=0)  # Save the image without extra padding\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cab7b494",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_data_creator = SpectrogramDataCreator()\n",
    "X_spectrogram, y, max_length = spectrogram_data_creator.create_data(final_data, save_folder='spectrogram_images_96x64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0677cac9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m spectrogram_data_creator \u001b[39m=\u001b[39m SpectrogramDataCreator()\n\u001b[0;32m      7\u001b[0m \u001b[39m# Call the create_data method on the remaining data\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m X_spectrogram, y, max_length \u001b[39m=\u001b[39m spectrogram_data_creator\u001b[39m.\u001b[39;49mcreate_data(remaining_data, save_folder\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mspectrogram_images_96x64\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[2], line 23\u001b[0m, in \u001b[0;36mSpectrogramDataCreator.create_data\u001b[1;34m(self, df, save_folder)\u001b[0m\n\u001b[0;32m     21\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdataset\u001b[39m}\u001b[39;00m\u001b[39m_index\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00memotion\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m filepath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(save_folder, filename)\n\u001b[1;32m---> 23\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_spectrogram_image(spectrogram, filepath)\n\u001b[0;32m     25\u001b[0m \u001b[39m# Update maximum length if needed\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39mif\u001b[39;00m spectrogram\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_length:\n",
      "Cell \u001b[1;32mIn[2], line 52\u001b[0m, in \u001b[0;36mSpectrogramDataCreator._save_spectrogram_image\u001b[1;34m(self, spectrogram, filepath)\u001b[0m\n\u001b[0;32m     50\u001b[0m plt\u001b[39m.\u001b[39maxis(\u001b[39m'\u001b[39m\u001b[39moff\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# Remove axis ticks and labels\u001b[39;00m\n\u001b[0;32m     51\u001b[0m plt\u001b[39m.\u001b[39msubplots_adjust(left\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, right\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, top\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, bottom\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)  \u001b[39m# Remove unnecessary margins\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m plt\u001b[39m.\u001b[39;49msavefig(filepath, bbox_inches\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtight\u001b[39;49m\u001b[39m'\u001b[39;49m, pad_inches\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)  \u001b[39m# Save the image without extra padding\u001b[39;00m\n\u001b[0;32m     53\u001b[0m plt\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\pyplot.py:996\u001b[0m, in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[39m.\u001b[39msavefig)\n\u001b[0;32m    994\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msavefig\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    995\u001b[0m     fig \u001b[39m=\u001b[39m gcf()\n\u001b[1;32m--> 996\u001b[0m     res \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39;49msavefig(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    997\u001b[0m     fig\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mdraw_idle()  \u001b[39m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[0;32m    998\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\figure.py:3328\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3324\u001b[0m     \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes:\n\u001b[0;32m   3325\u001b[0m         stack\u001b[39m.\u001b[39menter_context(\n\u001b[0;32m   3326\u001b[0m             ax\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39m_cm_set(facecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m, edgecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m-> 3328\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(fname, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\backend_bases.py:2338\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2332\u001b[0m     renderer \u001b[39m=\u001b[39m _get_renderer(\n\u001b[0;32m   2333\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure,\n\u001b[0;32m   2334\u001b[0m         functools\u001b[39m.\u001b[39mpartial(\n\u001b[0;32m   2335\u001b[0m             print_method, orientation\u001b[39m=\u001b[39morientation)\n\u001b[0;32m   2336\u001b[0m     )\n\u001b[0;32m   2337\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mgetattr\u001b[39m(renderer, \u001b[39m\"\u001b[39m\u001b[39m_draw_disabled\u001b[39m\u001b[39m\"\u001b[39m, nullcontext)():\n\u001b[1;32m-> 2338\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m   2340\u001b[0m \u001b[39mif\u001b[39;00m bbox_inches:\n\u001b[0;32m   2341\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[0;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 95\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     96\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[0;32m     97\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\figure.py:3125\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3122\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   3124\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 3125\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[0;32m   3126\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[0;32m   3128\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[0;32m   3129\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[0;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[1;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\axes\\_base.py:3030\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3027\u001b[0m     \u001b[39mfor\u001b[39;00m spine \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspines\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m   3028\u001b[0m         artists\u001b[39m.\u001b[39mremove(spine)\n\u001b[1;32m-> 3030\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_title_position(renderer)\n\u001b[0;32m   3032\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxison:\n\u001b[0;32m   3033\u001b[0m     \u001b[39mfor\u001b[39;00m _axis \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_axis_map\u001b[39m.\u001b[39mvalues():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\axes\\_base.py:2965\u001b[0m, in \u001b[0;36m_AxesBase._update_title_position\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2962\u001b[0m bb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2963\u001b[0m \u001b[39mif\u001b[39;00m (ax\u001b[39m.\u001b[39mxaxis\u001b[39m.\u001b[39mget_ticks_position() \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mtop\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39munknown\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m   2964\u001b[0m         \u001b[39mor\u001b[39;00m ax\u001b[39m.\u001b[39mxaxis\u001b[39m.\u001b[39mget_label_position() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtop\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m-> 2965\u001b[0m     bb \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49mxaxis\u001b[39m.\u001b[39;49mget_tightbbox(renderer)\n\u001b[0;32m   2966\u001b[0m \u001b[39mif\u001b[39;00m bb \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2967\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39moutline\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m ax\u001b[39m.\u001b[39mspines:\n\u001b[0;32m   2968\u001b[0m         \u001b[39m# Special case for colorbars:\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\axis.py:1320\u001b[0m, in \u001b[0;36mAxis.get_tightbbox\u001b[1;34m(self, renderer, for_layout_only)\u001b[0m\n\u001b[0;32m   1317\u001b[0m     renderer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39m_get_renderer()\n\u001b[0;32m   1318\u001b[0m ticks_to_draw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_ticks()\n\u001b[1;32m-> 1320\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_label_position(renderer)\n\u001b[0;32m   1322\u001b[0m \u001b[39m# go back to just this axis's tick labels\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m tlb1, tlb2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\axis.py:2308\u001b[0m, in \u001b[0;36mXAxis._update_label_position\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2304\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   2306\u001b[0m \u001b[39m# get bounding boxes for this axis and any siblings\u001b[39;00m\n\u001b[0;32m   2307\u001b[0m \u001b[39m# that have been set by `fig.align_xlabels()`\u001b[39;00m\n\u001b[1;32m-> 2308\u001b[0m bboxes, bboxes2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_tick_boxes_siblings(renderer\u001b[39m=\u001b[39;49mrenderer)\n\u001b[0;32m   2310\u001b[0m x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel\u001b[39m.\u001b[39mget_position()\n\u001b[0;32m   2311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_position \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbottom\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\axis.py:2104\u001b[0m, in \u001b[0;36mAxis._get_tick_boxes_siblings\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2102\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(ax, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39maxis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2103\u001b[0m ticks_to_draw \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39m_update_ticks()\n\u001b[1;32m-> 2104\u001b[0m tlb, tlb2 \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[0;32m   2105\u001b[0m bboxes\u001b[39m.\u001b[39mextend(tlb)\n\u001b[0;32m   2106\u001b[0m bboxes2\u001b[39m.\u001b[39mextend(tlb2)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\axis.py:1299\u001b[0m, in \u001b[0;36mAxis._get_ticklabel_bboxes\u001b[1;34m(self, ticks, renderer)\u001b[0m\n\u001b[0;32m   1297\u001b[0m \u001b[39mif\u001b[39;00m renderer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1298\u001b[0m     renderer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1299\u001b[0m \u001b[39mreturn\u001b[39;00m ([tick\u001b[39m.\u001b[39;49mlabel1\u001b[39m.\u001b[39;49mget_window_extent(renderer)\n\u001b[0;32m   1300\u001b[0m          \u001b[39mfor\u001b[39;49;00m tick \u001b[39min\u001b[39;49;00m ticks \u001b[39mif\u001b[39;49;00m tick\u001b[39m.\u001b[39;49mlabel1\u001b[39m.\u001b[39;49mget_visible()],\n\u001b[0;32m   1301\u001b[0m         [tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1302\u001b[0m          \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\axis.py:1299\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1297\u001b[0m \u001b[39mif\u001b[39;00m renderer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1298\u001b[0m     renderer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1299\u001b[0m \u001b[39mreturn\u001b[39;00m ([tick\u001b[39m.\u001b[39;49mlabel1\u001b[39m.\u001b[39;49mget_window_extent(renderer)\n\u001b[0;32m   1300\u001b[0m          \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel1\u001b[39m.\u001b[39mget_visible()],\n\u001b[0;32m   1301\u001b[0m         [tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1302\u001b[0m          \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\text.py:959\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[1;34m(self, renderer, dpi)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    955\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot get window extent of text w/o renderer. You likely \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    956\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwant to call \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfigure.draw_without_rendering()\u001b[39m\u001b[39m'\u001b[39m\u001b[39m first.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    958\u001b[0m \u001b[39mwith\u001b[39;00m cbook\u001b[39m.\u001b[39m_setattr_cm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, dpi\u001b[39m=\u001b[39mdpi):\n\u001b[1;32m--> 959\u001b[0m     bbox, info, descent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_layout(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_renderer)\n\u001b[0;32m    960\u001b[0m     x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_unitless_position()\n\u001b[0;32m    961\u001b[0m     x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_transform()\u001b[39m.\u001b[39mtransform((x, y))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\text.py:378\u001b[0m, in \u001b[0;36mText._get_layout\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    375\u001b[0m ys \u001b[39m=\u001b[39m []\n\u001b[0;32m    377\u001b[0m \u001b[39m# Full vertical extent of font, including ascenders and descenders:\u001b[39;00m\n\u001b[1;32m--> 378\u001b[0m _, lp_h, lp_d \u001b[39m=\u001b[39m _get_text_metrics_with_cache(\n\u001b[0;32m    379\u001b[0m     renderer, \u001b[39m\"\u001b[39;49m\u001b[39mlp\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fontproperties,\n\u001b[0;32m    380\u001b[0m     ismath\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTeX\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_usetex() \u001b[39melse\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m, dpi\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdpi)\n\u001b[0;32m    381\u001b[0m min_dy \u001b[39m=\u001b[39m (lp_h \u001b[39m-\u001b[39m lp_d) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_linespacing\n\u001b[0;32m    383\u001b[0m \u001b[39mfor\u001b[39;00m i, line \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(lines):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\text.py:97\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache\u001b[1;34m(renderer, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call ``renderer.get_text_width_height_descent``, caching the results.\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39m# Cached based on a copy of fontprop so that later in-place mutations of\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[39m# the passed-in argument do not mess up the cache.\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m \u001b[39mreturn\u001b[39;00m _get_text_metrics_with_cache_impl(\n\u001b[0;32m     98\u001b[0m     weakref\u001b[39m.\u001b[39;49mref(renderer), text, fontprop\u001b[39m.\u001b[39;49mcopy(), ismath, dpi)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\text.py:105\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache_impl\u001b[1;34m(renderer_ref, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mlru_cache(\u001b[39m4096\u001b[39m)\n\u001b[0;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_text_metrics_with_cache_impl\u001b[39m(\n\u001b[0;32m    103\u001b[0m         renderer_ref, text, fontprop, ismath, dpi):\n\u001b[0;32m    104\u001b[0m     \u001b[39m# dpi is unused, but participates in cache invalidation (via the renderer).\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     \u001b[39mreturn\u001b[39;00m renderer_ref()\u001b[39m.\u001b[39;49mget_text_width_height_descent(text, fontprop, ismath)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\backends\\backend_agg.py:234\u001b[0m, in \u001b[0;36mRendererAgg.get_text_width_height_descent\u001b[1;34m(self, s, prop, ismath)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m width, height, descent\n\u001b[0;32m    233\u001b[0m font \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_font(prop)\n\u001b[1;32m--> 234\u001b[0m font\u001b[39m.\u001b[39;49mset_text(s, \u001b[39m0.0\u001b[39;49m, flags\u001b[39m=\u001b[39;49mget_hinting_flag())\n\u001b[0;32m    235\u001b[0m w, h \u001b[39m=\u001b[39m font\u001b[39m.\u001b[39mget_width_height()  \u001b[39m# width and height of unrotated string\u001b[39;00m\n\u001b[0;32m    236\u001b[0m d \u001b[39m=\u001b[39m font\u001b[39m.\u001b[39mget_descent()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHQAAABUCAYAAABTNhMRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyg0lEQVR4nO29Sawm2XXn97tDzN/85jHnysyaJxWpoihKoqaWLEuypVbbRgO24WFn2CvDK6PRCy8MeNOA4Z0XBuxGdwNG25a6pZYEURZbElkskjVmZWbl8Ob5G2OOuNeLeJUqSrT6ESZBspxnle+9+OKLPP97zz3D/5wQ1lrLU/nMiPxhP8BT+f7KU0A/Y/IU0M+YPAX0MyZPAf2MyVNAP2PyFNDPmDwF9DMmTwH9jIm+6IVCOD/I53gq/waxtrzQdU936GdMngL6GZOngH7G5CmgnzH5/z2gSnXwvVUE4m+9TogfD1Vd2Mv9YYuUHtaWWGsAEELj6B7GVhiTYkz+XT/3M93/kpd7bRZ9SCpBbWFcWLbinEXf5WeXDCtBwbDQnBaaWSUoDEQalrwKgNIIQm3IaslhrjAWLOBKyGrYieHtyZATdcBGvcl6ECIFOBLi0hI5go1I0NJQWYgr2IktR1lJx9E805VEGoyFSSmYlJaeK9DCktWCYXHxkvWPHKB/HbhP/QVHz1PVY6ytUapFbQqMmSFQKBVR1/HfuJ9GYmxjijxlmZawFecYa4m04LRQRFpRGElbGwau5axQZLXgvbHDsLDMSsOllstqYGhrgxKQ1AJPWkASOZCJlPl6mctRiACUFBS1pTAGUwpqq3ClpawFaQ2uEighmJU107IBtKUtWoAUgo5jGTiGykLbubh1+JED9K/vNCE0UoZPTJ7rzBG6c8T5MVJoauNSmxQlI0ydYPnO1ZxSUJgILUEBowISU1JSETk+kTYEylBbwVmhqS2MSoErYVZZaguroWLZbxZYUktKA76yCJrdNilgRcxhsEyKGk9J1n0JCIyFjivwFWSm+bnngBICJRyshdUAOo6h+QQoYYm0pbIwqSQn3934fFf5kQP00yKFg5ABdT1BqYiiGiGFgzEFRXmC1j2MyRFCUpvsb4AJMCcjOg5oAbMK5jx4pd/im8MZR6llJZDspi6TShJX4CsYFnCQGBYDSec8n3KUSyoDWkJSWdqOoO9CaaA0lqFJGMoTrtabbLQ0XccSaJBCMiqahVFWn/y/IK4ss9LiKsG0Al81YKtzU20sjErJpBSU5sfY5H5ajC2hbjIkdR3j6AG1SalNiu+t4qiIso6p6gRj0r/xeUcPUELQcSDSBi0FEiiMZNkLmBQ1o0LTDSFSFl9CYQSBElzvSLxzS6ekRQkYFQIlLHNeo/jCCEojAEtfhjhmmY6n6bngqmantXUDuhJQW5iUf/VzxxW0tGDFr2lpQ6gM41KxlylA4EnoOJbhZ2WHQrNLgSe7z3cXCJwBQkiycnR+jUsn2iDOj8mLgyeftRjE+c4MK0lWN78/Si27+Yw3Bl02QoOhcXLa2jCuJKURXOvUrPgFvqppOyVJpXl33KI0MHAb82ssOEKipaQ0LuSwnU9ZzHvMuZYFr0ILzV4qcCR4sjGpJzmcZpZxURFpxcCTLPkltRWMSok8d7hzA4WBxeDi+vqRB9Sc5zCV6iCEJM33SPMdpGwhhEQKFzCMkwcACMQT8F3dYeBpXClIKouvwJOWgSe5XLWZFJa9VNJ1LAZBbhQHqeAkM7xjFH9ZBfS9Rrv7iWHeF6wGMK0kvrQYQAjQovm+oUnYkw9YT15m0VfUVnOYSbSw5zsaxiUMc0OkJb52iEtDaeCs0GgB5jx8cgRUNAsgq//2kOrT8iMDqFIR1lZgDcaWSOHgugsYUyGlRgpNVhziu8so6QLQ96/gEJDaIb7oUtqE0/Q+ab4DQJbv8/V0mxfrda51FJ40lLYJA+6nYy55HRypyI1gwatp6xqJg0XgSsGib4krmJWWK22BI5pdk9UCQ7PrjjM4yy27WUoucm7ZZ3GVYDdpHJ/Hs5zlwMGTn5h1gbGSk8xwmpf4UnGYSmqrWPUNq36zgAvT2PvSCM7KHzMvV6kIIRysrRDSRRqwtiLL955c4zqLBN4KjgzQKkALj7g6IivHJNkWQuhmQXxKPHeJl711vrQEnqyYc0uSWnKUuThoVkKFEo2T4ghLS9cs+4LaOpTWktcQaUuo4HJUseznVLYxyUmtSCrJ1chwVijUacC9mcFVCoEgry2VAU9KAi3oORWuNJwWGl9J5n0JOGR1483WFu7NFHElkcBL/cbkGyuItLqwLn8kAP3O+LHxAJTq4OoORTXB0S1c3UaJ5nGzcoSxFVoFuCpCRzfR0mWSblNVo7+6U3nMXpaR1QErfsGjxONxLPna6ZRDucdhcgNHSnoOTCvFvNecY3cmMClqrIVrHc2Sb0hqydujiNo2CYW2NvjS8MHE4aOR4S+qd6lkRtcuc5gFLIougVbsllOI2zwONNbCWdE4RNbCvC9xpcBXlrXAnMe1zdl8VioexQGehFEJv3VBXf5IAPqJSBmgZEBVNyA6OjoPSQqyYkhtMkJvCd/p4csOaT1ilNz7rgkFaGLar5e/x8nu5/m1uQ2OMkta1XhCoXAojKE0ksrCcS4YlQFZDc904FJoaOuKrK6ZVqoJ8LXBWMGwEBRGsuBC37X4ujnw2izyS71NXu1XzHslxtZsJV2GpeRmq6C0gseJw0Fq2U1qzsqcecfj5TnVZKOUwZGW+zOHowx6bpNZ+h6ilh8dQJWKcHUfYysULYriGC19jK1oecsEqocUDhaDtTW+7GIwtP1N8mpKUU2o68nfuG/HXee2s4IjLS/2LHEteW/oQbZCUtcUtcaR8Ctrp7SDnP1xi7fO2vzfxw7LvoOWjSPV1o3XmlSSUdmo7biQ3B1b3kmOqUVJYEMeTSv2E0nPDSgtnKQVVzuSX1qZMWjHrA277CU+z3Y0d6bhk9ThrhD0XIcbrYplvwYUvmqOgsr+GJ2hQmgifxMtvSfZICkcOnoVJRwOsw+I9AJr5gau1aQiZyiPsBjWuY2nX2LkjqjIGdld9kdffXLvwFvnN9qf57VBzcczwUEmWPAMV9qKr+VbPCOuIASEyrLQm9FaLAB4vta80LVoaclrSdctCJyKrNJ8NG7xfCdnwc9Q0vJT85K70zk+nCzS0nAprNnLJB+NLYuBINIaRwo+GHWYTwNKI5iUmpOiCaNcCdc6liW/pDSCgVsy52fcrDUPpiEHuf7x2qFCOJR1gpYejmoBUJmErclXcHWffnCViD4H8hGxOWWTF5mvV9iV97hb/ikGQ16OEUJirUFK70n6MM13CHWTJfrSQszjxOfBTDGrLLflVRZ8Tajh+W5K2C2xFShpuDIYsXwrxrnZRfgam1WQV8TfGuI/qjiIQ1xVE7klWaXpOzUdR1EYwR/sC2ZlSd/TbM1qHhRnPBvME2nNwC15Zf0Q1684O414+3ieh3GTbjzIHHpOzbTSrOialldwnHlMKkUn/Ot57b9FnxftPvt+c4qE0AihMCbH91aRQpPme7SCK5R1jK+7aBUgzit8jgyJ5ByxOWVWHhI58zgiJBBdakoKm7A//QZldfbkO7Tu8Xrr73HTn+OVgeRaK6cwkvfGDndGNeOyZNH3uNyW/N3LR1x7YwwGjj/wSDOX0kiO4pDTwmXBy7m1dkLvdo3QgtldywcPF9lLfUal4sFMcWdU0HIUC77E0IQ7ArjWFrw+SNHCMK00pRHEleLjWPPxpOb5vmTVr5ECLkcJK+0ZZ0mAp2sCp+TRuMuX//V/dyG9/lB26CchxidhRl4cgLVYLHG2hTE5RXFMK7yKIwOMLalMykn+Ad3gMkves3g2xFBzUj/E2JJA9dlov8lJcY9J/BEAVTViXnR4oS+5HBWU5pPUnaXvKbLaUBjDjZah5RdM7ivSxGWc+NwZdUhqSd+pcaVhL/U5/HiNjYOUrFIc5y4LXsHALRmVTVixGjn0XMGtdkWoDcNCMSwlL3VTbi6cUpaKh6MuB6VHaZvcrSMF01IQtgyOsGS1oqg0LbfkNPU5TEJ2Eu/Cuv2hAGpthRQOSrUpq7PvKJUZkyMQGFs+AWau/TKuiijrlNPptxnrRyxGz1PYlMokCBSn6T2SbOs7vifw1lmPPHqOYTtxOM4lq4HBWjA0gf8zXQ1UnM0Cri6kCFHw9sECh3mjmlGpUMIyLATXogotDF235lJvwjTzOE59uo7hagsOM0law7dGiistyZWwYMmHG4MR3cWU0WGIpwy+MhzmjcVbCiRLvmFaKoSwJLXko2nARlhwuT2jL7PvSbc/tDPU2BLzKfMIn7AC5N9IEOTVhNKkhO7C+XWKyuYM43sE3gI9d5OBc4XUv8owf0Sa72NMTprvsBPnPNd1eb6bspN49NyK3dTFETAfaI4zS0srLpUuDx4O2I4jPpq6TMsmPsxqwbhoqiO1dRiVXW62U5S0nGY+Xbdg4OXcm7YZlZKWtrS0YT+TtJSDAbbHbapaMsk9xoWDKw2+bBIWCYLjXOJKw8Ct8ZVh2c+JK82fHAy4FJYMvOLCev2hO0XwV0BG/iZFNaGqp0T+JsaWODLAURGVSTG2xNMdALTwuNX+VTzrExifVGRkYoIjA5Lz/O9m/xd4fd7nUpjzMPZZ9Qs22jMWfBdo82Am8JWgtpajzKXlFLR1xXqgEYFlL9OA5bC2xJUhr5sieGkk6ytDnn1RgaexccmlD874wzuXMBYiXfPKIOWZG8dYC/fuL3AYR+S1ZM7PqY2gtoIlXzAtFc92p7S8gqM4ZDf1+eqJx3OdmgWvqSbcnYZ84YK6/JEAtDG5jdlt++tM0i3ycozv9oFmR867z1DbknG1gxCSyuakckIhUqzpMk+flnmBOzphdG7Cr5jbtLRFCcvf/3tbZA9KilihT1oseAFZ7XBnYuk4sOwrtmYtHiYud8/D2SutJi14vSOwVqHOE/KONHzweInyoWQn8djLFFsx5LXl1QGsBhkSy/sfLbEdB5wVmnmv4nIr5urGKQBv31+htg2wH05aTR5ZwHGuiDSEujlTx6XClxf3cn9ogH66KgIQBZdxVEBantEO1ujpS0T0ScWEgVnmshxQWctI3qAlXYYmYZ8t5utlNJKu4zCsLI4IcfSAsjpjJMdciUJ+8sYO2YPm7JxOfO6Pupzkmm+cGgpjmfc0jrBEuuJqZBkVHg+mhpNcklRNntVaaDnQcwSPE5+jTBJoWA9Knu1URNrlNBfc7iS8fPOA4IZGSHj2o4pHjwYoaeiEGafHEfeHPQDiWjGrJLc7M7p+zix32U4cjBWMy4YGs5UIihr+vQvq9YcG6KfBlNJDycaTy8sRSnpMxB6ZnDArDomdE47rpprSlxsM0eQypbIZ75S/T1nHXFJvEoo2uZlhzs/gF5x18trw1Xvr/PJv7qNuLhKdzgh+/4CNszarQcQHE4/SWOa9kudWj6kqCSzSdTw+HFtOs5qWo/jpJcurgxEdP6c2ksM4Ylw4jEtFaRRdbchqxYeTAP/eItGjilHu4irDYhSz9lKMCCTx/Zz7wx47qUuoDIUR5LXiLA0YFg7ueZE9VIZn2hlfXMrZj8ML6/WHAqjrLJ57t43ijcnJiiHdYBNHt7C2ZpJuoVXIwL9KX2wwYo/T9D65NyNQfdJ6SGVSlv3nuW6useb7HGclj81b30G5fLY34fabZwjlMP0/9ghvKDrrFTsnku3Exdom8XB35jN9vEpeC7bTJtjvugIhNGdZxZ8eKraTATfbFV2nIqkVx7lmIyjwlOFR7KEFXAoLyvPSV9sp2Y4jHs1C5r/S4yR3WPIL1loxjmxi0iW/QEuLrypq63JaCC5HNT2n4ihz+eYwYlwKfuGCuv2hAFqUR0/+rVQHJX2K8ojj8gjXWSQp95HSw1URUjgM7TZtscgg/DIGg2d9EjXHMfdp2R5t7VCZJgzp6g3OqncBOMhTaisxsWX0EWhXMnnfkswCvn7a5WHcUCuf75a8NH9KXmk+HncYFrAzMwx8SWUsnpIsBoJQQ22bWFYJS0fXJLXkQexybyo4TGty49FzXNYDh1DXzCrJdqpxpOWV+TOsFbx90udKK+FKb0xZK3qdlDh2qazEk4b3Jz7HuY+x8GhmWQ1/RAvcjh5QVcPvMLd1/Z1J9U/AtrYkKU4JnAFrPEtGQk3FjBMq0eUGV7jlXGarPmVYFZyUBk8onuFZev0ltqpv8rb5V/zjx7/B+nGPK2GBEpb9zGEnVeQ1TArDw0lNWjvk9Ty3u1MWg4yVwGXOa+if755ZJmXFa3Mun5ubsNyOiVo5Qlji2EOrmp1hl0uhz6yS+KpgWikcaXjt1h5Iy9FOm243Jc80j077nJWKeNzi/jRiI8woakVVS9KqAX49aKzA7YUzstzhL47mLqzj7xnQv+7M/JtECget+xTl0Xek5Z78XXqE3hqBM3hiSqf5Hi1vGWNLFA6xGDM025QmZeBcoWsGnNqYGVNiOaK0BX3bp7SGj+UdHg5/D4D13s/Qd+FKWPC5S/tMpj7PAEWtuDPq8vUzB1dq1gLLwK2IK4e707ChUaqmbvlzK9DWgqSu+d29Lp7q8GovZ85v8sVZpfhgEnJ3Kkgry5cW4dW5Ed0w42Q/YpJ5PJi2sCeN5l6cP+N31o45PmtxFIfElcbJXTYHY9yk5igJaeua3dRlZ2v5Cd3lovI9A/q9gPnJ9Z/sOiFkw0wwBUp3MXWMMTm1KVDCQeHgyBBXtynqmGlyj7FsYdovY2ioKV0zj2ddtuR9JtUeropQ0uED7nA6+5BB9Azt8AbT5B6FTTnJ4K3a46PZJZa9mkjXxJXirFRMy8Z7zYxg3s/wdE0vcymMw7ujJovccSUdR6IEXI5qjnJJXCtuRzGOU/POwQJXopwXexUPZwGesrSDZgenpcNuHPHFa7v0f9LBphUHf64ZjwOKSmERTCvFi8tjFp5J6Y5S5oYxp+OI0nbYTpq6aN/9AZncT6iTtcmRQuPpTkN2tjl5NUVJDy1dlPAo65jSpJTVjNqkGJOeV0M0YbBGXo4I/DUidwlXBPTEGg4uB4wpqilVnbDR+3Lj/Nicsp6x4ryAYxzO5JAFu4HQksLOqClZk89ShQkWQ9+7jKsi0vKMpIaBZ3ElPEoU0BSTpYCiNuynBf/ZjZgbz55iK7D3BMWow+fnBIe54ttnNXFVM/A0NzqSm+2SJT9Ha8P89ZSff26b/NiSDF2uLzWksc5mga1geaXiRjIm2zfMvmmYDj3eOVhgzs+JS42nDJeihKNJi92vdViMYoZpgCMbNkSkLS926+8Fou8N0Czf49OZxRmfMNs9QOHoFpNP8YA+LUJIouAyvu4xjD/C2ryhWSIpVUAmJwzj+/Sj61wNf5oZp5xlH9Px1inMjJ5ziUKkTOWYI3OfpDim718hkH0u1VcYiSkD5yrG1k8S9EJI7kynRLrNv39tn24/JZ56vHs4z8Okqab4ymNWlox2fVq9nEubZ7T9nKqWnCQBN9sep7nDsp9zc25Iu5MRzlfUORzcafFg2GU5SpjkLlmtmZaak3saJSzXWikdt2B9ZUjv5zp0lrqsSQEzQfG1Xe58Y46Pp23m3AJHGh6Pu7iyppaChSDj2cVT/KDkwcHgBwOo6yw2WZo6wdENq6AJPRTGzCgrCP1NjK0oytMndUnPXQYgTh/R6X2Bpc6rjLNtrDW03CU2xYt41mXSeYFETJ5UULT0kEi08JjVR2jpgYSOWsbzW9S2RONQYfCsR21L9uK3cVSI763yiv8bfGG+w2v9nD/ZW0LtWzxpeZxoRoXgwbSi40g+nIQMgpQ0c3gw6pLUiqyWfO1Uk9VN+PJnxx4vx8v88vohfndKESsejbocZi5vj0Lq82TOrBKsBobTQvLeuMUwt2y/HfDvvOOz4JV0nZLSODxKruPK5uzueTlZrcFAz88pKsW4cCnHbXb3Az6aOnzuBwHoJ2ehowffwcizJkWg0CokKw7BGvhULJgXB2jdA3jCKPhkZx+Md3D6IV3RgN4188zEEaPkIeutN7AYdkZ/QuCt0wsu4dsWpchZsdc5Ebvcnfwuj3Sf0J1H4eHqNtPkHr63yqHc4jAd8MB1uTexdN3mmbZnNV+v38exHn4V0R6v8+u3Yro3KpZPpvzFO+v40vDaQPDuWOEry7M9wbUo49G4y0ff7KOE5azQLPolm1HGSe7yIHbxrSWpBQuexRGCpBL81qbHz6wcIYTlraN5jnNFZgT7iWA1dJn3XK7MDwGQ0uK4NeFZxP1RF4Hlpe7FqfMXBtR1FtHKJz0HMvDWsRja3ipZNWaa3MNRIS1vmeHs/SfAf+LZVtXoSeNRXU+Q0sPRXTrBZY7i99k336AXXsWXHSb5LmV1xuPJn+LqDv3WcziqxcH4Lxm5j1kIb7Odfe38WQxarTJOH1FVI7TuNX0w5ZBH4z9i196i6wYI0TgWrhR4SjLKt3FlC1dc4cWe4d3tRbw9w7BwCJRhUmkOc0VRw7IPpYX3Jz4tbRmXgpvtAkda/vlOwKgw7GYJkpK2cpnzNUuBJKstcWn5eCYZby3hSPClRQhY9GoEioczWPACAl3hSIOShsgvOIzD8xxwyVqUfP8BraohVQVKtbAY0nwHz11mmu8hhW4ah2xFUpwgZIDvDrDWUNdTfG8FYysEkn5wlWmxj7HleZmrQEqXhdZzBKLP9vRfP1kES+2X8UXnSU73xc5/gSMk7/NtjK2I/E0CZ8Awuf+EvvlpGifAyCbcGytem3fxFaz6FQu+wlO/gpaC/aTkl69vs/AljU1Lhm9bilyTZg7BWZ9lT3F0zuv5net7rDyfYCtLcSYIrkj+7cyQ78PoOOBoEnHzmT2CGw0RvDopOPow5MFpj4Gfk1WKs9xjVDZAXQoNK77P55aOWVydkYwdpjOfk2mIsYJfvL5De7VAfQ+JhQtTULqt54mceab5PnH6EIT4Lj2cTdxpbYXFIkTT01mUR2jdw1Et2v4anmyxN/k61ub47hJlNWOh9Txz4hJTjjjJ7pHk+wghMSYn8jeZ929QU2FtjRQOcXWMEJK2WkYLj7PyIaGewxMtJvUBZT2jqGN+PvgdXuh7/Fef+5jWpqEcW+7fmWOY+7w1DNmawSsDw68/94j+r8/DxhKMJlR/uQUGTt93mMUeV76cIVfaICV2mlE+mJIfCaZDj+EspKgVpZGs9SbEqcf7wx6XWzHLvSndpYzw831Yn4e8wG6dYsY50/dq3nm4zI3FMwZXM6opDA9Clp5P0SsB4ovPY9stxMER4gv/9fcXUM9doxdeaUKB/BBjZrSCa5R1jBSaJNuiFVzF1RFJcYqvuwghmaTbTzJBrjOPqzsEzoBxuoUQkrIaY0yK6yzSDTaZZDvUJkMgkdJlLXodnxaFSDnJ76JVwCTdYhDe4Cz5GM/p4qoIS81odgepIoLzhiYlNP/p/Jd5tZ+zkzpoAWtBQVwpHGn59sjld092+YXBKq/1S3zVlKyWgpR/sjXg9UHBapCS1RpfVZRGspP47GaavmNoacNBpnFl0y7oK8u9qaQ47y7rNRsVV8KlsKLnVHTdgpZbsh+HTCtNXgtud6cA5Ebx8huHuG+uwTAm+doIFYEtIPhH/8v3F1ClWnjOArUpcHRIWSVo5VObgtCdQ8uA48lbCAS+t0ZWHBD5m5R1Ql4c0Ilu0nFWSOpThrMPsbZ6wo4XQpLl+wjpIoRDVY1wnUVCd45ptkVdx/Si2/TcTXI7Y5g+RCDp+hsA1LbkZPKNc6ugGbSeZ0U/R9t0+aXFeQSWm+2K7bQBAuBhrDjJDMdZxWbL4VrL0nGatnslLIGyONLiS4NzXo/cSV0EDU/XV+YJl+iskAwLuDsueXXOwVNN6+GibylM07bfdxsaS1vDZlhwnDtPgL8a5WRG0tYVbzy/i7csEa6gOq359ttLXF89Ze5/+58vBOj3MElMk5enRP56o0STUZsYJSOsNayrF5jvX2VsD5BIJjoiL8eU1RilOgzcy4T0QYHuvEZtckbJAwK3j7WGrDimF95gmu3RDm+Q5IdM0kcoGaDdNlo1PXWVybkRfpnAhhyLbQI6SBTPdt9kJmK2zLepTMpW8RaeavO54u/wWr/mD/YVl1rgS8HDmeDdcUxmC1rCYz10+Mn5MfPthJNpSNsreDDuUFlBqBpqZdPraVDCPmG5h6ppkfjmmeR6B3pOQzkJlCUILJURzU4ODM/2JpxlHlmt6HkFgTJU9q/OxmudKZPcJT5zqYuK1ksOMjF0vJw8u3gwcuErI38dJTRSOOTnLHWlIqp6TFpK3s3/d0JvCWNKWu4S1hpCd45u9BKjYotZfcyMY4o6JnLmkVKy0flJaiqG2UOMSZlmexhb4Ok2vu4SF0e0vBWU0BR1TGVzPNni4/QrDPyr1LYktUMG8hKxSNm279FSi8w4Yjh5i8v9XyKr4f2JIq3qc9NpuN215Cbkn4y/wgt8kQdT+MK8xNSCaemipWExyPh42qLvlkRORuSUVLXEcyr2ZxG+qun5OVvTFr+62gD75ycOuYEtK/hwOua1XpdLLUlmBHGpcaThtHDxq4Z4lhtJVkseJ5rD3GHFL/ja1go3+yOkmnC01yL0StrzFyeKXRhQY0p6/iYWwzD+CM9dPu+cjqnqKUoG1CbHkQGVbdrkk+L0SeHalx0yM2Ga3KN0YxwdMaoeU9UJUrjMd14lVHO4ImQ3/gZKuvhOF4C4PGm4QvUpSnhE7iKn6X2KakLoLZGJEX33ClWdsJc+BqAVXCWgy+NZSux5LASKuLLcmUh8JRjmFZfkKySkPNNpMSpcxmcuWloeTFt0nJo5t2BYOBxmDrUVXApzvMIw8HKSShMXDqWRHOaax7GiNJYPJzOe67R4sdPlIK15ODXc6rk4os1p0eSH97Qm0vbJNBVPwmaY46uKSFdEQU4ydjhJQkJd4Q9L2t9vQGfpA2bpA/qt51ju/ASFmbGmXiAWI2b1EaGcw1DiiJDYnBKoPlMkZ7MPAcMo/hApA3x3FU+3SYpjHN1CCo05p3VOih2m2S6BO89K8BLaOlSiIXy15AJSKB6M/iWBt3LuQTdM+7a7yqw+4qr6PDY0bNv3OJ29R+4nvLkYsOhZvj2EF/tNDbPp/1Q8PHJYVh3enB/z4htHqK4ivm85PmjuW5tmR26kHkdpwEnusBo0YEZOyaRwudad8KyuGKU+/2y7x+1OizfmanpuxXHukNWajTCj75bspx4HmWbgNqY7qSXXWwkvXj/E7RryoeTxTh/HMbSXC166dIgtmgLCReXCgF7p/wqWmuPsI4o6RgqHPd5nXb1AIDvsVe8yjD+iH92kNjlKevTdK2y4r1ORc1I/QAmHo+m3SPMdFjqvE6iGBLZoL7PLByjpsdb5HJXNic0pbblI18xTy5KBXeGUXda6P4VCs2gvsy/uo/GYs2uM9QlThvg2QqF5pvOruAQECkJleGUg2E0Va/2C2go8qfj15Tn2UojcEve1Rbi0TOeFM6J390k+NlSF5OHugNJIBl7Omy/tEP7aJVCqyYYtzjXZ+O0D4t/d4XeEZX1pRO9lgZwLsJOc5IMC6Vn8Gz5UhuROyeTU49Fpn8dxwINZyM1Y480VWAMdP0cqg/RBeIIqt/gvd7//gA6Lh0zPicyD6Da1zenqNY7NQ07Su42nq9pM0i0ib6k583TOfv0+Pb3RVF+Aq71fpGcWyUXGlCNm9TGlWuWSfYFK1cSM0cJj2S5ia8sDeZd5u0bHRvS5TWYLTuQh27zHIteZckopCnzbomXa7Mp7KBy6dkAsYmoLPbfip5/dxl+B4sQyPvJ5pufzpwfz7KWCO6MuG3/0iNZvt7HPXkdtLNP+eAd7MOG5B8eovkJf7cGl58B1QCuIE3j3AbQDKCt0G1xdIwSMv205OZVo5dLr1XQuWeSXnsdurhONJ4T/15+zeHrIa7EhP5VYAzIQBEsGtzXDXVWov//z2I0NVFnCwcHfis2n5cJhi+9t8FL466zIHrW1+FKRmZqhSRjLISt2Gee8D+WQM47EIwSSq+Y5NJJDeczA9DmTQzSaeTsgEJqJyXGEIrMF79V/jLWGBe8Woe00YJGi8RBIlswmI3nCcX2f58VPs+FHAOxmCS3pUtqaSDlkpsaXClcJ/sOrBW/c3KP9mk+5lbD3foswLBhNQv7PnQXGheBGu2I9yLk2NyIvNOs3xnhXPKqjnOF9DyktQadkfOLz9b1FjnKHgVvTc0pGpcOt7gRPVySFw7R0GBUuSliOc4eBW9FxmmMj1BUvfeEY5/l5MIby/TOmjxTDYcj67QmqK5l8JBn8UhtubsDJiOwPtpA+eP/9xeLQC+/Q58NfJbQBd+1Djuv7uLbVZHbkETUVpcw5Kj4k0HMUZoYrW/iiw5E8oBApu/E3KKoJtzu/RmgivmW/wjh9xFLrJRwCzsqPaTlLLHENvw64a/8CJRxu8hO4wmHMjLE8oxIlX9C/QGIq/vnsn9F111nnJp5V7IhDHmdfY969QWi6/HzrKi9vHhKsWL72T9vspwushhnFpM3XzlrElWAnNmip+eLKEWFYMJwF7H/cZvq+x1k+z0HmEekaCeSmmR52KWyS5YeZy+3ulNoIPhz2iCvFYa7Iaphzm1h1J3XIYpfO+dia5fdmzMfH1CncvbeAIw2hW1DOQGhD/8ttCF3K332XZEswHkZIYdm4IE4XBrQQBViYN0u0ZZ9t3kOjye2M2lYsiavkzjqJGXFJvgLARJxxUj+krGdcDt9E4RDaFhM5ZjR9QCfYpMsybdPlpnMLgWBL7NG1Hd7UX2ZUp8xEjECySI+OidiVO7zDu7wsX+Tn/d8krityKu6ID5pjIb6LMSWvuL+KBH7/7gbcheNCIYGWrnGkZcVvmpB6TpOMX1if4c4JymLGX+wsM+cWnBUOx7mi41Rc7UyJ/ALPrdg+6fKnx10cCXtJiAHuzVwezeDFnuW3ru1R15KDacTDWUhLG1bDhMCpeHTWRSmD61Ucpz5xrbgUxYzv+7z0K2NEy6P81hGzx5LJKOBgGrHU+u4d6v+fAD00d0nVMj2ziMXwnP0cCkkuNujaAYdiiz6rSOngGg8XzZgTXuQLtF2XXTMksB4FFcssErX+Liuyx7QuKKlQQnJgmxLSA/kB82aTDi0G9JjZlIIaJSSvOTfIasPVjiatYD8RHJlT1s01frbzKmXLcpoXeFKxNav45ZWSl9aPqCrJ2TRknHvspT7P9cacZAHbqUNpYXQYMN9OaQ9ybs3GKGF54fIhVaEI+wU6AukLzu66nOYet9v5OZBeM9+oEDyYJmyEAaM44MbLp6y1E27ehzR2WXilRLiSfGvIu+8tcXlhxBvXd9k/7LK6MsZfMGAdyEpkR2Nqi+tWjAuXBfsDqLbM8n2075ExZpg/wtNtjKlYdV/inv0LfNtBssQ8axyrXRbqNTIz5lQOObAFe/U7JMUpg+A6XbFMKXIqU7MnPuIsvc8guA7Aur3NWBzQp8OMlHfzf8mm/wbaLOBYzU4e01Ue7w0zMltRU9OhzZ7a5sP4q7iyxYK4wtge8Kp4haRW7J+2WejGKGk4zDwqAw+mLc6KporiS8tHx3PE6YyjJGBUuPTcAm9UEQQFZSIZH7mcTSPeOu1xVkgWvJrCCCJlz/tUDJ9bCNmKLd886/LBn3RwZEP3LIzkmfGEykh2kpCWrtk+6ZLViu0k4DgJmNvLWOjN6G4MqVMwtcsfP1ol1IakcL//gH7B/20CodmzZ/T9DYZ2G6kdFs0yfTHPiTxAGc2WfYc18yzPBH2umDf5sNwnZsib+u/QDx12swQHhS8UVoBnXmSq9nmOnyAQmg/EHVbMdSSCBdnm5/zfJtKKs7JgznVxpcSRMCkNTi3pu80chIX8FiNxhRkJH9dv8YL4Is/Pufzi5+7i//QylG3af3TCnWGXJb9kIcjYi0P2M59fWT/lynMjAMKPC/5yb5GHccBZ4bLkZwyCjJMk4DT36DkVk9Ll/bGi4zS9L2+fVCwGmvXIshQ0qb9I1WynLhtBwXprxtrimKpUTEuXtlPQ9gqyOKTjVPzEK3v4tyMwmvidgjt3F3kch+RGsKQrHk1bvHBBnC7s5T47+A+4Ja5yUsd8dfI/cav377Jh10lsTkt4Tduc2CFjRmJO2RQvMpantEyXPe6wyi26tsOB3KdjexyKLXI7Y53bLIseQ5NwIg+5wRVmpmDe8Qm1ajrD8pwxM9pEXI2agnLPbQrI38p36Js+K26IEoK4qtkyxzg4fL67wCv9mmfaMZFTsX2estvsTNmdtjgrHLJa8muvPyS44SJvLWN3zhh/NUEHhnv3FyhqyfvjFtdbKYWRGCvougV3pxFaQM9pCtNzfs6DacT19ozlwZSoV3D343m6fs7iypSqkESrNXvvt8gqTVUrtKq5M+yyGmbcunJMsG4xqeX0Y5/jcYuk0pRGshgl3P6Df/T9BfSX+/8Nm6HPUVbiSclyqEkry0lWMa0LXKFYDjyK2nJc5OS2Ylc9xrMhAvkkZBmYPpHwyGzFvtzlGpdZC11KA8O8Yt+MuOnPsRRIjlLLW/lD+mZAXzb9HX9W/R5L+jZt22eONoktGKgQg0UJgbWQmApPKPqe5t9aq3l96YRL/0kXbl4GY2DnEEYz7GmMzSpE6CBur0Pgw71t7DijPs2gstSxQWhw1kPEc+vQbcPpCM6mmP0Jsutj0xIzbXo41WYPnr+GXVwAYxAHh9iFOchyxMExxCnEGfZkSvV41gzyNSDOqZr11FCcCdpf7MJCp7l2nCL/8//x+wvof7TyD7jcbtjkO7HhURKz5ocs+M340EgLdpMSiWBal+yKfZ5Vm6xHGi2hMnB/UnC57VKYZrBTx1X0XUFhLNuzioXz4UyugqKGuDL0vWay1n5S03EleQ1pbSiNQSLoe00JqzCWrLbcrfa5oZbpuApXCv7bzz9m4Te7sNhrEgLGgOfCwRnlW/sA7L8XsnApJj3VjEYBnU6G36rwNwSy7yGvL0Kv3RSnP9yluB8z2XE5GrY4TEI6TsHl5SGt5RJTws79Hh8Mu3xu/ZDuUoa7KKmnhuOPQ1y3on+rRC34VDspRx+FzG0mBG8MwHeaoUTtAJIcphmzr465+/E8r/3J/3AhQC98hn4jf0xSrbNfzlh321wOI2ZlzaRsZgUUxqKFIDeGjdBnobrcrBjR8HjiqtlBACsBFHXTN7I9M2y0FANfU9TN/NjinIpqLOzMKnqeYlpVHBcVm2FIpJvZtpGWzPmC06wZPOwqyevBGvO+ZFZaSgs7J13yfxzz9kHI66uHLL1RIdsuxaOE4kxQFZJuP2V64HI8avHOWQ/3uIkZ3/2qx6wStB3LG4Mhvqr4cLLMQSbPF5Gg51g6jscfHnY5+UsItKCtLS3H8k/vbhA9MMSV5FY7ozCSSFf81K09bFpRnAkWriXNLnU1zDcpPntvHzsrqA5yQDAI/+bo2P83ufAO/QfP/EM6jmU3gUAJ0triK0HPbT6+5lfnregO+5kk0pazXLAcNNX8UDUen4AndcTTQtLWltKKc4CaWbJ7CbQcwY1WRaRrdlOH7URQnReLIwdauhkUHJ0vya42nJWSObdJAsS15KwQ30HMshZeH0y5sjjECyumI5/dUZvSSL49iihtM5O+NLCfQKBh0W++82pU4UjLQaZ5ZwibrWaYY6QtmRHcHVtKAyuh5HJkKC3sJpK10LDiN3P+HicuJ7nkP761w/KrGbLtUDzKyccSr2vQ/WahJFvw4YMF9tKAb49cXugW/NZb//BCgF68fHYO+4IHo9LyjeG0Sb21FH3X8iDWeJ+aMTjnGlwp+XgK19rNmNDcCHxpOS0U06rZ2cd5A2bbAYllLxEoCa603Jtp0lqhRbNwjIW0FgTKUhjBadqY+q5jOc2bL9+KmyH/mxGs+o1izwrJaQ6hFvzhYYeXMp9IV5wVDrupw70pfGG+YskvOM5dDjLNS33DUS45zCCroO00TcFbSTNuPKmao2IvbRaaFM2060hb2rqm69QMHMVWoplpyYpfESrLvGf4X++u8VPDGWudKeAwy12O7gdc6Y3R2nA6DSmN5CTXnGSWR87FRwpdGND3hgVroUOgG+W/MWgT6ka596cQlwbvfMz2qCjZTzTGWjpuA9hHsSCrLad5xYLvnL9RwbIUSApjyWvB+wkUtWXeFzyaWZYDgScFx5nhwbTxbAMNDyY1VzuaSDeDLT6ZCXSWN9O72g48nsG3chj4ko2oGR8TKEuomg60gSt4f+LScSzPdBowpICsbiZ8JbUkqwXPtGuUaBZ0361xpOLuVD5Z3GcFTEzz9gcl4SwXWDR57TQvBZDwMG5m4V5vJTyOAx7OFN8YtpiWmqPcoaUNL86d0Wrn7B13eDBrEaqaUBnm/Yaz9H0H9HrHQYlGuUcp9DxBnFkWfVgOBGdSMikahS4GDgLBo2lDrOq5gs0IHs7gUsvlOK3Z6ClmVTOwoucKWtqyHlqOc8Ewb+a4h+dF4I4rWAqaJEBuLJ9fVChh2EkEH4xqrrQVR6lhVJZo6bI9M5TGYrDUqeUgsVzrOHQdy7QSPJzBaa6Y9y1Z3ThgCy4c5y6HeQPWR2PD63OCObcirRX3ZprdVFKYZnS4FA1X9zA1PE5jVtyQwyxnmGsCrbjZ1biKJ51jw1IyHkdsJYLlAA5SwVcOmmnWq6HGlT0W0oBJ4XCca9YCQ9tpGquiizNQLg7ovxo1Q4V/trNOqAWHqUFJwWEKfQ924pKzKuODLOXV1mJjPosZCsVa1MZIixCNuVoKFcMC0spyZzahpwKO6ikRPpthyGIgWA0Vo8JymBocKWhFDYvuIIXjTACCuLQs+ophbum4ksIoRnlN31Oc5hUdR1MZS1YbbnUqAmUxVrEUCPqeZHL+wr/VELZTzdWopOtY/sVuyXLg8OFYcJg1jIvKWlYCAMsf7xc4QuIrSdeTvOy1uTvOqK1hvdXwfz8YlgRacqmlaGnLQdHMI1oJOC/pWVZCh+O0wlgY5h4nmeawSHlzXuJLh2W/4EsLBbn5AXSfXZPLKCkQAu6MyibkcJqX2jyeGpYDh03lcJiEtB3QQvBM1GEryZiWlo7T8HjvjEpWQoeW07y35EsLPWoLR6nDetR0hY2K5u0M46JxMj4Zvp/VjZMzqyzD3DSv3wgsIBgVcKWtnzhintTkRpDVgqNMMiktYIi0IambVsJmBE3j4P3c4pTNwZjDcYu9tE+omrc6eOeMP19arraanOpzHcVOohHC8jAW7CcGi6WtXB7NMt5YCHhzSXOQNs+aG/jyYspGe8Yw8/mz4xaBhuWgOZt91YxQn/cVL8+1mHNrNsKMzc6UrNL808fzF56Xe2Ev96n8eMiPxwu9nsqF5SmgnzF5CuhnTJ4C+hmTp4B+xuQpoJ8xeQroZ0yeAvoZk6eAfsbk/wFT3dGk3YW8LgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 96x64 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Due to crushed code df is the DataFrame containing data start from the last saved image by index\n",
    "start_index = 1165\n",
    "# Create a new DataFrame starting from the index where it stopped\n",
    "remaining_data = final_data.iloc[start_index:]\n",
    "# Create a new instance of the SpectrogramDataCreator class\n",
    "spectrogram_data_creator = SpectrogramDataCreator()\n",
    "# Call the create_data method on the remaining data\n",
    "X_spectrogram, y, max_length = spectrogram_data_creator.create_data(remaining_data, save_folder='spectrogram_images_96x64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4d4d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCCDataCreator:\n",
    "    def __init__(self, num_mfcc=30):\n",
    "        self.num_mfcc = num_mfcc\n",
    "        self.max_length = 0\n",
    "\n",
    "    def create_data(self, df):\n",
    "        X_mfcc = []\n",
    "        X_audio = []\n",
    "        sr_list = []\n",
    "        y = []\n",
    "\n",
    "        for i, row in df.iterrows():\n",
    "            audio_path = row['audio_path']\n",
    "            emotion = row['emotions']\n",
    "            mfcc, audio, sr = self._extract_mfcc(audio_path)\n",
    "            X_mfcc.append(mfcc)\n",
    "            X_audio.append(audio)\n",
    "            sr_list.append(sr)\n",
    "\n",
    "            y.append(emotion)\n",
    "            # Update maximum length if needed\n",
    "            if mfcc.shape[1] > self.max_length:\n",
    "                self.max_length = mfcc.shape[1]\n",
    "\n",
    "        # Apply padding or truncation with the computed maximum length\n",
    "        for i in range(len(X_mfcc)):\n",
    "            if X_mfcc[i].shape[1] < self.max_length:\n",
    "                pad_width = self.max_length - X_mfcc[i].shape[1]\n",
    "                X_mfcc[i] = np.pad(X_mfcc[i], pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "            else:\n",
    "                X_mfcc[i] = X_mfcc[i][:, :self.max_length]\n",
    "\n",
    "        X_mfcc = np.array(X_mfcc)\n",
    "        X_audio = np.array(X_audio)\n",
    "        sr_list = np.array(sr_list)\n",
    "        y = np.array(y)\n",
    "\n",
    "        return X_mfcc, X_audio, sr_list, y, self.max_length\n",
    "    \n",
    "    # extract_mfcc function is an internal method\n",
    "    def _extract_mfcc(self, audio_path):\n",
    "        audio, sr = librosa.load(audio_path)\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=self.num_mfcc)\n",
    "        return mfcc, audio, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d34482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history, metric):\n",
    "    train_metric = history.history[metric]\n",
    "    val_metric = history.history['val_' + metric]\n",
    "    \n",
    "    plt.plot(train_metric)\n",
    "    plt.plot(val_metric)\n",
    "    plt.title('Model ' + metric)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53b72f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_early_stopping_callback():\n",
    "    return EarlyStopping(patience=10, monitor=\"val_loss\", mode='min', verbose=1)\n",
    "\n",
    "def create_model_checkpoint_callback(file_name):\n",
    "    return ModelCheckpoint(file_name, save_best_only=True, monitor=\"val_accuracy\")\n",
    "\n",
    "def create_reduce_lr_callback():\n",
    "    return ReduceLROnPlateau(factor=0.1, patience=3, monitor=\"val_accuracy\", min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add266c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self, X, y, dataframe):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.dataframe = dataframe\n",
    "        self.num_classes = len(dataframe['emotions'].unique())\n",
    "        self.class_labels = list(dataframe['emotions'].unique())\n",
    "        self.label_encoder = LabelEncoder()\n",
    "    \n",
    "    def split_data(self, test_size=0.2, val_size=0.1, random_state=42):\n",
    "        # This methods splits the arrays after the mfcc extraction\n",
    "        X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "            self.X, self.y, test_size=test_size, shuffle=True, random_state=random_state)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val, test_size=val_size, random_state=random_state)\n",
    "        \n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "    \n",
    "    def split_dataframe(self, test_size=0.2, val_size=0.1, random_state=42):\n",
    "        # Splitting the data into train, val, test datasets\n",
    "        train_val, test = train_test_split(self.dataframe, test_size=test_size, shuffle=True, random_state=random_state)\n",
    "        train, val = train_test_split(train_val, test_size=val_size, shuffle=True, random_state=random_state)\n",
    "\n",
    "        train = train.reset_index(drop=True)\n",
    "        val = val.reset_index(drop=True)\n",
    "        test = test.reset_index(drop=True)\n",
    "        return train, val, test\n",
    "    \n",
    "    def normalize_data(self, X_train, X):\n",
    "        mean = np.mean(X_train, axis=0)\n",
    "        std = np.std(X_train, axis=0)\n",
    "        X_scaled = (X - mean) / std\n",
    "        return X_scaled\n",
    "    \n",
    "    def modify_channels(self, X):\n",
    "        X_modified = X[..., np.newaxis]\n",
    "        return X_modified\n",
    "    \n",
    "    def encode_labels(self, y_train, y_val, y_test):\n",
    "        y_train_encoded = self.label_encoder.fit_transform(y_train)\n",
    "        y_val_encoded = self.label_encoder.transform(y_val)\n",
    "        y_test_encoded = self.label_encoder.transform(y_test)\n",
    "        return y_train_encoded, y_val_encoded, y_test_encoded\n",
    "    \n",
    "    def one_hot_encode_labels(self, y_encoded):\n",
    "        y_categorical = to_categorical(y_encoded, self.num_classes, dtype='float32')\n",
    "        return y_categorical\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test = self.split_data()\n",
    "        X_train_scaled = self.normalize_data(X_train, X_train)\n",
    "        X_val_scaled = self.normalize_data(X_train, X_val)\n",
    "        X_test_scaled = self.normalize_data(X_train, X_test)\n",
    "        X_train_modified = self.modify_channels(X_train_scaled)\n",
    "        X_val_modified = self.modify_channels(X_val_scaled)\n",
    "        X_test_modified = self.modify_channels(X_test_scaled)\n",
    "        y_train_encoded, y_val_encoded, y_test_encoded = self.encode_labels(y_train, y_val, y_test)\n",
    "        y_train_categorical = self.one_hot_encode_labels(y_train_encoded)\n",
    "        y_val_categorical = self.one_hot_encode_labels(y_val_encoded)\n",
    "        y_test_categorical = self.one_hot_encode_labels(y_test_encoded)\n",
    "        \n",
    "        return X_train_modified, X_val_modified, X_test_modified, y_train_categorical, y_val_categorical, y_test_categorical, self.num_classes, self.class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "238ee0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier:\n",
    "    def __init__(self, model, num_classes, class_labels, dataframe):\n",
    "        self.model = model\n",
    "        self.dataframe = dataframe\n",
    "        self.num_classes = num_classes\n",
    "        self.class_labels = class_labels\n",
    "    \n",
    "    def predict_sample(self, test):\n",
    "\n",
    "        # Randomly choose a sample from X_test_scaled\n",
    "        sample_index  = np.random.choice(self.dataframe.shape[0])\n",
    "        # Get the selected sample\n",
    "        sample = test[sample_index]\n",
    "\n",
    "        prediction = self.model.predict(np.expand_dims(sample, axis=0))\n",
    "        predicted_class = np.argmax(prediction)\n",
    "        predicted_emotion = self.class_labels[predicted_class]\n",
    "        \n",
    "        # Display sample and prediction\n",
    "        print(\"Sample Emotion:\", self.dataframe.iloc[sample_index].emotions)\n",
    "        print(\"Predicted Emotion:\", predicted_emotion)\n",
    "        \n",
    "        # Display sound \n",
    "        audio = ipd.Audio(self.dataframe.iloc[sample_index].audio_path)\n",
    "        display(audio)\n",
    "        \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        loss, accuracy = self.model.evaluate(X_test, y_test)\n",
    "        print(\"Test Loss:\", loss)\n",
    "        print(\"Test Accuracy:\", accuracy)\n",
    "        \n",
    "    def plot_confusion_matrix(self, X_test, y_test, class_labels):\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # Convert y_pred from label-encoded to one-hot encoded format\n",
    "        y_pred_onehot = to_categorical(y_pred, self.num_classes)\n",
    "\n",
    "        # Decode y_pred and y_test back to their original class labels\n",
    "        label_encoder = LabelEncoder()\n",
    "        label_encoder.fit(class_labels)\n",
    "        y_pred_labels = label_encoder.inverse_transform(np.argmax(y_pred_onehot, axis=1))\n",
    "        y_test_labels = label_encoder.inverse_transform(np.argmax(y_test, axis=1))\n",
    " \n",
    "        cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "        plt.xlabel(\"Predicted Emotion\")\n",
    "        plt.ylabel(\"True Emotion\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate row sums for percentage calculation\n",
    "        row_sums = cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "        # Calculate confusion matrix in percentage format\n",
    "        cm_percentage = (cm / row_sums) * 100\n",
    "\n",
    "        # Plot the confusion matrix in percentage format\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm_percentage, annot=True, fmt=\".0f\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "        plt.xlabel(\"Predicted Labels\")\n",
    "        plt.ylabel(\"True Labels\")\n",
    "        plt.title(\"Confusion Matrix (Percentage)\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_metrics(self, history):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cfcf84-9a71-44f5-be04-d4f010472cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_creator = MFCCDataCreator(num_mfcc=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8873401-7492-4074-8c2f-1a31b50bd4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mfcc, X_audio, sr_list, y, max_length = data_creator.create_data(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7dbfd8-daaa-4fff-8ccd-6d71af6f2a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessor(X, y, merged_df)\n",
    "X_train_scaled, X_val_scaled, X_test_scaled, y_train_categorical, y_val_categorical, y_test_categorical, num_classes, class_labels = preprocessor.preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854448fe-25ac-4906-bc4d-2f4071183fb6",
   "metadata": {},
   "source": [
    "### 3x3 kernel model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf72d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train_scaled.shape[1:]\n",
    "\n",
    "# Define the optimizer with an initial learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd15786",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    create_early_stopping_callback(),\n",
    "    create_model_checkpoint_callback(\"best_model_kernel3by3.h5\"),\n",
    "    create_reduce_lr_callback()\n",
    "]\n",
    "\n",
    "history = model.fit(X_train_scaled, \n",
    "                    y_train_categorical, \n",
    "                    batch_size=32, \n",
    "                    epochs=30, \n",
    "                    validation_data=(X_val_scaled, y_val_categorical),\n",
    "                    callbacks=callbacks\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c24e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history, 'accuracy')\n",
    "plot_metrics(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b001931d-ef42-4e39-9334-f503270e3963",
   "metadata": {},
   "source": [
    "### 4x10 kernel model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10df062-7811-4287-b23b-931fdd7ba204",
   "metadata": {},
   "source": [
    "Since the MFCC shape is of a wide rectangle, a rectangular kernel might be more fitted for our model Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefa540c-0d9a-4b5c-9e3e-0acc19e9d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train_scaled.shape[1:]\n",
    "\n",
    "# Define the optimizer with an initial learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Conv2D(32, kernel_size=(4, 10), activation=\"relu\", padding=\"same\")(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Conv2D(32, kernel_size=(4, 10), activation=\"relu\", padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Conv2D(64, kernel_size=(4, 10), activation=\"relu\", padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Conv2D(64, kernel_size=(4, 10), activation=\"relu\", padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de91bee-b8d3-4fff-82f6-c09abe9db6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    create_early_stopping_callback(),\n",
    "    create_model_checkpoint_callback(\"best_model_kernel4by10.h5\"),\n",
    "    create_reduce_lr_callback()\n",
    "]\n",
    "\n",
    "history = model.fit(X_train_scaled, \n",
    "                    y_train_categorical, \n",
    "                    batch_size=32, \n",
    "                    epochs=30, \n",
    "                    validation_data=(X_val_scaled, y_val_categorical),\n",
    "                    callbacks=callbacks\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0bce34-de4a-46f7-888c-a7583076d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history, 'accuracy')\n",
    "plot_metrics(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de4d4b1",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd71468-9554-4056-92f1-81a4a12b5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugmentation:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def shift_pitch(self, audio, sr, semitones):\n",
    "        shifted_audio = librosa.effects.pitch_shift(audio, n_steps=float(semitones), sr=sr)\n",
    "        return shifted_audio\n",
    "    \n",
    "    def time_shift(self, audio, sr, shift_range=5):\n",
    "        shift_samples = np.random.randint(-shift_range, shift_range)*1000\n",
    "        shifted_audio = np.roll(audio, shift=shift_samples)\n",
    "        return shifted_audio\n",
    "    \n",
    "    def time_stretch(self, audio, rate):\n",
    "        stretched_audio = librosa.effects.time_stretch(audio, rate=rate)\n",
    "        return stretched_audio\n",
    "    \n",
    "    def add_noise(self, audio, noise_factor):\n",
    "        noise = np.random.randn(len(audio))\n",
    "        noise_factor = noise_factor *np.random.uniform() * np.amax(audio)\n",
    "        noisy_audio = audio + noise_factor * noise\n",
    "        return noisy_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4742c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = DataAugmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1fcf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a random 75% of the data\n",
    "random_merged_df = merged_df.sample(frac=0.75, random_state=42)\n",
    "random_merged_df.reset_index(drop=True, inplace=True)\n",
    "random_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c103157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe to store augmented data\n",
    "augmented_df = pd.DataFrame(columns=random_merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c9db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output folder to save augmented audio files\n",
    "output_folder = './data/augmented_audio'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad181640",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dd80cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in random_merged_df.iterrows():\n",
    "    audio_path = row['audio_path']\n",
    "    emotion = row['emotions']\n",
    "    \n",
    "    # Load the audio\n",
    "    audio, sr = librosa.load(audio_path, sr=None)\n",
    "    \n",
    "    # Augment the audio using each method in the DataAugmentation class\n",
    "    shifted_audio = augmentor.shift_pitch(audio, sr, semitones=2)\n",
    "    time_shifted_audio = augmentor.time_shift(audio, sr, shift_range=5)\n",
    "    stretched_audio = augmentor.time_stretch(audio, rate=1.2)\n",
    "    noisy_audio = augmentor.add_noise(audio, noise_factor=0.1)\n",
    "    \n",
    "    # Save the augmented audio if needed\n",
    "    output_path = os.path.join(output_folder, f'{emotion}_{idx}.wav')\n",
    "    sf.write(output_path, shifted_audio, sr)\n",
    "    \n",
    "    # Append the augmented data to the augmented_df\n",
    "    augmented_df = pd.concat([augmented_df, \n",
    "                              pd.DataFrame([{\n",
    "                                  'emotions': emotion,\n",
    "                                  'genders': row['genders'],\n",
    "                                  'audio_intensity': row['audio_intensity'],\n",
    "                                  'audio_path': output_path,  # Replace with the actual path if not saving\n",
    "                                  'duration': row['duration'],\n",
    "                                  'dataset': row['dataset']\n",
    "                              }])])\n",
    "\n",
    "augmented_df.to_csv('augmented_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2794e1fd-da0c-4a86-955e-fbcd75ac1619",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('merged_df.csv')\n",
    "augmented_df = pd.read_csv('augmented_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4037c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.concat([merged_df, augmented_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec055674",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d811088e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "tile cannot extend outside image",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\PIL\\ImageFile.py:518\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 518\u001b[0m     fh \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mfileno()\n\u001b[0;32m    519\u001b[0m     fp\u001b[39m.\u001b[39mflush()\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m spectrogram_data_creator \u001b[39m=\u001b[39m SpectrogramDataCreator()\n\u001b[1;32m----> 2\u001b[0m X_spectrogram, y, max_length \u001b[39m=\u001b[39m spectrogram_data_creator\u001b[39m.\u001b[39;49mcreate_data(final_data, save_folder\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mspectrogram_images\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[30], line 27\u001b[0m, in \u001b[0;36mSpectrogramDataCreator.create_data\u001b[1;34m(self, df, save_folder)\u001b[0m\n\u001b[0;32m     25\u001b[0m plt\u001b[39m.\u001b[39maxis(\u001b[39m'\u001b[39m\u001b[39moff\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# Remove axis ticks and labels\u001b[39;00m\n\u001b[0;32m     26\u001b[0m plt\u001b[39m.\u001b[39msubplots_adjust(left\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, right\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, top\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, bottom\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)  \u001b[39m# Remove unnecessary margins\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m plt\u001b[39m.\u001b[39;49msavefig(filepath, bbox_inches\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtight\u001b[39;49m\u001b[39m'\u001b[39;49m, pad_inches\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)  \u001b[39m# Save the image without extra padding\u001b[39;00m\n\u001b[0;32m     28\u001b[0m plt\u001b[39m.\u001b[39mclose()\n\u001b[0;32m     30\u001b[0m \u001b[39m# Update maximum length if needed\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\pyplot.py:996\u001b[0m, in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[39m.\u001b[39msavefig)\n\u001b[0;32m    994\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msavefig\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    995\u001b[0m     fig \u001b[39m=\u001b[39m gcf()\n\u001b[1;32m--> 996\u001b[0m     res \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39;49msavefig(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    997\u001b[0m     fig\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mdraw_idle()  \u001b[39m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[0;32m    998\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\figure.py:3328\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3324\u001b[0m     \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes:\n\u001b[0;32m   3325\u001b[0m         stack\u001b[39m.\u001b[39menter_context(\n\u001b[0;32m   3326\u001b[0m             ax\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39m_cm_set(facecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m, edgecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m-> 3328\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(fname, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\backend_bases.py:2362\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2358\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2359\u001b[0m     \u001b[39m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2360\u001b[0m     \u001b[39m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2361\u001b[0m     \u001b[39mwith\u001b[39;00m cbook\u001b[39m.\u001b[39m_setattr_cm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, dpi\u001b[39m=\u001b[39mdpi):\n\u001b[1;32m-> 2362\u001b[0m         result \u001b[39m=\u001b[39m print_method(\n\u001b[0;32m   2363\u001b[0m             filename,\n\u001b[0;32m   2364\u001b[0m             facecolor\u001b[39m=\u001b[39;49mfacecolor,\n\u001b[0;32m   2365\u001b[0m             edgecolor\u001b[39m=\u001b[39;49medgecolor,\n\u001b[0;32m   2366\u001b[0m             orientation\u001b[39m=\u001b[39;49morientation,\n\u001b[0;32m   2367\u001b[0m             bbox_inches_restore\u001b[39m=\u001b[39;49m_bbox_inches_restore,\n\u001b[0;32m   2368\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   2369\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   2370\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\backend_bases.py:2228\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2224\u001b[0m     optional_kws \u001b[39m=\u001b[39m {  \u001b[39m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[0;32m   2225\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdpi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfacecolor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39medgecolor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39morientation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2226\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbbox_inches_restore\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m   2227\u001b[0m     skip \u001b[39m=\u001b[39m optional_kws \u001b[39m-\u001b[39m {\u001b[39m*\u001b[39minspect\u001b[39m.\u001b[39msignature(meth)\u001b[39m.\u001b[39mparameters}\n\u001b[1;32m-> 2228\u001b[0m     print_method \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mwraps(meth)(\u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: meth(\n\u001b[0;32m   2229\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m kwargs\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m k \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m skip}))\n\u001b[0;32m   2230\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m     print_method \u001b[39m=\u001b[39m meth\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\backends\\backend_agg.py:509\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_png\u001b[39m(\u001b[39mself\u001b[39m, filename_or_obj, \u001b[39m*\u001b[39m, metadata\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pil_kwargs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    463\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[39m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[39m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 509\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_print_pil(filename_or_obj, \u001b[39m\"\u001b[39;49m\u001b[39mpng\u001b[39;49m\u001b[39m\"\u001b[39;49m, pil_kwargs, metadata)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\backends\\backend_agg.py:458\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[1;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    457\u001b[0m FigureCanvasAgg\u001b[39m.\u001b[39mdraw(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 458\u001b[0m mpl\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mimsave(\n\u001b[0;32m    459\u001b[0m     filename_or_obj, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuffer_rgba(), \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49mfmt, origin\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mupper\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    460\u001b[0m     dpi\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdpi, metadata\u001b[39m=\u001b[39;49mmetadata, pil_kwargs\u001b[39m=\u001b[39;49mpil_kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\image.py:1687\u001b[0m, in \u001b[0;36mimsave\u001b[1;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m   1685\u001b[0m pil_kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mformat\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mformat\u001b[39m)\n\u001b[0;32m   1686\u001b[0m pil_kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mdpi\u001b[39m\u001b[39m\"\u001b[39m, (dpi, dpi))\n\u001b[1;32m-> 1687\u001b[0m image\u001b[39m.\u001b[39;49msave(fname, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpil_kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\PIL\\Image.py:2431\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2428\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mw+b\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2430\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2431\u001b[0m     save_handler(\u001b[39mself\u001b[39;49m, fp, filename)\n\u001b[0;32m   2432\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   2433\u001b[0m     \u001b[39mif\u001b[39;00m open_fp:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\PIL\\PngImagePlugin.py:1420\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[0;32m   1418\u001b[0m     _write_multiple_frames(im, fp, chunk, rawmode, default_image, append_images)\n\u001b[0;32m   1419\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1420\u001b[0m     ImageFile\u001b[39m.\u001b[39;49m_save(im, _idat(fp, chunk), [(\u001b[39m\"\u001b[39;49m\u001b[39mzip\u001b[39;49m\u001b[39m\"\u001b[39;49m, (\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m) \u001b[39m+\u001b[39;49m im\u001b[39m.\u001b[39;49msize, \u001b[39m0\u001b[39;49m, rawmode)])\n\u001b[0;32m   1422\u001b[0m \u001b[39mif\u001b[39;00m info:\n\u001b[0;32m   1423\u001b[0m     \u001b[39mfor\u001b[39;00m info_chunk \u001b[39min\u001b[39;00m info\u001b[39m.\u001b[39mchunks:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\PIL\\ImageFile.py:522\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    520\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[0;32m    521\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, io\u001b[39m.\u001b[39mUnsupportedOperation) \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m--> 522\u001b[0m     _encode_tile(im, fp, tile, bufsize, \u001b[39mNone\u001b[39;49;00m, exc)\n\u001b[0;32m    523\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(fp, \u001b[39m\"\u001b[39m\u001b[39mflush\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    524\u001b[0m     fp\u001b[39m.\u001b[39mflush()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\PIL\\ImageFile.py:533\u001b[0m, in \u001b[0;36m_encode_tile\u001b[1;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[0;32m    531\u001b[0m encoder \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39m_getencoder(im\u001b[39m.\u001b[39mmode, e, a, im\u001b[39m.\u001b[39mencoderconfig)\n\u001b[0;32m    532\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 533\u001b[0m     encoder\u001b[39m.\u001b[39;49msetimage(im\u001b[39m.\u001b[39;49mim, b)\n\u001b[0;32m    534\u001b[0m     \u001b[39mif\u001b[39;00m encoder\u001b[39m.\u001b[39mpushes_fd:\n\u001b[0;32m    535\u001b[0m         encoder\u001b[39m.\u001b[39msetfd(fp)\n",
      "\u001b[1;31mSystemError\u001b[0m: tile cannot extend outside image"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABQAAAD0CAYAAACbzQaPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAAYUlEQVR4nO3MQQEAAAQEMPTvfEr42QKsk9SlOd2EQqFQKBQKhUKhUCgUCoVCoVAoFAqFQqFQKBQKhUKhUCgUCoVCoVAoFAqFQqFQKBQKhUKhUCgUCoVCoVAoFAqFQuHzcAGi/gTlUKHUzAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 0x224 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spectrogram_data_creator = SpectrogramDataCreator()\n",
    "X_spectrogram, y, max_length = spectrogram_data_creator.create_data(final_data, save_folder='spectrogram_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c673d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9349d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_creator = MFCCDataCreator(num_mfcc=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72cbdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=final_data, x='duration', hue='dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3282c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301971c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mfcc, X_audio, sr_list, y, max_length = data_creator.create_data(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Saving the arrays of mfcc, audio wave, sr, y, max length  #####\n",
    "np.save('X_mfcc.npy', X_mfcc)\n",
    "np.save('X_audio.npy', X_audio)\n",
    "np.save('sr_list.npy', sr_list)\n",
    "np.save('y.npy', y)\n",
    "np.save('max_length.npy', max_length)\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3dbfca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Loading the arrays of mfcc, audio wave, sr, y, max_length #####\n",
    "X_mfcc = np.load('X_mfcc.npy')\n",
    "X_audio = np.load('X_audio.npy', allow_pickle=True)\n",
    "sr_list = np.load('sr_list.npy')\n",
    "y = np.load('y.npy')\n",
    "max_length = np.load('max_length.npy')\n",
    "######################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd8131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad41f8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64eba653",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessor(X_mfcc, y, final_data)\n",
    "X_train_scaled, X_val_scaled, X_test_scaled, y_train_categorical, y_val_categorical, y_test_categorical, num_classes, class_labels = preprocessor.preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89a08d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train , val, test datasets\n",
    "train, val, test = preprocessor.split_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ada0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a66c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e2cfa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ce1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train_scaled.shape[1:]\n",
    "\n",
    "# Define the optimizer with an initial learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a148de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    create_early_stopping_callback(),\n",
    "    create_model_checkpoint_callback(\"best_model_kernel3by3_augmentation.h5\"),\n",
    "    create_reduce_lr_callback()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, \n",
    "                    y_train_categorical, \n",
    "                    batch_size=32, \n",
    "                    epochs=50, \n",
    "                    validation_data=(X_val_scaled, y_val_categorical),\n",
    "                    callbacks=callbacks\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_classifier = EmotionClassifier(model, num_classes, class_labels, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f6ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_classifier.predict_sample(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671c2b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_classifier.evaluate(X_test_scaled, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6503d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_classifier.plot_confusion_matrix(X_test_scaled, y_test_categorical, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab79d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_classifier.plot_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce6ec3",
   "metadata": {},
   "source": [
    "## Transfer learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ba1dbc",
   "metadata": {},
   "source": [
    "### Creating and sorting images to training, validation, test directories and to the 7 unique classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3452934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the data directory name\n",
    "data_directory = 'spectrogram_images_96x64'    #   'spectrogram_images'\n",
    "\n",
    "train_dir = os.path.join(data_directory, 'train\\\\')\n",
    "val_dir = os.path.join(data_directory, 'validation\\\\')\n",
    "test_dir = os.path.join(data_directory, 'test\\\\')\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8b472b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all image files\n",
    "image_files = [f for f in os.listdir(data_directory) if f.endswith('.png')]\n",
    "\n",
    "# Shuffle the image files randomly\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# Split ratio (adjust as needed)\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of images for each split\n",
    "num_train = int(train_ratio * len(image_files))\n",
    "num_val = int(val_ratio * len(image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move images to the train directory\n",
    "for file in image_files[:num_train]:\n",
    "    src = os.path.join(data_directory, file)\n",
    "    dst = os.path.join(train_dir, file)\n",
    "    move(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a091831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move images to the validation directory\n",
    "for file in image_files[num_train:num_train+num_val]:\n",
    "    src = os.path.join(data_directory, file)\n",
    "    dst = os.path.join(val_dir, file)\n",
    "    move(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81ad3d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move images to the test directory\n",
    "for file in image_files[num_train+num_val:]:\n",
    "    src = os.path.join(data_directory, file)\n",
    "    dst = os.path.join(test_dir, file)\n",
    "    move(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41c8d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of emotions\n",
    "emotions = [\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprised\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "710a488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectories for each emotion in the train and validation directories\n",
    "train_dir = os.path.join(data_directory, \"train\")\n",
    "val_dir = os.path.join(data_directory, \"validation\")\n",
    "test_dir = os.path.join(data_directory, \"test\")\n",
    "for emotion in emotions:\n",
    "    train_emotion_dir = os.path.join(train_dir, emotion)\n",
    "    val_emotion_dir = os.path.join(val_dir, emotion)\n",
    "    test_emotion_dir = os.path.join(test_dir, emotion)\n",
    "    os.makedirs(train_emotion_dir, exist_ok=True)\n",
    "    os.makedirs(val_emotion_dir, exist_ok=True)\n",
    "    os.makedirs(test_emotion_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5de102e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_images(directory, emotions):\n",
    "    for subdir in directory:\n",
    "        subdir_path = os.path.join(data_directory, subdir)\n",
    "        for emotion in emotions:\n",
    "            destination_dir = os.path.join(subdir_path, emotion)\n",
    "            os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "        search_pattern = os.path.join(subdir_path, '*.png')\n",
    "        image_files = glob.glob(search_pattern)\n",
    "\n",
    "        for image_path in image_files:\n",
    "            filename = os.path.basename(image_path)\n",
    "            emotion = filename.split('.')[0].split('_')[-1]\n",
    "            if emotion in emotions:\n",
    "                destination_dir = os.path.join(subdir_path, emotion)\n",
    "                shutil.move(image_path, destination_dir)\n",
    "\n",
    "\n",
    "organize_images(['train', 'validation', 'test'], emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39819aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42799041",
   "metadata": {},
   "source": [
    "### Creating the data generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f8a79147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10705 images belonging to 7 classes.\n",
      "Found 2293 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image data generator for training data\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Image data generator for validation data\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a84a00a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2295 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image data generator for validation data\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdce642a",
   "metadata": {},
   "source": [
    "### MobileNetV2 transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8194ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_classes):\n",
    "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "    # Freeze the pre-trained layers\n",
    "    # fine_tune_layers = 2  # Choose the number of layers to fine-tune\n",
    "    for layer in base_model.layers:     #[:-fine_tune_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    # x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.6)(x)\n",
    "    # x = Dense(512, activation='relu')(x)\n",
    "    # x = Dropout(0.3)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def compile_model(model, learning_rate=0.001):\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "input_shape = (224, 224, 3)  # Shape of your spectrogram images\n",
    "num_classes = 7  # Number of emotion classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c62222f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    create_early_stopping_callback(),\n",
    "    create_model_checkpoint_callback(\"transferLearning_mobilenet_melspec.h5\"),\n",
    "    create_reduce_lr_callback()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f0ed596a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_41 (InputLayer)       [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)              (None, 112, 112, 32)         864       ['input_41[0][0]']            \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalizati  (None, 112, 112, 32)         128       ['Conv1[0][0]']               \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)           (None, 112, 112, 32)         0         ['bn_Conv1[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (D  (None, 112, 112, 32)         288       ['Conv1_relu[0][0]']          \n",
      " epthwiseConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN  (None, 112, 112, 32)         128       ['expanded_conv_depthwise[0][0\n",
      "  (BatchNormalization)                                              ]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_re  (None, 112, 112, 32)         0         ['expanded_conv_depthwise_BN[0\n",
      " lu (ReLU)                                                          ][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_project (Con  (None, 112, 112, 16)         512       ['expanded_conv_depthwise_relu\n",
      " v2D)                                                               [0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (  (None, 112, 112, 16)         64        ['expanded_conv_project[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)     (None, 112, 112, 96)         1536      ['expanded_conv_project_BN[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNo  (None, 112, 112, 96)         384       ['block_1_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)  (None, 112, 112, 96)         0         ['block_1_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D  (None, 113, 113, 96)         0         ['block_1_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_1_depthwise (Depthwi  (None, 56, 56, 96)           864       ['block_1_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (Batc  (None, 56, 56, 96)           384       ['block_1_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (Re  (None, 56, 56, 96)           0         ['block_1_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)    (None, 56, 56, 24)           2304      ['block_1_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchN  (None, 56, 56, 24)           96        ['block_1_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)     (None, 56, 56, 144)          3456      ['block_1_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNo  (None, 56, 56, 144)          576       ['block_2_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)  (None, 56, 56, 144)          0         ['block_2_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_depthwise (Depthwi  (None, 56, 56, 144)          1296      ['block_2_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (Batc  (None, 56, 56, 144)          576       ['block_2_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (Re  (None, 56, 56, 144)          0         ['block_2_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)    (None, 56, 56, 24)           3456      ['block_2_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchN  (None, 56, 56, 24)           96        ['block_2_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_add (Add)           (None, 56, 56, 24)           0         ['block_1_project_BN[0][0]',  \n",
      "                                                                     'block_2_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)     (None, 56, 56, 144)          3456      ['block_2_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNo  (None, 56, 56, 144)          576       ['block_3_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)  (None, 56, 56, 144)          0         ['block_3_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D  (None, 57, 57, 144)          0         ['block_3_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_3_depthwise (Depthwi  (None, 28, 28, 144)          1296      ['block_3_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (Batc  (None, 28, 28, 144)          576       ['block_3_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (Re  (None, 28, 28, 144)          0         ['block_3_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)    (None, 28, 28, 32)           4608      ['block_3_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_3_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_3_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_4_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_4_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_depthwise (Depthwi  (None, 28, 28, 192)          1728      ['block_4_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (Batc  (None, 28, 28, 192)          768       ['block_4_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (Re  (None, 28, 28, 192)          0         ['block_4_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)    (None, 28, 28, 32)           6144      ['block_4_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_4_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_add (Add)           (None, 28, 28, 32)           0         ['block_3_project_BN[0][0]',  \n",
      "                                                                     'block_4_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_4_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_5_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_5_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_depthwise (Depthwi  (None, 28, 28, 192)          1728      ['block_5_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (Batc  (None, 28, 28, 192)          768       ['block_5_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (Re  (None, 28, 28, 192)          0         ['block_5_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)    (None, 28, 28, 32)           6144      ['block_5_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_5_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_5_add (Add)           (None, 28, 28, 32)           0         ['block_4_add[0][0]',         \n",
      "                                                                     'block_5_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_5_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_6_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_6_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D  (None, 29, 29, 192)          0         ['block_6_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_6_depthwise (Depthwi  (None, 14, 14, 192)          1728      ['block_6_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (Batc  (None, 14, 14, 192)          768       ['block_6_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (Re  (None, 14, 14, 192)          0         ['block_6_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)    (None, 14, 14, 64)           12288     ['block_6_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_6_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_6_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_7_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_7_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_7_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_7_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_7_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_7_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_7_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_add (Add)           (None, 14, 14, 64)           0         ['block_6_project_BN[0][0]',  \n",
      "                                                                     'block_7_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_7_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_8_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_8_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_8_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_8_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_8_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_8_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_8_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_8_add (Add)           (None, 14, 14, 64)           0         ['block_7_add[0][0]',         \n",
      "                                                                     'block_8_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_8_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_9_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_9_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_9_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_9_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_9_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_9_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_9_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_9_add (Add)           (None, 14, 14, 64)           0         ['block_8_add[0][0]',         \n",
      "                                                                     'block_9_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)    (None, 14, 14, 384)          24576     ['block_9_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchN  (None, 14, 14, 384)          1536      ['block_10_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU  (None, 14, 14, 384)          0         ['block_10_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_10_depthwise (Depthw  (None, 14, 14, 384)          3456      ['block_10_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (Bat  (None, 14, 14, 384)          1536      ['block_10_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (R  (None, 14, 14, 384)          0         ['block_10_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)   (None, 14, 14, 96)           36864     ['block_10_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_10_project_BN (Batch  (None, 14, 14, 96)           384       ['block_10_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_10_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_11_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_11_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_11_depthwise (Depthw  (None, 14, 14, 576)          5184      ['block_11_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (Bat  (None, 14, 14, 576)          2304      ['block_11_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (R  (None, 14, 14, 576)          0         ['block_11_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)   (None, 14, 14, 96)           55296     ['block_11_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_11_project_BN (Batch  (None, 14, 14, 96)           384       ['block_11_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_add (Add)          (None, 14, 14, 96)           0         ['block_10_project_BN[0][0]', \n",
      "                                                                     'block_11_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_11_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_12_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_12_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_12_depthwise (Depthw  (None, 14, 14, 576)          5184      ['block_12_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (Bat  (None, 14, 14, 576)          2304      ['block_12_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (R  (None, 14, 14, 576)          0         ['block_12_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)   (None, 14, 14, 96)           55296     ['block_12_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_12_project_BN (Batch  (None, 14, 14, 96)           384       ['block_12_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_12_add (Add)          (None, 14, 14, 96)           0         ['block_11_add[0][0]',        \n",
      "                                                                     'block_12_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_12_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_13_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_13_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2  (None, 15, 15, 576)          0         ['block_13_expand_relu[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block_13_depthwise (Depthw  (None, 7, 7, 576)            5184      ['block_13_pad[0][0]']        \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (Bat  (None, 7, 7, 576)            2304      ['block_13_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (R  (None, 7, 7, 576)            0         ['block_13_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)   (None, 7, 7, 160)            92160     ['block_13_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_13_project_BN (Batch  (None, 7, 7, 160)            640       ['block_13_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_13_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_14_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_14_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_14_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_14_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_14_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_14_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)   (None, 7, 7, 160)            153600    ['block_14_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_14_project_BN (Batch  (None, 7, 7, 160)            640       ['block_14_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_add (Add)          (None, 7, 7, 160)            0         ['block_13_project_BN[0][0]', \n",
      "                                                                     'block_14_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_14_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_15_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_15_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_15_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_15_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_15_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_15_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)   (None, 7, 7, 160)            153600    ['block_15_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_15_project_BN (Batch  (None, 7, 7, 160)            640       ['block_15_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_15_add (Add)          (None, 7, 7, 160)            0         ['block_14_add[0][0]',        \n",
      "                                                                     'block_15_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_15_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_16_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_16_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_16_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_16_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_16_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_16_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)   (None, 7, 7, 320)            307200    ['block_16_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_16_project_BN (Batch  (None, 7, 7, 320)            1280      ['block_16_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)             (None, 7, 7, 1280)           409600    ['block_16_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalizat  (None, 7, 7, 1280)           5120      ['Conv_1[0][0]']              \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " out_relu (ReLU)             (None, 7, 7, 1280)           0         ['Conv_1_bn[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_11 (Flatten)        (None, 62720)                0         ['out_relu[0][0]']            \n",
      "                                                                                                  \n",
      " dense_42 (Dense)            (None, 1024)                 6422630   ['flatten_11[0][0]']          \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)        (None, 1024)                 0         ['dense_42[0][0]']            \n",
      "                                                                                                  \n",
      " dense_43 (Dense)            (None, 7)                    7175      ['dropout_15[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66491463 (253.64 MB)\n",
      "Trainable params: 64233479 (245.03 MB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build and compile the model\n",
    "model = build_model(input_shape, num_classes)\n",
    "compile_model(model)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77680f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "51c9dd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "335/335 [==============================] - 796s 2s/step - loss: 5.4208 - accuracy: 0.3538 - val_loss: 1.2522 - val_accuracy: 0.4741 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "335/335 [==============================] - 776s 2s/step - loss: 1.4510 - accuracy: 0.4062 - val_loss: 1.1939 - val_accuracy: 0.5111 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "335/335 [==============================] - 751s 2s/step - loss: 1.3922 - accuracy: 0.4280 - val_loss: 1.1754 - val_accuracy: 0.5150 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "335/335 [==============================] - 703s 2s/step - loss: 1.3546 - accuracy: 0.4457 - val_loss: 1.1458 - val_accuracy: 0.5312 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "335/335 [==============================] - 641s 2s/step - loss: 1.3388 - accuracy: 0.4459 - val_loss: 1.1912 - val_accuracy: 0.5294 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "335/335 [==============================] - 646s 2s/step - loss: 1.3201 - accuracy: 0.4523 - val_loss: 1.1898 - val_accuracy: 0.5325 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "188/335 [===============>..............] - ETA: 4:14 - loss: 1.3046 - accuracy: 0.4556"
     ]
    }
   ],
   "source": [
    "# Train the model using the data generator\n",
    "history = model.fit(train_generator, validation_data=val_generator, batch_size=32, callbacks=callbacks, epochs=30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf18964",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49msave(\u001b[39m'\u001b[39;49m\u001b[39msaved_model\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3000\u001b[0m, in \u001b[0;36mModel.save\u001b[1;34m(self, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[0;32m   2946\u001b[0m \u001b[39m@traceback_utils\u001b[39m\u001b[39m.\u001b[39mfilter_traceback\n\u001b[0;32m   2947\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave\u001b[39m(\u001b[39mself\u001b[39m, filepath, overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, save_format\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   2948\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Saves a model as a TensorFlow SavedModel or HDF5 file.\u001b[39;00m\n\u001b[0;32m   2949\u001b[0m \n\u001b[0;32m   2950\u001b[0m \u001b[39m    See the [Serialization and Saving guide](\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2998\u001b[0m \u001b[39m    Note that `model.save()` is an alias for `tf.keras.models.save_model()`.\u001b[39;00m\n\u001b[0;32m   2999\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3000\u001b[0m     saving_api\u001b[39m.\u001b[39;49msave_model(\n\u001b[0;32m   3001\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3002\u001b[0m         filepath\u001b[39m=\u001b[39;49mfilepath,\n\u001b[0;32m   3003\u001b[0m         overwrite\u001b[39m=\u001b[39;49moverwrite,\n\u001b[0;32m   3004\u001b[0m         save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[0;32m   3005\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   3006\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\saving_api.py:149\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m     saving_lib\u001b[39m.\u001b[39msave_model(model, filepath)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39m# Legacy case\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39;49msave_model(\n\u001b[0;32m    150\u001b[0m         model,\n\u001b[0;32m    151\u001b[0m         filepath,\n\u001b[0;32m    152\u001b[0m         overwrite\u001b[39m=\u001b[39;49moverwrite,\n\u001b[0;32m    153\u001b[0m         save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[0;32m    154\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    155\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\legacy\\save.py:168\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mwith\u001b[39;00m serialization\u001b[39m.\u001b[39mSharedObjectSavingScope():\n\u001b[0;32m    165\u001b[0m     \u001b[39mwith\u001b[39;00m keras_option_scope(\n\u001b[0;32m    166\u001b[0m         save_traces\u001b[39m=\u001b[39msave_traces, in_tf_saved_model_scope\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     ):\n\u001b[1;32m--> 168\u001b[0m         saved_model_save\u001b[39m.\u001b[39;49msave(\n\u001b[0;32m    169\u001b[0m             model,\n\u001b[0;32m    170\u001b[0m             filepath,\n\u001b[0;32m    171\u001b[0m             overwrite,\n\u001b[0;32m    172\u001b[0m             include_optimizer,\n\u001b[0;32m    173\u001b[0m             signatures,\n\u001b[0;32m    174\u001b[0m             options,\n\u001b[0;32m    175\u001b[0m             save_traces,\n\u001b[0;32m    176\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\save.py:98\u001b[0m, in \u001b[0;36msave\u001b[1;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mwith\u001b[39;00m backend\u001b[39m.\u001b[39mdeprecated_internal_learning_phase_scope(\u001b[39m0\u001b[39m):\n\u001b[0;32m     97\u001b[0m     \u001b[39mwith\u001b[39;00m utils\u001b[39m.\u001b[39mkeras_option_scope(save_traces):\n\u001b[1;32m---> 98\u001b[0m         saved_nodes, node_paths \u001b[39m=\u001b[39m save_lib\u001b[39m.\u001b[39;49msave_and_return_nodes(\n\u001b[0;32m     99\u001b[0m             model, filepath, signatures, options\n\u001b[0;32m    100\u001b[0m         )\n\u001b[0;32m    102\u001b[0m     \u001b[39m# Save all metadata to a separate file in the SavedModel directory.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     metadata \u001b[39m=\u001b[39m generate_keras_metadata(saved_nodes, node_paths)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\saved_model\\save.py:1313\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[1;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[0;32m   1309\u001b[0m saved_model \u001b[39m=\u001b[39m saved_model_pb2\u001b[39m.\u001b[39mSavedModel()\n\u001b[0;32m   1310\u001b[0m meta_graph_def \u001b[39m=\u001b[39m saved_model\u001b[39m.\u001b[39mmeta_graphs\u001b[39m.\u001b[39madd()\n\u001b[0;32m   1312\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[39m=\u001b[39m (\n\u001b[1;32m-> 1313\u001b[0m     _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[0;32m   1314\u001b[0m saved_model\u001b[39m.\u001b[39msaved_model_schema_version \u001b[39m=\u001b[39m (\n\u001b[0;32m   1315\u001b[0m     constants\u001b[39m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[0;32m   1317\u001b[0m \u001b[39m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[39m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\saved_model\\save.py:1493\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   1466\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[0;32m   1467\u001b[0m \n\u001b[0;32m   1468\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1489\u001b[0m \u001b[39m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[0;32m   1490\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1492\u001b[0m \u001b[39mwith\u001b[39;00m save_context\u001b[39m.\u001b[39msave_context(options):\n\u001b[1;32m-> 1493\u001b[0m   \u001b[39mreturn\u001b[39;00m _build_meta_graph_impl(obj, signatures, options, meta_graph_def)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\saved_model\\save.py:1424\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   1422\u001b[0m augmented_graph_view \u001b[39m=\u001b[39m _AugmentedGraphView(obj)\n\u001b[0;32m   1423\u001b[0m \u001b[39mif\u001b[39;00m signatures \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1424\u001b[0m   signatures \u001b[39m=\u001b[39m signature_serialization\u001b[39m.\u001b[39;49mfind_function_to_export(\n\u001b[0;32m   1425\u001b[0m       augmented_graph_view)\n\u001b[0;32m   1427\u001b[0m signatures, wrapped_functions, defaults \u001b[39m=\u001b[39m (\n\u001b[0;32m   1428\u001b[0m     signature_serialization\u001b[39m.\u001b[39mcanonicalize_signatures(signatures)\n\u001b[0;32m   1429\u001b[0m )\n\u001b[0;32m   1430\u001b[0m signature_serialization\u001b[39m.\u001b[39mvalidate_augmented_graph_view(augmented_graph_view)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\saved_model\\signature_serialization.py:104\u001b[0m, in \u001b[0;36mfind_function_to_export\u001b[1;34m(saveable_view)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39m# TODO(b/205014194): Discuss removing this behaviour. It can lead to WTFs when\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39m# a user decides to annotate more functions with tf.function and suddenly\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[39m# serving that model way later in the process stops working.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m possible_signatures \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 104\u001b[0m \u001b[39mfor\u001b[39;00m name, child \u001b[39min\u001b[39;00m children:\n\u001b[0;32m    105\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(child, (def_function\u001b[39m.\u001b[39mFunction, defun\u001b[39m.\u001b[39mConcreteFunction)):\n\u001b[0;32m    106\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\saved_model\\save.py:180\u001b[0m, in \u001b[0;36m_AugmentedGraphView.list_children\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_children_cache:\n\u001b[0;32m    178\u001b[0m   children \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_children_cache[obj] \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 180\u001b[0m   \u001b[39mfor\u001b[39;00m name, child \u001b[39min\u001b[39;00m \u001b[39msuper\u001b[39;49m(_AugmentedGraphView, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlist_children(\n\u001b[0;32m    181\u001b[0m       obj,\n\u001b[0;32m    182\u001b[0m       save_type\u001b[39m=\u001b[39;49mbase\u001b[39m.\u001b[39;49mSaveType\u001b[39m.\u001b[39;49mSAVEDMODEL,\n\u001b[0;32m    183\u001b[0m       cache\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_serialization_cache):\n\u001b[0;32m    184\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(child, defun\u001b[39m.\u001b[39mConcreteFunction):\n\u001b[0;32m    185\u001b[0m       child \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_uncache_variable_captures(child)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\checkpoint\\graph_view.py:75\u001b[0m, in \u001b[0;36mObjectGraphView.list_children\u001b[1;34m(self, obj, save_type, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns list of all child trackables attached to obj.\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \n\u001b[0;32m     66\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m  List of all children attached to the object.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     74\u001b[0m children \u001b[39m=\u001b[39m []\n\u001b[1;32m---> 75\u001b[0m \u001b[39mfor\u001b[39;00m name, ref \u001b[39min\u001b[39;00m \u001b[39msuper\u001b[39;49m(ObjectGraphView,\n\u001b[0;32m     76\u001b[0m                        \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mchildren(obj, save_type, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     77\u001b[0m   children\u001b[39m.\u001b[39mappend(base\u001b[39m.\u001b[39mTrackableReference(name, ref))\n\u001b[0;32m     79\u001b[0m \u001b[39m# GraphView objects may define children of the root object that are not\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[39m# actually attached, e.g. a Checkpoint object's save_counter.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\checkpoint\\trackable_view.py:84\u001b[0m, in \u001b[0;36mTrackableView.children\u001b[1;34m(cls, obj, save_type, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m obj\u001b[39m.\u001b[39m_maybe_initialize_trackable()\n\u001b[0;32m     83\u001b[0m children \u001b[39m=\u001b[39m {}\n\u001b[1;32m---> 84\u001b[0m \u001b[39mfor\u001b[39;00m name, ref \u001b[39min\u001b[39;00m obj\u001b[39m.\u001b[39;49m_trackable_children(save_type, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     85\u001b[0m   ref \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39mconvert_to_trackable(ref, parent\u001b[39m=\u001b[39mobj)\n\u001b[0;32m     86\u001b[0m   children[name] \u001b[39m=\u001b[39m ref\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\functional.py:461\u001b[0m, in \u001b[0;36mFunctional._trackable_children\u001b[1;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_trackable_children\u001b[39m(\u001b[39mself\u001b[39m, save_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcheckpoint\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    460\u001b[0m     dependencies \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layer_checkpoint_dependencies\n\u001b[1;32m--> 461\u001b[0m     dependencies\u001b[39m.\u001b[39mupdate(\u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_trackable_children(save_type, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[0;32m    462\u001b[0m     \u001b[39mreturn\u001b[39;00m dependencies\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3923\u001b[0m, in \u001b[0;36mModel._trackable_children\u001b[1;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[0;32m   3920\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_function \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   3921\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_tf_function \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 3923\u001b[0m children \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_trackable_children(save_type, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   3925\u001b[0m \u001b[39mif\u001b[39;00m save_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msavedmodel\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   3926\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function \u001b[39m=\u001b[39m train_function\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer.py:3478\u001b[0m, in \u001b[0;36mLayer._trackable_children\u001b[1;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m     cache \u001b[39m=\u001b[39m kwargs[\u001b[39m\"\u001b[39m\u001b[39mcache\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   3475\u001b[0m     \u001b[39m# TODO(b/213628533): This must be called before super() to ensure\u001b[39;00m\n\u001b[0;32m   3476\u001b[0m     \u001b[39m# that any input shape changes are applied before getting the config\u001b[39;00m\n\u001b[0;32m   3477\u001b[0m     \u001b[39m# of the model.\u001b[39;00m\n\u001b[1;32m-> 3478\u001b[0m     children \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_trackable_saved_model_saver\u001b[39m.\u001b[39;49mtrackable_children(\n\u001b[0;32m   3479\u001b[0m         cache\n\u001b[0;32m   3480\u001b[0m     )\n\u001b[0;32m   3481\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3482\u001b[0m     children \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\base_serialization.py:61\u001b[0m, in \u001b[0;36mSavedModelSaver.trackable_children\u001b[1;34m(self, serialization_cache)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m utils\u001b[39m.\u001b[39mshould_save_traces():\n\u001b[0;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m {}\n\u001b[1;32m---> 61\u001b[0m children \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobjects_to_serialize(serialization_cache)\n\u001b[0;32m     62\u001b[0m children\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunctions_to_serialize(serialization_cache))\n\u001b[0;32m     63\u001b[0m \u001b[39mreturn\u001b[39;00m children\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\layer_serialization.py:79\u001b[0m, in \u001b[0;36mLayerSavedModelSaver.objects_to_serialize\u001b[1;34m(self, serialization_cache)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjects_to_serialize\u001b[39m(\u001b[39mself\u001b[39m, serialization_cache):\n\u001b[1;32m---> 79\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_serialized_attributes(\n\u001b[0;32m     80\u001b[0m         serialization_cache\n\u001b[0;32m     81\u001b[0m     )\u001b[39m.\u001b[39mobjects_to_serialize\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\layer_serialization.py:106\u001b[0m, in \u001b[0;36mLayerSavedModelSaver._get_serialized_attributes\u001b[1;34m(self, serialization_cache)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    101\u001b[0m     save_impl\u001b[39m.\u001b[39mshould_skip_serialization(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m    102\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_must_restore_from_config\n\u001b[0;32m    103\u001b[0m ):\n\u001b[0;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m serialized_attr\n\u001b[1;32m--> 106\u001b[0m object_dict, function_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_serialized_attributes_internal(\n\u001b[0;32m    107\u001b[0m     serialization_cache\n\u001b[0;32m    108\u001b[0m )\n\u001b[0;32m    110\u001b[0m serialized_attr\u001b[39m.\u001b[39mset_and_validate_objects(object_dict)\n\u001b[0;32m    111\u001b[0m serialized_attr\u001b[39m.\u001b[39mset_and_validate_functions(function_dict)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\model_serialization.py:57\u001b[0m, in \u001b[0;36mModelSavedModelSaver._get_serialized_attributes_internal\u001b[1;34m(self, serialization_cache)\u001b[0m\n\u001b[0;32m     53\u001b[0m     default_signature \u001b[39m=\u001b[39m save_impl\u001b[39m.\u001b[39mdefault_save_signature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m     55\u001b[0m \u001b[39m# Other than the default signature function, all other attributes match\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# with the ones serialized by Layer.\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m objects, functions \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_get_serialized_attributes_internal(\n\u001b[0;32m     58\u001b[0m     serialization_cache\n\u001b[0;32m     59\u001b[0m )\n\u001b[0;32m     60\u001b[0m functions[\u001b[39m\"\u001b[39m\u001b[39m_default_save_signature\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m default_signature\n\u001b[0;32m     61\u001b[0m \u001b[39mreturn\u001b[39;00m objects, functions\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\layer_serialization.py:117\u001b[0m, in \u001b[0;36mLayerSavedModelSaver._get_serialized_attributes_internal\u001b[1;34m(self, serialization_cache)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns dictionary of serialized attributes.\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m objects \u001b[39m=\u001b[39m save_impl\u001b[39m.\u001b[39mwrap_layer_objects(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, serialization_cache)\n\u001b[1;32m--> 117\u001b[0m functions \u001b[39m=\u001b[39m save_impl\u001b[39m.\u001b[39;49mwrap_layer_functions(\n\u001b[0;32m    118\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj, serialization_cache\n\u001b[0;32m    119\u001b[0m )\n\u001b[0;32m    120\u001b[0m \u001b[39m# Attribute validator requires that the default save signature is added\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[39m# to function dict, even if the value is None.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m functions[\u001b[39m\"\u001b[39m\u001b[39m_default_save_signature\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\save_impl.py:168\u001b[0m, in \u001b[0;36mwrap_layer_functions\u001b[1;34m(layer, serialization_cache)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m    162\u001b[0m         fn_name: \u001b[39mgetattr\u001b[39m(layer\u001b[39m.\u001b[39mkeras_api, fn_name, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    163\u001b[0m         \u001b[39mfor\u001b[39;00m fn_name \u001b[39min\u001b[39;00m serialized_attributes\u001b[39m.\u001b[39mLayerAttributes\u001b[39m.\u001b[39mall_functions\n\u001b[0;32m    164\u001b[0m     }\n\u001b[0;32m    166\u001b[0m \u001b[39m# Reset the losses of the layer and its children. The call function in each\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m# child layer is replaced with tf.functions.\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m original_fns \u001b[39m=\u001b[39m _replace_child_layer_functions(layer, serialization_cache)\n\u001b[0;32m    169\u001b[0m original_losses \u001b[39m=\u001b[39m _reset_layer_losses(layer)\n\u001b[0;32m    171\u001b[0m \u001b[39m# Wrap all the layer call and activity regularizer functions.\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \n\u001b[0;32m    173\u001b[0m \u001b[39m# Use LayerCallCollection to ensure that all layer call functions (__call__,\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39m# call with losses) are traced with the same inputs.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\save_impl.py:305\u001b[0m, in \u001b[0;36m_replace_child_layer_functions\u001b[1;34m(layer, serialization_cache)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[39mif\u001b[39;00m child_layer \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m serialization_cache[constants\u001b[39m.\u001b[39mKERAS_CACHE_KEY]:\n\u001b[1;32m--> 305\u001b[0m     serialized_functions \u001b[39m=\u001b[39m child_layer\u001b[39m.\u001b[39;49m_trackable_saved_model_saver\u001b[39m.\u001b[39;49m_get_serialized_attributes(  \u001b[39m# noqa: E501\u001b[39;49;00m\n\u001b[0;32m    306\u001b[0m         serialization_cache\n\u001b[0;32m    307\u001b[0m     )\u001b[39m.\u001b[39mfunctions\n\u001b[0;32m    308\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     serialized_functions \u001b[39m=\u001b[39m serialization_cache[\n\u001b[0;32m    310\u001b[0m         constants\u001b[39m.\u001b[39mKERAS_CACHE_KEY\n\u001b[0;32m    311\u001b[0m     ][child_layer]\u001b[39m.\u001b[39mfunctions\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\layer_serialization.py:106\u001b[0m, in \u001b[0;36mLayerSavedModelSaver._get_serialized_attributes\u001b[1;34m(self, serialization_cache)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    101\u001b[0m     save_impl\u001b[39m.\u001b[39mshould_skip_serialization(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m    102\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_must_restore_from_config\n\u001b[0;32m    103\u001b[0m ):\n\u001b[0;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m serialized_attr\n\u001b[1;32m--> 106\u001b[0m object_dict, function_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_serialized_attributes_internal(\n\u001b[0;32m    107\u001b[0m     serialization_cache\n\u001b[0;32m    108\u001b[0m )\n\u001b[0;32m    110\u001b[0m serialized_attr\u001b[39m.\u001b[39mset_and_validate_objects(object_dict)\n\u001b[0;32m    111\u001b[0m serialized_attr\u001b[39m.\u001b[39mset_and_validate_functions(function_dict)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\layer_serialization.py:117\u001b[0m, in \u001b[0;36mLayerSavedModelSaver._get_serialized_attributes_internal\u001b[1;34m(self, serialization_cache)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns dictionary of serialized attributes.\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m objects \u001b[39m=\u001b[39m save_impl\u001b[39m.\u001b[39mwrap_layer_objects(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, serialization_cache)\n\u001b[1;32m--> 117\u001b[0m functions \u001b[39m=\u001b[39m save_impl\u001b[39m.\u001b[39;49mwrap_layer_functions(\n\u001b[0;32m    118\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj, serialization_cache\n\u001b[0;32m    119\u001b[0m )\n\u001b[0;32m    120\u001b[0m \u001b[39m# Attribute validator requires that the default save signature is added\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[39m# to function dict, even if the value is None.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m functions[\u001b[39m\"\u001b[39m\u001b[39m_default_save_signature\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\save_impl.py:216\u001b[0m, in \u001b[0;36mwrap_layer_functions\u001b[1;34m(layer, serialization_cache)\u001b[0m\n\u001b[0;32m    211\u001b[0m     fns[\u001b[39m\"\u001b[39m\u001b[39mcall_and_return_all_conditional_losses\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m call_fn_with_losses\n\u001b[0;32m    213\u001b[0m \u001b[39m# Manually trigger traces before restoring the overwritten functions. The\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[39m# functions are traced within the layer call context to ensure that layer\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[39m# functions (e.g. add_loss) behave as though running in graph mode.\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m \u001b[39mwith\u001b[39;49;00m tracing_scope():\n\u001b[0;32m    217\u001b[0m     call_collection\u001b[39m.\u001b[39;49mtrace_with_input_signature()\n\u001b[0;32m    218\u001b[0m     \u001b[39mwith\u001b[39;49;00m base_layer_utils\u001b[39m.\u001b[39;49mcall_context()\u001b[39m.\u001b[39;49menter(\n\u001b[0;32m    219\u001b[0m         layer, inputs\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, build_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, training\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, saving\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    220\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    145\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\save_impl.py:390\u001b[0m, in \u001b[0;36mtracing_scope\u001b[1;34m()\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[39mif\u001b[39;00m training \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    389\u001b[0m     \u001b[39mwith\u001b[39;00m backend\u001b[39m.\u001b[39mdeprecated_internal_learning_phase_scope(training):\n\u001b[1;32m--> 390\u001b[0m         fn\u001b[39m.\u001b[39;49mget_concrete_function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    391\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m     fn\u001b[39m.\u001b[39mget_concrete_function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1189\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1188\u001b[0m   \u001b[39m# Implements GenericFunction.get_concrete_function.\u001b[39;00m\n\u001b[1;32m-> 1189\u001b[0m   concrete \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1190\u001b[0m   concrete\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1169\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1167\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1168\u001b[0m     initializers \u001b[39m=\u001b[39m []\n\u001b[1;32m-> 1169\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwargs, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[0;32m   1170\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[0;32m   1172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[0;32m   1173\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m   1174\u001b[0m   \u001b[39m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:694\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[39m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 694\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn    \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    695\u001b[0m     \u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(\n\u001b[0;32m    696\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[0;32m    698\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[0;32m    699\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:176\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m--> 176\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[0;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[0;32m    169\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:398\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m args \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39margs\n\u001b[0;32m    396\u001b[0m kwargs \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39mkwargs\n\u001b[1;32m--> 398\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(\n\u001b[0;32m    399\u001b[0m     args, kwargs, func_graph)\n\u001b[0;32m    401\u001b[0m \u001b[39m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mfunction_captures\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:304\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[1;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m   arg_names \u001b[39m=\u001b[39m base_arg_names\n\u001b[1;32m--> 304\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39;49mConcreteFunction(\n\u001b[0;32m    305\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    306\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m    307\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m    308\u001b[0m         args,\n\u001b[0;32m    309\u001b[0m         kwargs,\n\u001b[0;32m    310\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    311\u001b[0m         func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[0;32m    312\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m    313\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value,\n\u001b[0;32m    314\u001b[0m         create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    315\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_function_attributes,\n\u001b[0;32m    316\u001b[0m     spec\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_spec,\n\u001b[0;32m    317\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;49;00m\n\u001b[0;32m    318\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;49;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;49;00m\n\u001b[0;32m    320\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;49;00m\n\u001b[0;32m    321\u001b[0m     shared_func_graph\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    322\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1066\u001b[0m, in \u001b[0;36mConcreteFunction.__init__\u001b[1;34m(self, func_graph, attrs, shared_func_graph, spec)\u001b[0m\n\u001b[0;32m   1060\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_garbage_collector \u001b[39m=\u001b[39m ConcreteFunctionGarbageCollector(func_graph)\n\u001b[0;32m   1062\u001b[0m \u001b[39m# Pairs of forward and backward functions used for computing gradients.\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \u001b[39m# These each get a reference to the FuncGraph deleter since they use the\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m \u001b[39m# FuncGraph directly.\u001b[39;00m\n\u001b[1;32m-> 1066\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_delayed_rewrite_functions \u001b[39m=\u001b[39m _DelayedRewriteGradientFunctions(\n\u001b[0;32m   1067\u001b[0m     func_graph, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_attrs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_garbage_collector)\n\u001b[0;32m   1068\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_order_tape_functions \u001b[39m=\u001b[39m {}\n\u001b[0;32m   1069\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_higher_order_tape_functions \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:155\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions.__init__\u001b[1;34m(self, func_graph, attrs, func_graph_deleter)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_function_pairs \u001b[39m=\u001b[39m {}\n\u001b[0;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph \u001b[39m=\u001b[39m func_graph\n\u001b[1;32m--> 155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inference_function \u001b[39m=\u001b[39m atomic_function\u001b[39m.\u001b[39;49mfrom_func_graph(\n\u001b[0;32m    156\u001b[0m     _inference_name(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func_graph\u001b[39m.\u001b[39;49mname), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func_graph,\n\u001b[0;32m    157\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func_graph\u001b[39m.\u001b[39;49minputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func_graph\u001b[39m.\u001b[39;49moutputs, attrs)\n\u001b[0;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_attrs \u001b[39m=\u001b[39m attrs\n\u001b[0;32m    159\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_name \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:357\u001b[0m, in \u001b[0;36mfrom_func_graph\u001b[1;34m(name, graph, inputs, outputs, attrs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_func_graph\u001b[39m(name, graph, inputs, outputs, attrs):\n\u001b[0;32m    355\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Initializes an AtomicFunction from FuncGraph with transforms.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 357\u001b[0m   atomic \u001b[39m=\u001b[39m from_func_graph_no_transforms(name, graph, inputs, outputs, attrs)\n\u001b[0;32m    358\u001b[0m   \u001b[39mfor\u001b[39;00m transform \u001b[39min\u001b[39;00m FUNCTION_TRANSFORMS:\n\u001b[0;32m    359\u001b[0m     atomic \u001b[39m=\u001b[39m transform(atomic)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:401\u001b[0m, in \u001b[0;36mfrom_func_graph_no_transforms\u001b[1;34m(name, graph, inputs, outputs, attrs, overwrite)\u001b[0m\n\u001b[0;32m    399\u001b[0m   output_names \u001b[39m=\u001b[39m []\n\u001b[0;32m    400\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39m_c_graph\u001b[39m.\u001b[39mget() \u001b[39mas\u001b[39;00m c_graph:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 401\u001b[0m   fn \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_GraphToFunction_wrapper(\n\u001b[0;32m    402\u001b[0m       c_graph,\n\u001b[0;32m    403\u001b[0m       compat\u001b[39m.\u001b[39;49mas_str(name),\n\u001b[0;32m    404\u001b[0m       \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    405\u001b[0m       [o\u001b[39m.\u001b[39;49m_c_op \u001b[39mfor\u001b[39;49;00m o \u001b[39min\u001b[39;49;00m operations],  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    406\u001b[0m       [t\u001b[39m.\u001b[39;49m_as_tf_output() \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m inputs],  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    407\u001b[0m       [t\u001b[39m.\u001b[39;49m_as_tf_output() \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m outputs],  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    408\u001b[0m       output_names,\n\u001b[0;32m    409\u001b[0m       [o\u001b[39m.\u001b[39;49m_c_op \u001b[39mfor\u001b[39;49;00m o \u001b[39min\u001b[39;49;00m graph\u001b[39m.\u001b[39;49mcontrol_outputs],  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    410\u001b[0m       [],  \u001b[39m# control_output_names\u001b[39;49;00m\n\u001b[0;32m    411\u001b[0m       \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    412\u001b[0m       compat\u001b[39m.\u001b[39;49mas_str(\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    413\u001b[0m   )\n\u001b[0;32m    415\u001b[0m \u001b[39mfor\u001b[39;00m attr_name, attr_value \u001b[39min\u001b[39;00m attrs\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    416\u001b[0m   serialized \u001b[39m=\u001b[39m attr_value\u001b[39m.\u001b[39mSerializeToString()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.save('mobilenet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbdbbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, '-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, ':', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6772b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1324 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb3c167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 26s 545ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(110.44999999999997, 0.5, 'Actual label')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAboAAAG1CAYAAACPoTFQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAACMDUlEQVR4nOzddVwU+R/H8ReNStiKgQgKGGCLiZ5xenadrWedHWd3YZ1iY2F3d555dreeKAYGInaB9M7vD37u3R6ogOjscp/n43GPw+/Mzr6HXfazM/Od79dIURQFIYQQIoUyVjuAEEII8S1JoRNCCJGiSaETQgiRokmhE0IIkaJJoRNCCJGiSaETQgiRokmhE0IIkaJJoRNCCJGiSaETQgiRopmqHeB7WXzuodoRkl3TQjnVjiC+IEN9H7UjJLugDd3UjpDsIqI0akdIdpbmKes4Jm0qkyQ/NmX9JoQQQoh/kUInhBAiRZNCJ4QQIkWTQieEECJFk0InhBAiRZNCJ4QQIkWTQieEECJFk0InhBAiRdOLQqfRpLybNYUQQugHvSh0np6eTJkyhXv37qkdRQghRAqjF4Wue/funDt3jho1atCkSRPWrVtHSEiI2rGEEEKkAHpR6Jo2bcratWvZs2cPpUqVwtfXl3LlytG3b19OnjypdjwhhBAGTC8K3Ue5c+emd+/e7N27l65du3Lw4EHat29PpUqVWLJkCTExMWpHFEIIYWD0avaCK1eusHXrVnbv3k1kZCRVq1alQYMGPHnyBB8fH65du8bUqVPVjimEEMKA6EWhmzNnDtu2bePhw4cULFiQ3r17U6tWLaysrLTrmJmZMWLECBVTCiGEMER6UehWrlxJnTp1aNiwIXnz5o13HScnJ/r37/+dkwkhhDB0elHofvzxR5o3b469vf0n18mfPz/58+f/jqmEEEKkBHrRGWXnzp0YG+tFFCGEECmMXhzReXp6snLlSrp3765zXU5fRUdGMu3XOmj+1QvUzMKSPot2xFn/4Mq5nP9jMwNX7v9eEb+aRqNh08b1bFi7msDAQNKnT0/FHyrTuVsPg3iN4mOo+5Q9gxXn57Sg8didHLv2WNtewT0HQ5t7UDB3BiKiYjh94wlDFp8gIPitdh2XnOkY17Ycnm7ZiYrRcORKIMOXneBu0Nv4nkpVF86fpduvbT65vEPnbnTo1O37BUoGz54G07ZZfcZ6z6BIsZLa9ovnzrB04Vzu3vHH3MyMgoWK0LlHH7Ln+PRZLX1z7eoV5sycxo3r10iVOjWly5SjR59+pE+fQe1ocehFoXv+/Dm7d+9m2bJlZMiQAQsLC53lBw8eVClZ/J4HBqCJiaFWl0GkzWKnbTc2Momz7qObVzm/d8v3jJcsli5eyJxZM2jdph0lPUrz8MF95syawZ07t5k7fxFGRkZqR0w0Q9ynHBmt2D6mHmmtdP8mSuezY+fYeuw8fY+23ntJY2nGoKYlOTS5EcW7ruLlu3ByZbHhkPfPvA2NoPe8wzx7E0bbHwtweHJjyv62lofP3qu0V/Fzdc3PwmVr4rTPmz0DvxvX+bF6TRVSJd2zp0/o17MTISG6v+drVy7Sr2dHynr+wHCv3wkLC2P54nl079CKJWu3kjZtOpUSJ5zfjb/o9msbSniUZuLUmbx4/ow5PtN49NsDFi5frXa8OPSi0Hl4eODh4aF2jAR79uAuxiYmuJQsj6mZ+SfXiwwPY/f8yViny8j7V8+/Y8Kvo9FoWLp4IQ0bNaHnb30BKFW6DLZp0zKofx9u3LhOgQJuKqdMHEPbJyMjaFE5HxPalSO++tvn52L4PXxF8wm7UZTYtlM3nnB7aVtaVcnH9M2X6FG3MKktTCn721ruB78D4MDFBxyd0pjRrUvTdvK+77hHX5bGyoqC7oV02o4ePsT5s6cZP2ka9rkc1AmWSBqNhr27tzN3xmSUjy/OP6xevphcuR0ZPWGq9pKNW6Ei/Fy7Cn/s3ErTlm2/d+REmzV9Ms4u+fCePku7D2msrJg6aQJBjwPJlj2Hygl16UWh6969u9oREuXZw7ukt8v52SIH8Oea+aSxTUeuAkU4uXXVd0r39UJDQqhZuw7VqtfQaXfI7QhA4KNHelUUEsLQ9sktd0Z8uv3A/F3XOHT5IVtH19VZfu5WMDtO3eOfn6NPXoXy9kMkubPaAuCSMz1+D19pixyAosCx649pW63gd9mPrxEeHs7UieMoW74ClapWUztOgt2948/U372o27ApxUuWYmDvrjrL8xdwo1yFSjr9EjJmykwaKyseBz763nET7e2bN1w8f44RY8br7MMPlavyQ+WqKib7NL0odLNmzYq33cjICDMzM7JmzYqnpydp06b9vsE+4en/j+jW/T6Qx7dvYGJqhktJT35o3hGLVKkBCLh2gb+OH6DN2LncOHlI5cSJY21jw8DBw+K0Hz50AAAnpzzfO9JXM7R9evTsPQU7LOfxyxDKu2WPs3zSuvNx2soVzE56a0v8Hr4C4OW7MAo4ZMDUxJjomL9nCHG0syWtlQXprCx4HRLx7XbiK61fvYLnz5/h47tY7SiJkiWLHas27SZzlqxcunA2zvJW7TrFabt88Rzv370jt6N+vQ/jc/v2LTQaDenSpWfE4P4cO/IniqJQsXJV+g4YgrWNjdoR49CLQnfu3DnOnTuHmZkZuXPnBuDBgweEh4djZ2fHmzdvsLCwYPny5Z+8z+57URSF5w8DAIVCFX+iTL0WPLl3ixObV/Ly8QOaD5tCZHgYexZOoVzD1qS3069D+KS6dvUKSxYtwLPiD+TJ66x2nGShz/v0OiQiUUUog40lc3pWIuhFCCsP+gGwfP8NmlR0YVHfqoxcfop3oZE0r+RK1aK5AEhjaaa3hS4qKpJ1a1ZQpdpP5LTPpXacRLGxtcXG1jbB67958xrvcaPImCkz1WvW/fIDVPbmVewXqbEjh1G6XHkmTfPh0cMHzJk5nceBgcxfskLvrnfrRaFzd3dHo9Ewffp0MmSI7bHz+vVr+vXrR+HChencuTMjRoxg8uTJ+Pr6qhtWUWjYx4tUNrZkyuEAQE5Xd9LYpmfn3N+5d+08N08fwSZ9JkpUb6hu1mRy+dJFenbrTLbsORg9ZrzacZJFStqnrOlSs31MPbKmS0PNYVsICYsC4NDlR7T13sukjp40ruACwMFLD5m88QIjWpbiQ0S0mrE/69CBfbx88YKWrdupHeWbevniOf16duTly+dMnbWQ1GnSqB3pi6KiY99frvkLMHTkGABKeJTGytqG4YP6cebUSUqVKatmxDj04ua1jRs3MmTIEG2RA0iXLh39+/dn9erVmJmZ0b59ey5evKhiylhGxsbY5y+kLXIfORWO7UzzNOA2N08fplr73iiKgiYmBkWJPW2kiYlBMbBJZvf+sZvOv7Ylq50dvguXGESPsC9JSftUIFcGjkxtTPaMVtQdsY1zt57qLF97+BYOLRdS8NdlOLVeRK1hWzE1MSImRsObUP08moPYQufolIe8Lq5qR/lm7t7xp0u75jx/9hTvGfPIX9Bd7UgJkjp1bDEuW76CTnvpMuUA8L/l990zfYleHNFFR0cTFRUVpz0iIoLw8HAAzM3N9WIm8vevX3D38lkc3YpjkzGztj06MvZD4/KhXURHRbJ40K9xHuv9S3UKlq9KzU4Dvlver7F86SKmT51M8RIlmTJ9FtbW1mpH+mopaZ883XOwflhN3oVGUmXARu21uY9ccqajWN4srD50U+e+ucJOmbl2/yUaTdwegfogOiqKMydP0KpNe7WjfDMXz59lWP+epLGywsd3Obn17Brx53w8lRwVFanTHh0de4bg37eH6QO9KHTlypVj9OjRTJ06lVy5Yn+JAQEBjB07lnLlyhETE8OaNWtwcXFROSkoMRr2LppG6TrN8Gz892kVvzNHMDI2pungSUSEheo85sqfu7ny525ae80itXXCz92raeP6tUyb4s2P1WswdvzvmH2hh6khSEn7VMgxE5tH1uZ+8DtqD9/Kk1ehcdbJb5+BRX1/5NytYG4/fgOAa870VC1qz+9rz33nxAl3585twsPDcC9cRO0o34T/LT8G9+mGXbbsTPaZT8ZMmb/8ID2S29EJu2zZ2f/HHn5u2kJ7Pe7YkT8BKFy0mJrx4qUXhW748OF06tSJ6tWrY2Njg6IovH//nkKFCjFixAiOHTvG2rVr1b8+B9hkzIybZzXO7NqAqbkF2fLkI9D/L05vX0PRqnXj7Xxy99IZAOwc1S/UCfHixXOmeP9OtuzZadqsBX43bugsz5HTnvTp06uULmlS2j7N7VUZMxNjxq46Tc5M1uTM9PeR6fO3YQQEv+WP8/e5G/SGpQOq47XiFDapzRnfrhwBwe/w2XpZvfBfcPe2P4BB9EBMikljRxAdHUXbjt14GvyEp8FPtMvSpkun96OjGBkZ0aN3P4YO6MOwgX2p26ARAffuMm/WDH6o8iMurvo3JrFeFLr06dOzfv16zpw5g5+fHyYmJri6ulKyZOyQOYUKFeLo0aN6c5rpx7Y9SZvZjr+OH+DktlVYp8tEuYat8ajZWO1oyeL4saOEh4cT9Pgx7X5pEWf56DHjqVOvgQrJki4l7ZNDVhuK5Ik9ClgzNO5oISsO3KDjtAOERURTZ8Q2vDt6srR/dcKjotl3/gEjl53kfVhknMfpi1evXgLoZTf1rxX0+BG3/38Na8Sg3nGWV69Zl8Ejx33vWIlWuWo1LGbMZpHvXPr27IqNrS31GzWhc/deakeLl5ES3637KdDicw/VjpDsmhbKqXYE8QUZ6vuoHSHZBW0wrPEmEyIiSv3r/8nN0lwv+homm7Sp4g6xmFB6cUR37949vLy8uHjxYrydUvz89K8XjxBCCMOgF4Vu5MiRvHz5kn79+unN6UkhhBApg14UuitXrrBmzRoKFCigdhQhhBApjF6cxE2XLh1mZmZqxxBCCJEC6UWha9myJVOnTiUkJETtKEIIIVIYvTh1efLkSc6fP0/JkiXJkCED5ua6N/Lq28SrQgghDIdeFLpixYpRrJj+3U0vhBDC8OlFoevevTs3b97E399fO56loihERkZy7do1ldMJIYQwZHpR6JYsWcKkSZNQFAUjIyPt9PNGRkYUL15c5XRCCCEMmV50Rlm1ahUdOnTgypUrpEuXjiNHjrBt2zacnJyoXLmy2vGEEEIYML0odMHBwfz8889YWFjg6urKtWvXcHFxYdCgQWzcuFHteEIIIQyYXhS61KlTExMTA4C9vT137twBwMnJicePH6sZTQghhIHTi0JXtGhR5s+fT1hYGPnz5+fQoUNoNBouXLhAGgOYWl4IIYT+0otC16dPH44dO8aqVauoWbMmL168oGTJkgwcOJAGDQxj6hQhhBD6SS96XTo7O3PgwAE+fPhAmjRpWL9+PTt37iRr1qxUr15d7XhCCCEMmF4UOgBLS0ssLS0ByJgxI23atFE3kBBCiBRBL05dCiGEEN+KFDohhBApmhQ6IYQQKZoUOiGEECma3nRG+dZSmZqoHSHZGRkZqR1BfIlRyvsuaWKc8t530f8fTD4lMTZKeZ95SZXy/gqFEEKIf5BCJ4QQIkWTQieEECJF04tCd+7cOaKjo+O0R0REsHfvXhUSCSGESCn0otC1bt2ad+/exWm/c+cO/fv3VyGREEKIlEK1XpdLly5l4sSJACiKQtmyZeNdz93d/XvGEkIIkcKoVuhatmxJ2rRp0Wg0DBkyhMGDB2Ntba1dbmRkROrUqSlVqpRaEYUQQqQAqhU6U1NT6tWrB8QWtZo1a2Jubq5WHCGEECmUXlyjq1+/PtevX+fVq1cAbN26lU6dOuHr64uiKCqnE0IIYcj0otCtXbuWFi1acOvWLW7evMngwYOJiopi6dKlzJ49W+14QgghDJheFLply5YxbNgwSpcuze7du8mbNy+LFy9m0qRJbN68We14QgghDJheFLrAwEAqVaoEwIkTJ/D09ATAycmJFy9eqBlNCCGEgdOLQpchQwaePXvG8+fP8fPz095qcPPmTTJmzKhyOiGEEIZML2YvqFmzJv369SNVqlRkzZqVkiVLsnv3bsaMGUOjRo3UjieEEMKA6UWh69u3L1mzZuXRo0e0aNECExMTXr58SdOmTenevbva8YQQQhgwvSh0xsbGtGrVSqft3/8WQgghkkIvCt2sWbM+u1yO6oQQQiSVXhS6f99CEBMTw8uXLzE1NaVo0aIqpRJCCJES6EWhO3ToUJy2kJAQhgwZIoVOCCHEV9GLQhcfKysrevbsSbt27WjTpo3acXRERUYyoW1NNDExOu1mFpYMXbYbgMd3b7Fv5TyC7t3CInUaCntWo+LPv2BqaqZG5K/yNDiYhvVrMW3GbEqU9FA7TrIwpH3KniEN52c3p/G43Ry79ljbXsE9O0OblaRg7gxERMVw+kYwQ5acICD47ymv7DNZM75dGcq7ZcfYyIhTN54wcNFxnXX0SUREBBXKFCfmX/NTpkqVmqOnL6iUKumePwumffOGeE2cTuFiJbTtvTr+wvWrl+KsP2fJGlzyFfieEZPE0F4nvS10AO/fv+f9+/dqx4jj2aMANDExNOg+hHRZsmnbjY1jb0t89TSI5eP6kTNvAX7+bQQvHj/k4LpFhIW+p3aH3mrFTpLgJ0/o2qk9IXr4OiSVIe1TjoxWbPeqQ1orC5320vmysnNMXXaeDqDt5P2ksTBlUNMSHPJuSPFua3j5LhxLcxN2jq2LqYkRfX2PEhYRzfCWHuybUJ/i3dfwNjRSpb36tLt3bhMTHY3X+EnkyJlT225sbKJiqqR59jSYgb06Exqi+z5TFIV7d/xp1Kw1FSpX1Vlm75D7e0ZMMkN7nfSi0MXXGSU0NJTdu3fj4aF/37aDH9zB2MSE/B6emJrFnXHhxPa1WFimpmn/MZiamuFcpBRm5hbsXuJD+XrNSZsxiwqpE0ej0bBj+1amTZ5IShlX25D2ycgIWlRyZUK7shgZGcVZ3qdRMfwevqL573u0+3LKL5jbS36hVeV8TN9yibIFspE3e1p+GrqVw1cCAfB//Iarvi2p5eHIqkM3v+cuJYj/LT9MTE2pXLWawc5motFo2Ld7B74+U+IdlD4o8BEfPoTiUaYc+QsWUiHh1zO010kvCl1841mamZlRunRpevfWvyOg4Pt3yJjNPt4iB3DnyjnyFi2lc5oyf6kK7Fo8g7tXzlGscq3vFTXJ/P1vMc5rJI2bNsejVBl6dO2odqSvZkj75OaQEZ9uFZm/+zqHLj9i66jaOsvP3Qpmx+l7OgX7yatQ3n6IJLedDQCWZrHfrt9/+PvI7dX7cAAy2Fh+4z1IGv+bN3FwyG0QH56fcu+OP9MnjaFOgyYUK1mKIX266Sy/czv2C4aTs6sa8ZKFob1OelHo4uuMos+CH9zF2MSE5eP688j/L0xMzShQqgI/tuyMsYkJb188JYNdDp3HpLFJi0WqNLwIeqRS6sSxs7Njx+79ZMmalXNnz6gdJ1kY0j49ev6egr+u4PHLUMq7ZY+zfNL6uNdByhXMRnprS/wexk53deDSI/wevmJc2zJ0nnGIsIhovDuW4/2HSLafuvfN9yEp/G/dxMTElO6d2nPl8iXMzc2pXLUavfoOIE2aNGrHS5DMWexYsXEnmTJn5fKFc3GW3/W/RarUqfGdOYVTx48QFvaBIsVK0vW3/uTMZRinLg3tddKLQhcUFBRvu5GREWZmZqRPn157/UttiqLw9OE9UBSK/lADzwYtCbp7i8OblvM88AGNeg0HwCJV6jiPNU+VioiwD987cpLY2qbF1lbtFMnLkPbpdUgEr0MiErx+BhtL5vSoRNDLEFYejD1iiIiKocvMQ2wcXhO/Ra0BCI+MpqHXLu4/1b/OKIqicOf2LRRFoW6DhrTr2Jkb16+z0Hc2Affu4rt4ud58DnyOja0t8Ok32p3btwj78AEraxtGT5zG0ydPWLFoHr91boPv8g1kzJT5+4VNAkN8nfSi0FWqVCne6xAfmZubU7NmTUaNGqX6obKiKDTrN5Y0NrZkzhn77cshXyGs0qZn86zx3L9x+bOPN9KzN4AwfFnTpWa7Vx2ypktNzWHbCAmLAmKP8HZ41eGU3xNmbrlMjEahw08FWDf0J+qN2sGJv56onFyXoihMmTGHtOnS4ZQnLwBFi5UgQ8aMjBgygFMnj1O2nKfKKb9e+849aNqyDe5Fisc2FIYC7oVp17Qum9etomN3/btc80+G+Drpxafu+PHjsbGxYciQIWzZsoUtW7YwfPhw0qZNS/fu3Rk7diwXLlzAx8dH7agYGxuTu0BhbZH7KG+RUgC8fhb74REZz5FbRNgHLFPp32G9MFwFcmXgyJRGZM9oRd2R2znn/1S7bGDj4gS9DKXeyB38cf4B+y8+pOn4Pdx48IqJHcqrmDp+xsbGFCtRUvvh+VG58hUAuH3rlhqxkp1TXpe/i9z/ZcueA3sHR+7d0f99NMTXSS8K3ZIlSxg5ciStWrXC1dUVV1dXmjdvjpeXF/v27aN27dqMGjWKnTt3qh2Vd69ecOHgTt68eKrTHh0Ze5rJOm0GrNNn5NVT3dOxIW9fExn2gYzZ7b9bVpGyebpl5+CkBhhhRJWBmznlF6yz3D6zNRdvPyMyWqNtUxQ4eeMJ+e3Tf++4X/T82TO2bFpP8BPdv52IiNgONOnSpVMjVrKKiY5m765t/HXtSpxlERHh2KbVv9fl3wzxddKLQvfgwQPy588fpz1v3rwEBAQA4ODgwMuXL793tDg0mhh2LJjKhQO6Rff6qT8xMjbG3tUNJ/fi+F88RXTU373d/M4cxcjYmNwFi3zvyCIFKuSYkc0jaxH4IoQK/TZqO6D8063A1xR3zoK5qe6fuYdrVgKC336vqAkWExPNeK+RbN64Xqd93949mJiYULhoMZWSJR8TU1NWLJrHfJ+pOu3+N28QFPhI56ZyfWWIr5NeXKPLkycPmzZtom/fvjrtmzZtIleuXAD4+fmRJYv695+lzZiFwhWrc2LHOkzNzcmZtwAPb13j2NbVlKxWj4zZclK2dlOunzjEyt8HUbrGz7wMDuTg2oUUq1zLIO6hE/pvbs9KmJkYM3bVWXJmsiJnJivtsudvwwgIfsfva89zcFIDto2uw6xtl4nWKPxSNR8erllpPmGPiunjl9UuG7XrNmDF0sVYWFjgVqgwVy5dZMlCX35u2pxcBnIz9Ze07tCFiV7D+H30EKpUr83T4CCWLZiDU14XfqxRR+14X2SIr5NeFLo+ffrQuXNnzp07R5EiRdBoNFy5coXr168za9Ys/Pz8GDhwIG3btlU7KgC12v9Gusx2XD22n6NbVmKTPhM//NyGMrWbAJApuz2thkxi3ypf1k8fRWprW0rXaMQPP+tHfmHYHLLYUCRPbM+8NUN+irN8xQE/Ok4/yMU7z/hx0BZGtPRgaf8fiYzWcC3gBdWGbOH49fh7Oqtt0LCRZM+Rg907t7N4wTwyZ8lKp649aNWmvdrRks2PNepgbm7BupVLGDmwF5apUlG2QmU6dOmFiYl+jizyb4b2Ohkp8d26rwI/Pz+WLVvGX3/9hampKa6urrRr1468efNy7do1/Pz8aNy4cZK3v+bS4y+vZGDqFYx7f5XQL+nrf34KKkP0dGNXtSMku3f/76maktikMrxxdT/HxjLpV9r04ogOIF++fPz+++/xLnNzc8PNze07JxJCCJES6EVnlMjISObNm8eDBw8AGDp0KEWKFKF9+/a8fv1a5XRCCCEMmV4UusmTJ7NkyRJCQkI4evQoW7ZsoVOnToSGhjJp0iS14wkhhDBgelHo/vjjD6ZOnUqBAgU4ePAgJUuWpHPnzgwbNozDhw+rHU8IIYQB04tC9+bNG5ycnAA4ceIEZcuWBSBt2rSEh4erGU0IIYSB04vOKPb29ly7do2XL18SGBhI+fKxwxMdOHCAHDlyfOHRQgghxKfpRaHr0KEDffr0wdjYmFKlSuHq6srs2bOZPXs248ePVzueEEIIA6YXha5evXq4uroSGBiIp2fsqNdubm4sWrSI0qVLq5xOCCGEIdOLQgdoB3P+6GPBE0IIIb6GaoWucuXKbNy4kXTp0n1xPrqDBw9+x2RCCCFSEtUKXf369bG0tASgQYMGasUQQgiRwqlW6HLkyMHevXu1PwshhBDfgmqFbtCgQTr/NjIyQlEULC0tMTU1JSQkBBMTE9KlS0e9evXUCSmEEMLgqVbobt68qf15586dLFq0iAkTJmg7pNy/f5+BAwdSq1YttSIKIYRIAfRiZJTJkyczatQonV6XDg4ODBs2DF9fXxWTCSGEMHR6UejevXuHhYVFnHaNRiNDgAkhhPgqelHoPDw88PLyIjAwUNt29+5dRo8eTcWKFdULJoQQwuDpxQ3jo0aNon379lStWhUbGxsUReH9+/e4u7szfPhwteMJIYQwYHpR6LJkycK2bds4efIkt2/fxsjICFdXV0qVKvXZG8mFEEKIL9GLQgdgYmJC+fLltTMXCCGEEMlBbwrdt6bRKGpHSHbRMRq1IySrFHn0/vjml9cxMBHRKet9BxCdAj8folLY58PXdCnRi84oQgghxLcihU4IIUSKJoVOCCFEiiaFTgghRIomhU4IIUSKJoVOCCFEiiaFTgghRIomhU4IIUSKJoVOCCFEiiaFTgghRIomhU4IIUSKJoVOCCFEiiaFTgghRIomhU4IIUSKpheFbufOnbx9+1btGEIIIVIgvSh0Xl5ePH/+XO0YQgghUiC9KHQODg74+/urHUMIIUQKpBczjLu6utKvXz8WLlyIg4MDFhYWOssnTJigUjIhhBCGTi8KXUBAAMWKFQMwiFOY0ZGR/N6+FpqYGJ12MwtLBi/ZpdMWEfYB30G/4tmgFYUrVP+eMZNV/949uHnzBjv2HFQ7SpJpNBpWLl/C5o3refY0GPtcDrRu24EaNWurHe2LsmdOy/mNQ2jcewHHLtyOd51uzSoyeUAjXGqM4OGTV9p2V8esjOtVj9KFHdFoFPYcu86wGVt5+vL994qfYBqNhrUrl7Ft0zqeP3uKXbYcNGjclIZNWqgdLUmeP3tKp5YNGfn7NAoVLQFAtTKFPrm+e9HieM9a9L3ifZVtmzewfvUKngQFkSWrHY2aNKNB42YYGRmpHS0OvSh0K1asUDtCojwLDEATE0P9roNJlyWbtt3IWPdMcFjIe9ZNHc6b58HfO2Ky2r1zO38eOoBdtmxfXlmPzZs9k2VLFtG5Ww8KFHDj+PEjDB/cH2MjI6rXqKV2vE/KkSUt2+d0I6116k+uk8c+M1496sRpt8tkyx/zexIQ+IJ2Q5eR2tKc0T1qs2teD0o1+53oaM23jJ5os6ZNYv3qFdRr2ATPHyrzOPARC+f6EPT4MT36DFA7XqI8exrM0N5dCA3R/UIxfX7cz7sTRw6yYdVSatb7+XvF+yrbt2xk4thRNGraAs8Klbh86QJTJ40nIjKS5q3aqB0vDr0odADR0dG8fPmSmP8fJSmKQmRkJNeuXaNOnbh/wGoKfnAHYxMT8nl4YmpmHu86ty6c5I9ls4gM//Cd0yWv58+eMXnieLJkyap2lK8SFhbG6pXLadaiFW3bdwSgZKnS3LzxF2tXr9DLQmdkZESLWiWZ0Lv+Z78lGxsbscCrJa/ehpI6le77sW39MthapaJhL19evQ0F4PnrEPYt7EXFEi4cOOX3TfchMd68fs2mdaupXa8h/YaM0LZnzpKVwX17UKd+I3LldlQxYcJoNBoO7NnBgllTURQlzvJ8Bd11/v3saTB7tm+idsMmVKxiGGd9dm7bQqHCRekzYAgAxT1K8fBBAJvWrZZC9ynHjx9n4MCBvHr1Ks4yS0tLvSt0T+/fJWM2+08WufDQENZPHYlbucqUrFafhcO6fueEyWfM6GF4lC6DhYUFF86fVTtOkpmbm7NkxRrSpU+v025qZkZISIhKqT7PLW82fIY2Zf6GYxw6c5OtPvG/j3q3rkzm9NZ4L97HjCFNdJbN33CMP47/pS1yAFHR0QBYWujFn7/Wo4f3iYmJoaxnRZ32oiVKotFoOHPquEEUuoA7/sz0Hkvt+o0pUqIUw/t1/+z6832mYG5hSdvOPb9Twq8XGRlBhoyZdNpsbdPy9u0bdQJ9gV70upw6dSr58+fH19cXS0tLZs2axZAhQ7CyssLb21vteHEEP7iLsbEJKycMYELbmkz6tR47F04lIiz26M3MwoIu3oup12UQqa1tVU6bdFs3b+DmjRsMHDxc7ShfzcTEhLzOLmTMmAlFUXj58gVLFs3n7OlTNGrcTO148XoU/JqCdUYzcMpmPoRFxbtOPsesDO1Ug06jV/EhPDLO8hevQ7h44yEAFuamlHRzYNqgxtx9+JwDp25+0/yJZZs2HQDBT57otD8OfARAUGDgd8+UFJmy2rFk/U469eqPhaXlZ9f1u36VY4f20bZTD9KksfpOCb9e42YtOXvqBH/s2kHI+/ecPnmcPTu3Ub2Gfl7v1ouvdHfu3GH8+PG4urqSL18+UqdOTatWrUidOjWLFi2iSpUqakfUUhSFp4/ugaJQ5IefKF+vJUH3bnJk8wqeP35Am+HTMDE1I2O2nGpH/SpPgh4zbfJERniNJ226dGrHSVZ79+xi6KB+AJTzrECNWvp1xuCj1+8+8Prdp099m5gYs3BMa5ZuPcXxC3dwyJbhs9s7u24wzg5Z+BAWSZO+CwiPiL94qsU+lwPuhYuyyHcWmTJnoVgJD4IeBzJp3EjMzc0JCw9TO2KC2NjYgk3CvuBuWLWELHbZqFyt5jdOlbyqVq/BxfPn8Bo+SNvmUbosv/Ub9JlHqUcvjuhMTEywtrYGIFeuXNp76kqVKsXdu3fVjBaXotC07xjaec2ixI/1yJXPndI1G1OzbS8e3brOnavn1E741RRFwWvkMMqU86RylR/VjpPsCri5s2DxCgYMHsaVS5fo0aVDvNdS9N3A9tVIa52KYTO2JWj9335fT60us/jz7C02z+hMldL5vnHCxBs7aRqFixRnaP9eVK9Yip6d21Gn/s/Y2KbF8gtHR4bm+bOnnDp2mPqNW2JiqhfHHAk2sHcPDh/cR7defZm9YCl9Bgzhpt9fDB3YRy//lvTit5s3b14OHTpEq1atcHR05MKFC/zyyy8EB+tfb0UjY2Mc8heO0563SCkAnj68R97CHt85VfJav3Y1t2/fYu3GbUT//3rOxzdvdHQ0xsbGGBvrxXekJMmZ056cOe0pWrwEadJYMXLYIC5dOE/R4iXUjpZghVxyMKD9j9TrMZeIqGhMTIwxNo7tsPLxZ41G9wPnzzO3ADh8zp+LG4fSt00VveqMApA+Q0YmTPXh/ft3vHj+jOw57DE2NmbyBK/YI6UU5MThA2BkRMWqhtEB5aNrVy5x+uRxBg0fTZ36jQAoUqwE2XLkpF/PLpw8diTOdVa16UWh69ixIz179sTMzIxatWrh4+NDx44duXXrFqVKlVI7no73r19w+9IZnNyLY5sxi7Y9KjICgDQGfE3uo4MH9vLm9WuqV/aMs6xUMTd+7dyNTl0+f4Fd37x+9YoTx49Spmx50mf4+xSfa778ADx//kytaElSq6I7FuZm7PGN24Hhxo5RHD1/m2q/zsCzeF5SWZqx9/gN7fKYGA1/3Qkiv5Pd94ycIAf27sbB0Yk8eV2wtrYB4OaN62g0Gpxd86ucLnmdOXEUt0JFSZf+86ec9c2TJ0EAuBcqotNeuGjsvdD37t2RQhefKlWqsGHDBkxMTLCzs2PhwoUsWbKEypUr07OnfvVE0sTEsHPhVMrVbU6lJu217X+dPoyRsTH2rm4qpkseQ4aP5kNoqE7bgnmz8fP7i6kz5pApU2aVkiVdeEQ4I4cNolvP3rTr0EnbfvrUCQDyOruoFS1JFm8+wZ5j13XafipfkGGda9Cw1zxuP4gt3M1rlqRmBTfy1RpJyIfYL2NWqS3wcM/Nqcv3vnvuL1m2yBfHPHkZPX6ytm3dquVYWVlTpJjhHHF/iaIo3PL7i7qNmqodJdFyOcT2fL186QIOjk7a9quXLwGQPbv+9U/Qi0IHUKBAAQAiIyMpWbIkJUuWVDlR/GwzZqFwheqc3LkeU3MLcuTNz6Nb1zm+bTUlf6xHBjv9e5ETy8Ehd5w227RpMTMzI3+Bgiok+np2dtmoW78hC33nYGpqiqtrfi5dPM/SxQuoW78Rjk551I6YKE+ev+XJc90ZPz4eoV2/HaQdGWXa8gM0/LEom2Z0ZtqyA1iYm9K3TVWsUlsw1nf3d8/9JY2atmDyeC8cnfLi5l6YA/v2sP+PXfQbPAKr/1/HTwmeBT8hNOQ99g5OX15Zz7i45qNi5ar4TJ3E+/fvKFDQnYC7d1jkOwfXfAXw/KGy2hHj0JtCt2bNGhYsWEBwcDB79+5l0aJFZM6cma5d9e8etBrtepE2sx3Xju/n2NaV2KTPRMVGv1CmVpMvP1ioZvCwkWTPnpMtm9Zrhy3q3LUnrdq0UzvaN3Mr4ClV2k3Dq0cdFo1tjamJMccu3KHz6FXcvKd/18DrNmhMRHgEm9atYsXiBdjncmDkuElUrW5YvRK/5PXrlwBY2dionCRpRo+fxNKFvmzduJ6Fc2eRJasdNevUo23HLpjqYccaI0UPusjs2LGD0aNH88svv7Bw4UJ27tzJn3/+yeTJk/ntt99o1+7rP4hWXTCMe3ASo04Bwx6S69/0cYy8r5WpVA+1IyS7h8emqx0h2YVGRKsdIdlZW+pfwfkaGdIkfX/0ouvc4sWLGTp0KD169ND25mvdujUjRoxg3bp1KqcTQghhyPSi0AUEBFC8ePE47R4eHjz51ygJQgghRGLoRaHLmDEjAQEBcdovXbpE5syG18NPCCGE/tCLQtekSRO8vLw4eDB2rrN79+6xZs0axo0bR4MGDVROJ4QQwpCpdrVy0qRJdOrUCVtbW2rUqMG7d+/o06cPERERdOrUCVNTU5o2bUqnTp2+vDEhhBDiE1QrdCtXrqR58+bY2tpSpUoVjh8/TteuXblz5w6KouDo6IiVleGM5i2EEEI/qVbosmfPTvfu3cmXLx+KojBu3DgsLCziXXfChAnfOZ0QQoiUIkGFbvDgwQneoJGREePHj//iet7e3vj6+vL48WOMjIwICgrCzMwswc8jhBBCJESCCt2ZM2cSvMGE3vRbsGBBfHx8AKhUqRJz584lXQqb90wIIYT6ElToDh069E1DfOvtCyGE+O9K8jW6t2/fcv78eZ49e0a1atV48+YNuXPnTpHDOAkhhDBcSSp0c+fOxdfXl/DwcIyMjHB3d2f69Om8fv2axYsXY2OgA5UKIYRIeRJ9w/jKlSvx8fGhbdu2rF+/XjvzdMuWLXn06BEzZsxI9pBCCCFEUiW60K1YsYKOHTvSq1cv7RxyABUqVOC3336T621CCCH0SqILXVBQ0CcnRXV0dOTFixdfHUoIIYRILokudHZ2dly6dCneZdevX8fOzu6rQwkhhBDJJdGdURo1aoSPjw+WlpZUrFgRgA8fPrB37158fX1p27ZtcmcUQgghkizRhe7XX38lMDCQyZMnM3nyZCB2klSA2rVryyDMQggh9EqiC52RkRFeXl60bduWM2fO8ObNG6ytrSlRogTOzs7fIqMQQgiRZEm+YTx37txoNBrevXtHhgwZsLe3T85cQgghRLJIUqFbsWIFvr6+vHz5UttmZ2dHnz59qFWrVrKFE0IIIb5WogvdypUrGTduHFWqVKFq1apkyJCB58+fs2vXLvr374+JiQk//fTTt8j6Ve6/CVc7QrIzMU5Zw60Zp7D9AcAms9oJkp+idoDkZ26S6A7oes/C1ETtCHoj0YVu+fLltGzZkmHDhum0169fn6FDhzJr1iy9LHRCCCH+mxL9NSY4OJhKlSrFu6xWrVo8evToq0MJIYQQySXRhc7NzY1Tp07Fu+zGjRu4uLh8dSghhBAiuSTo1OW5c+e0P9esWZMJEyYQFhbGTz/9RKZMmXjz5g1HjhxhxYoVjB079puFFUIIIRLLSPk4/cBnuLq66swz9/Ehn2rz8/NL7pxfbdzBO2pHSHa9yzupHSFZpcTOKOkqe6kdIdk93DlE7QjJLipGo3aEZGeTykztCMnKyiLpnw8JOqJbvnx5kp9ACCGEUFOCCt2nZisQQggh9F2Sbhi/evUqZ86cITIyUnvKUlEUPnz4wIULF1i/fn2it3nkyBE8PT11TocKIYQQXyvRhW7VqlWMHTuW+C7tGRsbU65cuSQF6dmzJ7a2ttStW5cGDRqQO3fuJG1HCCGE+KdE316wcuVKPD09OXPmDO3ataNx48ZcvnyZGTNmYGFhQZ06dZIU5MSJE3Tr1o3z58/z008/0aRJE9atW0dISEiStieEEEJAEgpdYGAgzZs3x9bWloIFC3LhwgUsLS2pVq0aHTt2THLHFSsrK5o0acKaNWvYu3cv5cuXZ+XKlZQrV45+/fpx+vTpJG1XCCHEf1uiC52ZmRmWlpYA5MqViwcPHhAVFQVAsWLFuH///leHypYtGy4uLri6ugJw4cIFunbtSu3atbl58+ZXb18IIcR/R6ILXb58+fjzzz+Bv6fquXLlChA7PNjXuHjxIiNHjqRcuXL0798fRVGYO3cuf/75J8eOHcPJyYnffvvtq55DCCHEf0uiO6O0bduW7t278+7dO8aPH0/lypUZMGAAP/74Izt27KBYsWJJClK1alUCAwPJnz8/vXr1onbt2lhbW2uXp0mThp9++okTJ04kaftCCCH+mxJd6KpUqcK8efO4e/cuAF5eXvTt25e1a9fi5ubG8OHDkxSkUqVKNGjQ4LNjZZYuXZq9e/cmaftCCCH+mxI0BNj3dP/+ffz9/TE2NqZAgQLY2dkly3ZlCDD9J0OAGQYZAswwyBBgf0v0oM4JUaJEiUQHCQ0NpXfv3hw7dkxn3MwaNWowYcIEzM3NE71NIYQQIkGFrlWrVnFGLFEURdv28eeP/0/KoM5jx44lICCA+fPnU6RIETQaDRcvXmTMmDFMnTqVQYMGJXqbQgghhN4M6nzgwAHmzJmjczRYsWJFzM3N6devn94VuucBN7m4dSkvH/hjapGKbPmLUaxBO1JZpwUg8NpZruxazdvgh1hY2eBUqgpu1ZtgYmoYpxM0Gg2bNq5nw9rVBAYGkj59eir+UJnO3XpgZWWldrwkO3niOLNmTOPu3Tukz5CBps1a0LpNO70fei57JmvOL+lC42HrOHb5gba9eqm8DGvriWuuTLx8+4EVf1xh4opjREX/fSpu8dB6NPvRPc42m4/YwJYj+jPTyLOnwbRuUo/xk2dStPjf4+sGPnrAzKkTuXrpIiYmJvxQpRpdevQhjQG8D58/DaZt8waMnTSDwsX+/mw7dfwoyxbO4UHAPWzTpqVazbq0bNsRMzPD+XxYuXwJmzeu59nTYOxzOdC6bQdq1KytdrR46c2gziYmJjq9LD/KlCkT0dHR3/z5E+Plw9vsmz4YO5fCVOw4jA9vX3Jp2zIOz3vMT/2nEHTjIn/OG4NjqcoUqfcL74IDubhtGWFvX1G6RU+14yfI0sULmTNrBq3btKOkR2kePrjPnFkzuHPnNnPnL9L7whCfq1cu06NrZ6r99BPdevTi0sULTJviTXR0DO1/7ah2vE/KkcmG7ZNbkNbaUqe9cnFHNo5vwsq9Vxg+/xAu9hnx6liJrBms6D55l3Y99zxZWXfgGnM2ndV5/O1HL79L/oR4GvyEvj06EhLyXqf9/ft39OzcjgwZMjJ01Hhev37JnJlTCQoKZKrPfJXSJsyzp8EM6NmJ0H/t07nTJxnWvwc/1qjDr1178fBBAAvmzODli+f0GzJKnbCJNG/2TJYtWUTnbj0oUMCN48ePMHxwf4yNjKheo5ba8eJI0qDO30Lr1q0ZM2YMM2bMIGPGjACEhIQwffp0WrdurXI6XRe2LCF9Dkd+6DwcI+PYWxHNLFNzbsN83r8I5tre9aS3z0PZVr8BkM21COEh77j2x1qKN+qImYXlZ7auPo1Gw9LFC2nYqAk9f+sLQKnSZbBNm5ZB/ftw48Z1ChRwUzll4s2Z5YNrvnyM/90bgLLlPYmKjmbRgnm0aNVaOxCCvjAyghbVCjGhS1Xi+17Rv2U5Lvk/ofPEHQD8eSGADLapGdSqPANm7eNDeBQW5iY422fAZ8Npzt54/J334Ms0Gg1/7NrG7OmTUYjbL27rxnW8e/uWxas2kjZtOgAyZc5K/16duXr5Iu6Fi37vyF+k0WjYt3s7c2dOgXj6+q1ethBn1/wMHD4GgGIlS/P2zRtWLJlPt94DSJUq9feOnChhYWGsXrmcZi1a0bZ97BfEkqVKc/PGX6xdvUIK3eccP36ca9euUblyZRwcHDA1NeX+/fuEhobi5+fHli1btOsePHhQtZzhIe946n+Nsq17a4scQK4iZclVpCwAZVr1QhMTo/M4E1NTFEVBidGvo9P4hIaEULN2HapVr6HT7pDbEYDAR48MrtBFRkZy/twZunTTPaKu+mM1li5eyKWLFyhdpqxK6eLn5pQFnz41mb/tPIfO32PrpOY6yztP3I6ZqYlOW2R0DMbGRpiZxr43C+TOjJmpCVfvPP1uuRPj7u1bTJ7gRf1GTSlesjT9f+uis/zMqRO4FymqLXIAJUuVIXWaNJw6cUwvC929O/5MnTiGug2bUKxEKQb36aazvP+w0XHOUpmamaFoNMTo2dmr+Jibm7NkxRrSpU+v025qZqa3YxPrTaErU6YMZcqUUTvGF715HICiaLCwtuXYEm8eXT0DKNgXKkPJxp0wT22Fdca/b4mIDPvAk5uX+OvAZnIXr4B5av2/rmBtY8PAwcPitB8+dAAAJ6c83zvSVwt89IioqChyOTjotNvb5wLgfkCA3hW6R0/fUrCFD4+fv6d84Vxxlt9/8kb7s3VqcyoVc+S3JqVZf/A6b0MigNjTlgBtahVhU7mmZLBJzTm/xwyes59zfuof4WXJasfaLXvInCUrF8+fjbP8wf17VK5aXafNxMQEu2zZefQg4HvFTJTMWexYtXEXmbJk5fKFuD3Ws2XPqf05NCSEC+dOs37VUir9+BNW1jbfM2qSmJiYkNc59n5nRVF49eol27du5uzpUwwZPlrldPHTm0LXvXt3tSMkSHjIOwBOrphB9gLF+KHTMN49C+LStqW8fxlM9T6TtNevPrx9xcbBrQCwypiVInX06xRsYly7eoUlixbgWfEH8uR1VjtOon289vPvjjSp06QBIDRU/76Jvn4fzuv34V9cL2t6KwK29AHg3uNXjFx4SLusUJ4sAKSxNOMXr81ksElFvxZl+WN6ayp0WcT1e8++TfgEsrFNi43tp5eHhrzXvkb/lDp1GkJDQ79hsqSzsbUF28/s1P+9fPGcRjUrAZAtew46dDaM6/f/tHfPLoYO6gdAOc8K1KiVtNlrvrVEj3X5LV2+fJm+fftSu3Zt6tWrx9ChQ7l9+7basXRoomMHsM5g70SZlr2wcy2Mi2cNPJp14/ndGzzxu6Rd19TMnKq9xuPZYRAmpmbs9u7Dhzcv1IqeZJcvXaRb51/Jlj0Ho8eMVztOkmg0n78h2MhIr/4UEiUsMorqvy2nxcgNRETFcGROe7JljO3YNWfzOWr3W0WH8ds4dvkBW4/epGbflYSGRzKwVXmVk3/Z5143IwMfYMDCwoIpsxcycvxkzMzM6dq+Bc+f6ecp5k8p4ObOgsUrGDB4GFcuXaJHlw7xzlWqtgQd0bm6uia4l52RkRE3btxIdJBDhw7RvXt33NzcKFu2LDExMVy6dIkGDRqwZMkSihcvnuhtfgumlqkAyOGm2xM1e/7YMT5fBd4lW/7Y6wbmqa2wcykEQMZczmwe0Z7bJ/dRqIbutRZ9tveP3YwcNhj7XA7MnrdA51qJIbH6f4/efx8FhP7/moK1tf6fUv6UtyERHLl0H4DzN4PwW9OTX2oWYcKyo9x+9DJO78q3IRGcvvYIN6csKqRNHCsraz58+BCn/UNoKJky63/+z7GytqFocQ8AXPMVpHmDn9i9fTO/dOjyhUfqj5w57cmZ056ixUuQJo0VI4cN4tKF8xQtnvhBQ76lBBW6bt26ffPu5NOmTaN9+/b07dtXp33ixIl4e3uzbt26b/r8CWWTOTsAMf+fmuijj51PTEzNuX/hGNaZs5Eh599DdFllyIJFamvC3rz6fmG/0vKli5g+dTLFS5RkyvRZ8d7+YShy5rTHxMSERw8f6LQ/fPgQgNyOhjWcmrGxEfUr5ONO4Cuu3P571pCHwW959S4MuwyxhbvRD/l5/T6cg+fv6Tze0sKMF2/jFhB9kzOXA48fPdRpi4mJISgoEM8fqqiUKuliYmI4+ud+cuTMRV6XfNr2rNmyY21jy8sXz1VMlzCvX73ixPGjlClbnvQZMmjbXfPlB+D5c3VPh8cnQYWuR48e3zoHDx48oGHDhnHamzRpwurVq7/58yeUbdacWGXIwv0LR3GtWFv7BeDR1diJYTPnLciR+eOwzpydqj3GaB/38uEdIkLfkTa7gxqxE23j+rVMm+LNj9VrMHb875iZGfYQbBYWFhQtVpyDB/bzS9v22tftwP69WFtbU9At7g3V+kyjURjTsTJ3Al9Rp/8qbXvhvFnJmDa19tpb+zrFyJU1LYVazdbeRJ4tozWlC+Zk5gb9n8y4ZKkyrF6+mNevX5EuXWwvv7OnTxL24QMlS+l/57V/MzExYcHs6WTPmQvvmb7adv+bN3j39g2OefT/+nd4RDgjhw2iW8/etOvQSdt++lTszDIfO6rokyR1Rnn69CkXLlwgMjJS26bRaAgLC+P8+fNMmzYt0dvMly8fp06dwuFfveKuX79O3rx5kxLzmzAyMqJY/XYcWfQ7RxdNJG+5arx98ohL25djX6QsGXI6UahmC04sn8rpNbPJVaQs718Ec2XXKtJmy0We0lXV3oUvevHiOVO8fydb9uw0bdYCv3+dis6R0570/+pabAh+7dSFTh3a0r9PL+o1aMjlS5dYtmQRvXr3JVWqVGrHS7SxS4+waEg9ZvSpwZbDfuTOlpbhbSty/d5Tlu++DMCE5cfYPaUlG8Y3ZfbGM6S3ScWQXzx59e4DM9adUjV/QtRr1JRN61bTu1sH2v7alXdv3zBn5hRKlSmPW6EiasdLkl9+7crvo4cybeIYPCtV5cnjQJYumENupzz8VKue2vG+yM4uG3XrN2Sh7xxMTU1xdc3PpYvnWbp4AXXrN8JRD3tlJ7rQ/fHHH/Tr14/o6Og4Y10CODo6JilInTp1mDx5Mvfu3cPDwwNTU1OuXbvGsmXLaNq0KVu3btWuW69evSQ9R3LJVbQclcxGcGX3Gg7NGY1FGmucy/9EkdqxvSqdSlXG1NyC6/s2cO/MQUwtUmFfqDRF6v2CqbmFqtkT4vixo4SHhxP0+DHtfmkRZ/noMeOpU6+BCsm+jkep0kyZ7sPc2TP5rUc3MmfJQu9+A/ilTTu1oyXJ6r1XCQuPom/zsrT40Z2QsEi2H7vJiPmHCI+MvR/r6KX71Oq3imFtK7BiZEM0isL+s3cZNu8A70IjVN6DL0uXLj0z5y1hxtTf8Ro2kNRp0vBD5Wp0/62/2tGSrFqNOlhaWLJ6+SL27d5BqlSpKFexMr927YWFng1a8CmDh40ke/acbNm0nidBQWTJakfnrj1ppad/S4mepqdevXpYWFgwcuRIVq1aRUxMDL/++itHjhxh6tSp+Pr6UrZs4u9HcnV1TVjgJA4aLdP06D+ZpscwyDQ9hkGm6flboo/oAgICmDJlCvnz58fDw4PFixfj5OSEk5MTL168YN68eUkqdDdv3kz0Y4QQQogvSfTNQ8bGxtj+/2bIXLlyce/ePe29Lp6enty5k/xHTsHBwV9eSQghhIhHoo/oHB0duXjxIiVKlMDR0ZHIyEhu3rxJ/vz5effunU4HlcR49OgREydOxN/fn5j/d9VXFIXIyEhevXqVpHvzhBBCiEQf0TVt2pQZM2Ywbdo0rK2tKVWqFIMHD2bFihVMmTKFAgUKJCmIl5cXt27dolq1ajx9+pSaNWtSoEABXrx4wahRo5K0TSGEECLRhe7nn39m6NCh2iO3MWPGEBERwbhx44iOjmbo0KFJCnLx4kXGjh1L3759yZMnD1WqVMHHx4dOnTpx5MiRJG1TCCGESNJ9dC1a/N3lPGfOnOzZs4fXr19/1b1VkZGR2NvbA5A7d25u3bqFu7s79erVo1WrVknerhBCiP+2ZBnJ1sjI6KtvIM6ePTv+/v5AbKH7eAuBRqPR21HKhRBC6L9EH9ElZIDnpNznVr9+fQYMGMCkSZOoWLEirVu3Jlu2bJw4cQIXF/0bUkYIIYRhSHShi2+A59DQUC5evMjDhw/p169fkoJ07NgRCwsLFEXB3d2drl27MnfuXOzs7Jg0aVKStimEEEIkemSUzxkwYABp0qRh5MiRybXJZCMjo+g/GRnFMMjIKIZBRkb5W7LOMF6/fn1+++23JBe6M2fOcP36dcLDw+NM3mcoM5ALIYTQL8la6B4+fEh0dHSSHjt//nymTp2KtbV1nHnPjIyMpNAJIYRIkkQXulmzZsVp02g0BAcHs3v3bn744YckBVm5ciW9evWiSxfDmV1XCCGE/kuWQgdgZWVFlSpVGDx4cJKCvHnzhtq1ayfpsUIIIcSnJLrQfatZBooVK8alS5fIkSPHN9m+EEKI/6ZEF7rBgwfTtWtXcubMGWfZvXv3mDRpEvPmzUvQtv45maqbmxujRo3i9u3b5MqVCxMTE5111Z5sVQghhGFKUKELCgrS/rxlyxaqVKkSpxABHD16lJMnTyb4yQcNGhSnbf78+XHajIyMpNAJIYRIkgQVutGjR3P06FHg8z0gFUVJ1KSrMtmqEEKIby1Bhc7Ly4uTJ0+iKApDhgyhS5cu2gGYPzI2NsbGxgYPD49vElQIIYRIigQVuixZslC/fn0g9oiuYsWK2NjYaE9fhoeHExUVFef+NyGEEEJtiZ69oFatWkyfPp3GjRtr2y5evEjp0qWZOHEiGk3KG0pHCCGE4Up0r0sfHx+2b99Oz549tW358+enX79++Pj4kC5dOjp27JisIZNDgUxWakdIdl+aRcLQJN+oq/ojnWtBtSMku1TmcTuiGbqIDzFqR0h2KW/8zqS/7xJd6Hbs2MHAgQNp2rSpti1t2rS0adMGU1NTli9frpeFTgghxH9Tok9dvn79Ot576AAcHR0JDg7+6lBCCCFEckl0oXN0dGTv3r3xLjt06BC5cuX66lBCCCFEckn0qcvWrVszaNAg3rx5Q5UqVciQIQOvXr3izz//ZM+ePUyYMOFb5BRCCCGSJNGFrl69eoSGhjJnzhz27dunbU+XLh0jRoygbt26yRpQCCGE+BpJmo+uRYsWNG/enICAAN68eYONjQ3W1tZs2LCBSpUq8eeffyZoO4mZ6UCOFIUQQiRFkideNTIywtHRkWPHjrFo0SKOHDlCdHR0omYfCAwMTOrTCyGEEAmSpEL36tUrNm7cyPr163n8+DFWVlbUr1+funXrUrx48QRvZ8WKFUl5eiGEECLBElXoTp8+zbp16zhw4AAxMTEUK1aMx48fM3v2bEqWLPnVYaKjo3n58iUxMbE3byqKQmRkJNeuXaNOnTpfvX0hhBD/PQkqdEuXLmXdunUEBASQK1cuunbtSv369UmdOjUlS5ZMlhE6jh8/zsCBA3n16lWcZZaWllLohBBCJEmC7qP7/fffMTc3Z/ny5ezdu5cuXbqQNWvWZB2CaurUqeTPnx9fX18sLS2ZNWsWQ4YMwcrKCm9v72R7HiGEEP8tCSp0NWvW5MGDB3Tq1ImuXbuyf/9+oqOjkzXInTt36Nu3L56enuTLl4/UqVPTqlUrBg0axKJFi5L1uYQQQvx3JKjQTZkyhePHjzNgwACeP39Ojx49KF++PJMmTcLIyChZjuxMTEy00/zkypULf39/AEqVKsXdu3e/evtCCCH+mxI8BJiVlRXNmjVjw4YN7Nixg7p163Lo0CHtZKwzZszgzp07SQ6SN29eDh06BMQOM3bhwgUAGTtTCCHEVzFSlKRPjhIdHc2ff/7Jpk2bOH78ODExMeTNm5ft27cnelsHDhygZ8+ejBgxggoVKlCtWjVKlSrFrVu3KFSoEDNnzkxqTAC2Xk15BbNavqxqRxBf4NR9s9oRkp3/zPpqR0h2bz5Eqh0h2aWxSPJt0nopXervOE2PzoNNTalatSpVq1blxYsXbNmyhS1btiRpW1WqVGHDhg2YmJhgZ2fHwoULWbJkCZUrV9aZ+04IIYRIjK86oktO3bt3p3fv3jg5OX2T7csRnVCDHNEZBjmi039fc0SX6Gl6vpXTp09jYWGhdgwhhBApjN4Uuvr16zN58mRu375NZKThfLta7j2M37s20Wl7+/I5a2aMYXTb2oxo/RMLvPrwOMBfpYRf72lwMOVKF+fc2TNqR0k2hrZPdmlT4TetFqWdMyZqWeWCWdk9+AfuzKzD2fHV6Vc7H2YmyXf/a3LTaDQsX7qIerWqUaZEIZo2qsvuXTvUjpVkz58FU6dKWS5fOKfT3qvjL1Qu5R7nv1t+f6mUNOEunD9LqSL5P/nfQt/ZakeMQ2+ObY8cOcLDhw8/Oamrn5/fd070ZReP7uOvs8dIl+nvU4gRYR+YN7InpqZm1O/YFzNzcw5uXM7CMf3oPWUJNukyqJg48YKfPKFrp/aEvH+vdpRkY2j7lC1dKlb3LIttavNELauQLzNLu5Vmw6kHTNhynTxZrRlcvwCZbS0ZsPLS94ieaPNmz2TZkkV07taDAgXcOH78CMMH98fYyIjqNWqpHS9Rnj0NZmCvzoSG6L7PFEXh3h1/GjVrTYXKVXWW2Tvk/p4Rk8TVNT8Ll62J0z5v9gz8blznx+o1VUj1eXpT6Lp06aJ2hER59+oF2xfPxDZDJp32Y7s28OH9O/pOX64tajkcXZg5sCP3/rpE4XJV1IibaBqNhh3btzJt8kT04yru1zO0fTIygp9L2TOikVuiln3U/ScXrj54TZ/lFwE4dvM56a0s6FXDhZHrrxIWGfPNsidFWFgYq1cup1mLVrRt3xGAkqVKc/PGX6xdvcJgCp1Go2Hf7h34+kwhvi4QQYGP+PAhFI8y5chfsJAKCb9OGisrCrrr5j56+BDnz55m/KRp2OdyUCfYZ+hNoTMyMqJGjRqYm+t+M/3w4QPr169XKdWnbZw3ibyFSmBmZs69G5e17ddPH8GtVAWdIzfrdBkYOn+TCimTzt//FuO8RtK4aXM8SpWhR9eOakf6aoa2T/mz2/J7iyIsO3KPY37PWNmjbIKWfdR3+QXMTHSvTkTGaDA2MsLMxJgw9KvQmZubs2TFGtKlT6/TbmpmRkhIiEqpEu/eHX+mTxpDnQZNKFayFEP6dNNZfuf2TQCcnF3ViJfswsPDmTpxHGXLV6BS1Wpqx4mXqoXu1atXhIeHA7GTsObNm5d06dLprOPn58fUqVNp06aNCgnjd/bgTh7f86fP1KXsWj5X2x4THc3TwPsUKV+VvWsXce7gTkLfv8XB1Y267X8ja079Py3xkZ2dHTt27ydL1qwGcx3rSwxtnx6/+kDZYft48iYszvW3zy376OGLD9qfrSxNKZ8vM52r5mXruUe8C4v6ptmTwsTEhLzOLkDs6b1Xr16yfetmzp4+xZDho1VOl3CZs9ixYuNOMmXOGufaHMBd/1ukSp0a35lTOHX8CGFhHyhSrCRdf+tPzlyG8xnx0frVK3j+/Bk+vovVjvJJqha6o0ePMmjQIIyMjFAUhUaNGsVZR1EUKlSooEK6+L1+HszOZbP5uesg0tik1VkWFvoeTUwMx3ZtIEPmbDTsPICY6Cj2rVuM78he9J68GJv08X8o6Rtb27TY2qqdInkZ2j69+RDFmw/xF6TPLfu3zDaWXPauAcD95yH8vu1GsmX8Vvbu2cXQQf0AKOdZgRq1DGf2EhtbW+DTb7Q7t28R9uEDVtY2jJ44jadPnrBi0Tx+69wG3+UbyJgp8/cL+5WioiJZt2YFVar9RE77XGrH+SRVC129evXInj07Go2GX375hZkzZ2L7j08iIyMjUqdOjbOzs4op/6YoChvmTMSlSCncSsUtvtHRf3/wtBs6CYtUqQHI7uiCd88WnPxjM9Wb6/fpMpHyhEfF8PPUY6RLY06/2vnYObAi1ccfIvhNuNrRPqmAmzsLFq/g9u1bzJ01kx5dOjB/8YpknTFFLe0796Bpyza4F/n/JNWFoYB7Ydo1rcvmdavo2L23qvkS49CBfbx88YKWrdupHeWzVL9GV6JECQCWL19O0aJFMTVVPdInnfpjC8EP7tJ7yhJiYmJnb1CIvdgcExONhWVsYXPKX1hb5ADSZcpC5uy5eBxw+/uHFv9578KiOHHrOQCXH7zm9NhqNCvrwLRdN1VO9mk5c9qTM6c9RYuXIE0aK0YOG8SlC+cpWryE2tG+mlNelzht2bLnwN7BkXt3bqmQKOkOHdiHo1Me8rro9/VGvakqQUFBBAUFfXJ5vXr1vl+YT7h2+gih798ytmODOMuGNK1MlZ/bkMYmrc6R3UcxMdGYmcsN8eL7MDaCmkWzE/AshOuP3mrbA19+4M2HSLLYWqqYLn6vX73ixPGjlClbnvQZ/u7M5ZovPwDPnz9TK1qyiYmO5sDeXeSwd6CAm27PxYiIcGzTpv/EI/VPdFQUZ06eoFWb9mpH+SK9KXSDBg2Kt93CwoKsWbPqRaFr0LEvEeEfdNoObFhK4D1/2gwcj026jLx+Fsz1s8cIffdGew3v+eOHvAh6RMnK+nd/iUiZNAoMqV+QgGchNJ95QtvuljMt6a0s8Hv8TsV08QuPCGfksEF069mbdh06adtPn4rN/7GjiiEzMTVlxaJ5ZMiYmRnzl2nb/W/eICjwEU1b6fcpwH+6c+c24eFhuBcuonaUL9KbQnfzpu5plJiYGO7fv8+oUaNo0qTJJx71fWXKbh+nLbWVLaamZuRwij10r/zzL/x17jgLx/ajSqNfiI6OYu+ahdhmyETJyoZxH5BIGabs9GNm2+JMaF6YXRcfY58xDf1q58Pv8VvWnbyvdrw47OyyUbd+Qxb6zsHU1BRX1/xcuniepYsXULd+Ixyd8qgdMVm07tCFiV7D+H30EKpUr83T4CCWLZiDU14XfqxhOJ1u7t6OHe0pt6P+vy56U+j+zcTEBCcnJwYPHkyvXr2oVcswikSGLNnoOnY2e1bNY63POIyNTcjrXoxabbrrXLcT4lvbePohYZHRdK/uws+l7AmNiGbPpSAmbP2L8CiN2vHiNXjYSLJnz8mWTet5EhRElqx2dO7ak1ZtDOdI50t+rFEHc3ML1q1cwsiBvbBMlYqyFSrToUsvTEySPnDx9/bq1UsArG1sVE7yZXoze8Gn3Lx5kyZNmnDlypWv2o7MXiDUILMXGAaZvUD/qTYfXXLaunVrnLaQkBDWr1+Pu7v79w8khBAiRdCbQhdfZxRTU1OKFCnCqFGjvn8gIYQQKYLeFLp/d0YRQgghkoPezEf3UVBQEMeOHSM8PJyXL1+qHUcIIYSB05sjusjISAYOHMiePXswNjZm7969TJw4kdDQUHx8fLCyslI7ohBCCAOkN0d0c+fO5ebNmyxbtgwLi9gRRFq1asWDBw+YPHmyyumEEEIYKr0pdLt27WL48OF4eHho2zw8PBg3bhwHDx5UMZkQQghDpjeF7unTp9jbxx15xM7Ojrdv38bzCCGEEOLL9KbQOTk5cerUqTjtu3btIk8e/R9iRgghhH7Sm84oPXr0oHfv3ty5c4eYmBi2bNlCQEAAe/fuZdq0aWrHE0IIYaD05ojuhx9+YObMmVy/fh0TExMWLVrEo0ePmDZtGtWqVVM7nhBCCAOlN0d0AJ6ennh6eqodQwghRAqiV4Xu/PnzXLx4kaioKP491nT37t1VSiWEEMKQ6U2hmz17Nj4+PtjY2MS5OdzIyEgKnRBCiCTRm0K3Zs0aevfuTadOnb68shBCCJFAetMZ5f379wYzuaoQQgjDoTeFrmjRoly6dEntGEIIIVIYvTl1WatWLcaMGcP169dxdHTE3NxcZ3m9evXUCSaEEMKg6U2hGzp0KABLly6Ns8zIyEgKnRBCiCTRm0InE68KIYT4FvTmGp0QQgjxLejNEd239jYySu0Iyc7ISO0EyetfYwSkCK+vnFE7QrKLiK6jdoRk9z48Wu0IyS5tavMvr/QfIUd0QgghUjQpdEIIIVI0KXRCCCFSNCl0QgghUjQpdEIIIVI0KXRCCCFSNCl0QgghUjQpdEIIIVI0KXRCCCFSNCl0QgghUjQpdEIIIVI0KXRCCCFSNCl0QgghUjQpdEIIIVI0KXRCCCFSNCl0QgghUjTVJl4dPHhwgtedMGHCN0wihBAiJVOt0AUGBmp/VhSF8+fPkzFjRvLnz4+pqSk3b97k6dOnVK5cWa2IQgghUgDVCt2KFSu0P0+ePJksWbIwYcIEzM1jp3+PiYlhxIgRGBkZqRXxk6IjI5ncoTaamBiddjMLS/ov3gnA1SN7Ob17A2+eBmGTMTPFqtSleLV6erk/n3LyxHFmzZjG3bt3SJ8hA02btaB1m3YGtQ+f8jQ4mIb1azFtxmxKlPRQO85nZc9ky/nVvWk8cDnHLt7Ttlcv48qwDlVwzZ2Fl29CWbHrAhOXHiIq+u/3pUdBe0Z3qU6JAjkJ+RDJnhN+jJj7B89ehaixKwmybfMG1q9ewZOgILJktaNRk2Y0aNzMIN53Go2GfTs2s2fbep4GPcY2XXpKlq1As7adSZ3GKs76OzauZtGsyfiu2UkWu2wqJE4ajUbDyuVL2LxxPc+eBmOfy4HWbTtQo2ZttaPFS7VC90/r1q1j7dq12iIHYGJiQvv27WnUqBFjx45VMV1czwMD0MTEUKfrYNJlttO2GxnHXvK8/Odudi+cSqlaTcjtVoyguzc5sGoukRFhlK3bXK3YiXL1ymV6dO1MtZ9+oluPXly6eIFpU7yJjo6h/a8d1Y73VYKfPKFrp/aEvH+vdpQvypHZlu0z2pPWOpVOe+WSedno/Qsrd19g+Nw/cMmVCa8uP5E1ozXdf98MQPH8Odg7pxM37z/jV6/1hEVE8VsLTw4v6Eqp1jN5Fxquxi591vYtG5k4dhSNmrbAs0IlLl+6wNRJ44mIjKR5qzZqx/uiLWuWsWrRHOo3bY170ZI8DnzAmsVzeRhwl1GT5+gU68ePHrBiwSwV0ybdvNkzWbZkEZ279aBAATeOHz/C8MH9MTYyonqNWmrHi0MvCp2ZmRlBQUE4OTnptN+9e5fUqVOrlOrTnj64i7GJCa4ly2NqZh5n+cltq3Et6UmlZr8CkLtgUV49CeT8vq0GU+jmzPLBNV8+xv/uDUDZ8p5ERUezaME8WrRqjaWlpcoJE0+j0bBj+1amTZ6Ioqid5vOMjIxoUaMoE3rUJL4Dmf6//MClm4/pPG4jAH+eu0OGtGkY1KYSA6bv4EN4FAPaVOJtSDjVu83nzfswAA6fv8uVdf3o06oCo+bt/Z67lCA7t22hUOGi9BkwBIDiHqV4+CCATetW632h02g0bF6zlGp1GtCqYw8AChX3wMbGlsleg7l7y488rvmB2DNWM38fibWNLS+f698Xjs8JCwtj9crlNGvRirbtY7/0lixVmps3/mLt6hV6Wej0otdlrVq1GDp0KJs3b8bf35+bN2+yevVqRowYQZMmTdSOF8fTB3fJYJcz3iIH0Lj/OCo11z3qMTE1JSYy8nvE+2qRkZGcP3eGSpWr6rRX/bEaoaGhXLp4QaVkX8ff/xbjvEZSq049xk6YpHacz3LLkxWfAfVZveci7Ueti7O887iNtBu9VqctMioGY2MjzExNAHB1yMypq/e1RQ4gLCKKc389pHoZ12+7A0kUGRlBaivdU3y2tml5+/aNOoES4UNoKBV/rIln5Z902rPb5wYgOOiRtm3buhW8ef2Khi3afteMycHc3JwlK9bQ8hfd7KZmZkTq6WecXhzR9evXj/DwcEaOHEl0dDSKomBhYUHLli3p1q2b2vHiePrgDsYmJqyZMJDA239hYmqGq4cnlZt3wiJVajJmzwXEdrIJD33PrXPHuXZ8Px41flY5ecIEPnpEVFQUuRwcdNrt7WP3635AAKXLlFUh2dexs7Njx+79ZMmalXNnz6gd57MePX1DwUbePH7+lvJFHeMsvx/0SvuzdWoLKpXMw2/NPVm//wpvQ2KPEF6++UDOrGnjPDZ3jgzkzp7+m2X/Go2btWSC1wj+2LWDcp4VuX7tCnt2bqN6zTpqR/siK2trfu05IE77meN/ApDTIfaM1cOAu6xd6suISbN4+uTxd82YHExMTMjr7ALEfsa9evWS7Vs3c/b0KYYMH61yuvjpRaEzNzfHy8uLgQMHEhAQgJGREblz59bL05aKovDsYQCgUKhiDcrWa8GTe7c4tnkFLx4/oNWwqdprdY/v+LF8VE8A7Byd8ajRSMXkCRcSEnvtyupf36xTp0kDQGio/nZk+Bxb27TY2qqdImFevwvjNWFfXC9rBmsCdg0D4F7gS0b+43Tksp3nmDukEd6/1WbqysNoNAo9mpUnn0Nm7VGfvqlavQYXz5/Da/ggbZtH6bL81m/QZx6lv/xvXGPz6qWUKONJLsc8xERHM33CcKrUrEfBwsUMstD90949uxg6qB8A5TwrUKOWfn4h0YtTlwDR0dGEhISQPn160qVLx+vXrwkICGD79u1qR9OlKPzc14tfRvtQ/Me62Odzx6Pmz1Rv14vAW9e5d/W8dlXbjJlpMWwKtTr2J+T1K5aN6kVUhP6fj9doNJ9dbmSkN2+b/7ywiCiqd5tPiyEriYiK5sjCbmTLZAPA0u3nGDhjJ23qlODezmHc2zkUB7v0LN52lg/hUSonj9/A3j04fHAf3Xr1ZfaCpfQZMISbfn8xdGAfFH2/sPovftcuM3pAdzLbZaPHwFEAbFi5iNCQEFp37KluuGRSwM2dBYtXMGDwMK5cukSPLh308nXSiyO648ePM3DgQF69ehVnmaWlJXXq6M+3BCNjY3LlLxynPU/h2C7qTx/exalwSQCs02XEOl1GyFeItJntWDm2DzfPHsWt/I/fM3KiWVlbAxAaGqrTHhoSeyRnbR23m7RQx9uQcI5cuAvAeb9A/DYN4JfaJZiw+CAAM9ccY876EzjmyMCrtx948SaUhSMa8/rdBzVjx+valUucPnmcQcNHU6d+7NmPIsVKkC1HTvr17MLJY0co61lR3ZAJdPzQXmb+PopsOe0ZMWkWNrZpuXf7JhtXLWb47zMxMzMjJjoaRYn9UqnRxBATE4OJiX4eaX9Kzpz25MxpT9HiJUiTxoqRwwZx6cJ5ihYvoXY0HXrx1Xzq1Knkz58fX19fLC0tmTVrFkOGDMHKygpvb2+14+l4//oFlw7t4u2Lpzrt0ZERAJiaW/DXiYO8CtY9JZE1d97/P/7l9wn6FXLmtMfExIRHDx/otD98+BCA3I5O8T1MfCfGxkY0rOxOIWfd+64ePnnNq3dh2GWMPaIr6pqduhULEB2jwf/Bc168if3iUtglO5dv6d8psydPggBwL1REp71w0WIA3Lt357tnSoqta5czZcwQXAq4MW7GQtJnyATAmeOHiY6KYmTfLjSsUpKGVUoya5IXAF1a1GVEn85qxk6w169esXP7Vl691P0sc80X26P0+fNnasT6LL0odHfu3KFv3754enqSL18+UqdOTatWrRg0aBCLFi1SO54OTUwMexZN49KhXTrtN04fxsjYGIf8hdm1cCqnd63XWX7vWuwpzcz2cTsW6BsLCwuKFivOwQP7dU5DHNi/F2trawq6uauYTmg0CmO6VmdMV93efYVdspExbRqu330CgGdRJ5aMaoat1d+3glQqmZcCTlnZfvSv75o5IXI5xP5tXL6k26v36uVLAGTPnvO7Z0qsvds3snTedMpWrMqISbNJY2WtXVatdkMmz1up81+TX2J7Zw8ZP42ufYeqFTtRwiPCGTlsEFu3bNRpP33qBIC2o4o+0YtTlyYmJlj//3RZrly58Pf3p3Tp0pQqVYqJEyeqnE6XbcYsuFeoxumd6zE1Myd73vwE3rrOye1rKP5jPTLbO1KmTjOOblpGGpu05MpfmGcP73Js8wocChbFqVBJtXchQX7t1IVOHdrSv08v6jVoyOVLl1i2ZBG9evclVapUX96A+KbGLjzAopFNmDGgHlsOXSN39gwM71CV63eesHxn7JeqNX9cpN8vFVk5rgXTVh0lZ5a0TOxVi5NXAljzxyWV9yAuF9d8VKxcFZ+pk3j//h0FCroTcPcOi3zn4JqvAJ4/6PdwgK9fvmDR7KlkzpqNGvWbcM/fT2d51uw5tffRffQgIPYoNVfuvAYzMoqdXTbq1m/IQt85mJqa4uqan0sXz7N08QLq1m+Eo1MetSPGoReFLm/evBw6dIhWrVrh6OjIhQsX+OWXXwgODlY7Wryqt+1F2kx2XD9xgBPbVmGTPhOejX6hVM3GAJSt14LU1rac37+NM7s2kNrGlqKVa1G+wS8GMYwRgEep0kyZ7sPc2TP5rUc3MmfJQu9+A/ilTTu1owlg9Z6LhIVH0bd1RVr8VIyQsAi2H/6LEXP/IDwiGoCnr0Ko3XMRE3vVYu2EVrwNCWPFzvOMnr8XjUb/OgwAjB4/iaULfdm6cT0L584iS1Y7atapR9uOXTA11YuPq0+6cOY4kRHhPAsOYkjP9nGW9xg4iso/6U9/g68xeNhIsmfPyZZN67VDtXXu2pNWevr5YKToQReZAwcO0LNnT0aMGEGFChWoVq0apUqV4tatWxQqVIiZM2d+9XMsO//oyysZmCaF9f9UTmKo/05MfunLD1Q7QrILPDhO7QjJ7tm7CLUjJLuc6fXv9qyvYWWR9IMEvbhGV6VKFTZs2EDhwoWxs7PTXperVKkSXl5eKqcTQghhyPSi0L179461a9diZGRETEwMs2fP5ujRo5w6dYr3BjDwrhBCCP2lF4VuwoQJnD59GlNTU/bv38+FCxfw9vYmd+7cTJqk32MSCiGE0G96cXX3yJEjzJ49GycnJxYsWEDZsmWpXbs2Li4utGjRQu14QgghDJheHNF9+PABO7vYed1OnDhBmTJlgNhRUWL+NbmpEEIIkRh6cUTn5OTE4cOHsbOz4/nz53h6egKwfv36OHPUCSGEEImhF4WuZ8+e9OjRg6ioKGrVqoWDgwMTJkxg1apVzJ49W+14QgghDJheFLoKFSpw5MgRnj59iqtr7ISQNWvWpHHjxnJEJ4QQ4qvoRaEDSJcuHenSpdP+291dxlMUQgjx9fSiM4oQQgjxrUihE0IIkaJJoRNCCJGiSaETQgiRokmhE0IIkaJJoRNCCJGiSaETQgiRokmhE0IIkaJJoRNCCJGiSaETQgiRoqk2BJirqytGRkYJWtfPz+8bpxFCCJFSGSmKoqjxxJs3b9YWusePH7NgwQKaNGlCkSJFMDMz49q1a6xatYouXbrQvn37r36+5yHRX70NfWNtqTdDlYpPePw6TO0IyS5b2lRqR0h2Kn0MflMJPZAwFKnMkv5Y1QrdP7Vs2ZJ69erRqFEjnfbt27ezbNkyNm3a9NXPIYVOqEEKnWHQg4/BZCeF7m96cY3u6tWrlChRIk67u7s7d+7cUSGREEKIlEIvCl2uXLnYtWtXnPZ169aRJ08eFRIJIYRIKfTi3FfPnj3p2bMnJ0+exM3NDY1Gw6VLl/Dz82PBggVqxxNCCGHA9OIaHcDFixdZuXIlt2/fBiBfvny0a9dOO+P415JrdEINco3OMOjJx2Cykmt0f9ObQvetSaETapBCZxhS4segFLq/6cU1OoAjR47QunVrypUrx+PHj/Hx8WHbtm1qxxJCCGHg9KLQnThxgu7du5MtWzbevXuHRqMhOjqawYMHs3XrVrXjCSGEMGB6Ueh8fHzo27cvv//+OyYmJgD07t2b3r17s2jRIpXTCSGEMGR6Uehu3bpFpUqV4rRXr16dhw8fqpBICCFESqEXhc7a2ppnz57Fab9z5w62trYqJBJCCJFS6EWhq127NuPHj+fmzZsYGRkRGhrK0aNHGTNmDDVq1FA7nhBCCAOmF7cXREVFMWjQIO3oKEZGRiiKQsWKFZkxYwYWFhZf/Rxye4FQg9xeYBj04GMw2cntBX/Ti0L30cOHD7lx4wYajQZnZ+dkHf5LCp1QgxQ6w6BHH4PJRgrd3/TmkzI8PJysWbNib2/P3bt3OXz4MO/evaNo0aJqRxNCCGHA9OIa3blz5/D09OTChQs8e/aMxo0bM3fuXFq1asWePXvUjieEEMKA6UWhmzp1KpUrV8bNzY2dO3eSJk0aTpw4wdChQ/H19VU7nhBCCAOmF4Xuxo0bdO3aFSsrK44fP07FihWxsLCgQoUK3Lt3T+14QgghDJheFLpUqVIRGRlJREQEFy5coHTp0gC8ePECa2trldMJIYQwZHpR6Dw8PPD29mbEiBEYGxtTvnx5/Pz8GDt2LB4eHmrH+yKNRsPq5UtoUrc6lUoXoUXD2mxat0rtWF/t5InjNG/cEI9ihfjpx0osW7LI4HunpZR9evHsKT9XL8fVi+d02s+cOMpvv7agbqWStKr/I/NnehP24YNKKb/e0+BgypUuzrmzZ9SOkmQajYYN69fSuEEdypQsSq3qVZg8cQIhISFqR0sWhvAa6UWhGzlyJGZmZty6dQtvb2+srKzYtm0b5ubmDB48WO14XzRr2iTmzJhMCY8y/D51Fo2atmCx7xx8pk5SO1qSXb1ymR5dO+Pg6MjU6T7UrFmbaVO8WbzQcCfCTSn79PxpMEP7dCH0Xx+UJ48cwmtQLyxTpWaw1yQ69ezPlQvnGNyrIzHRhnd7TfCTJ3Tp2I6Q9+/VjvJVli5eyMTxYyjnWYGpM2bRuk07du7YSr/ePQ3yS9Y/GcprpBe3F6RPnx4fHx+dtj59+mBubq5SooR78/o1m9atpna9hvQbMkLbnjlLVgb37UGd+o3IldtRxYRJM2eWD6758jH+d28Aypb3JCo6mkUL5tGiVWssLS1VTph4hr5PGo2Gg3/sYNHsafF+QK5aPI+cuXIzZsoczMxibzoqUKgo7ZvUYv/ubVSv0/B7R04SjUbDju1bmTZ5IgZeB9BoNCxdvJCGjZrQ87e+AJQqXQbbtGkZ1L8PN25cp0ABN5VTJp6hvUaqHdFt3bqVyMhI7c///m/37t3an/XZo4f3iYmJoaxnRZ32oiVKotFoOHPquDrBvkJkZCTnz52hUuWqOu1Vf6xGaGgoly5eUClZ0qWEfQq468+syeOoVL0W/YaPjbP80YN7FPUooy1yAOnSZyBnrtycPXXse0b9Kv7+txjnNZJadeoxdoLhnhUBCA0JoWbtOvxUs5ZOu8P/v/wGPnqkRqyvZmivkWpHdIMGDaJ8+fJkyJCBQYMGfXI9IyMj6tWr9/2CJZJt2nRA7CH8Pz0OjH0DBwUGfvdMXyvw0SOioqLI5eCg025vnwuA+wEBlC5TVoVkSZcS9ilzFjsWrd1BxsxZ4lybA7CxTcezYN33YXR0FM+fBhMVFfW9Yn41Ozs7duzeT5asWfX6uk9CWNvYMHDwsDjthw8dAMDJKflGf/qeDO01Uq3Q3bx5U/vz+fPnsbKyUivKV7HP5YB74aIs8p1FpsxZKFbCg6DHgUwaNxJzc3PCwg1vCKiQkNjz7f9+TVKnSQNAaKjhXURPCftkbWOLtc2nZ/OoWrMu65YvZMPKJfxYsy4REREsXzCb0NAQLFOl/o5Jv46tbVpS8qQl165eYcmiBXhW/IE8eZ3VjpMkhvYa6UVnlPr16/PXX3+pHSPJxk6aRuEixRnavxfVK5aiZ+d21Kn/Mza2afX+uk98NBrNZ5cbGenF2yZRUuI+/VvLdp35uUVbViycTbPalejQtDapUqemVLmKWBjg+zAlunzpIt06/0q27DkYPWa82nH+M/SiM0pYWJhBFoSP0mfIyISpPrx//44Xz5+RPYc9xsbGTJ7ghc1nvoHrK6v/37sYGhqq0/6xl5+1teEdfafEffo3E1NT2nbpRYt2nQkOCiR9xkxYWdvQv1u7zx4Jiu9j7x+7GTlsMPa5HJg9bwFp/3/ZQ3x7elHoWrduTY8ePWjRogX29vZxil6JEiVUSpYwB/buxsHRiTx5XbC2tgHg5o3rsbMwuOZXOV3i5cxpj4mJCY8ePtBp/zjbe25HJzVifZWUuE//dvXiOaKioijmUQb73LH7ExMdzYO7t6lSo47K6f7bli9dxPSpkyleoiRTps+SgTC+M70odFOnTgVgzJgxcZYZGRnh5+f3vSMlyrJFvjjmycvo8ZO1betWLcfKypoixfS7SMfHwsKCosWKc/DAfn5p21473ceB/XuxtramoJu7ygkTLyXu078dP3yAM8ePsGj9DkxNY3te7tu1lZCQ95Qu/4PK6f67Nq5fy7Qp3vxYvQZjx/+OmZn+3zaV0uhFoTt48KDaEb5Ko6YtmDzeC0envLi5F+bAvj3s/2MX/QaP0J4yMzS/dupCpw5t6d+nF/UaNOTypUssW7KIXr37kiqVYc5HlhL36Z9q1PuZP3ZsZuq4EfxYsx737vizdN4MPCtXw61IcbXj/Se9ePGcKd6/ky17dpo2a4HfjRs6y3PktCd9+vQqpfvv0ItClz17dgA+fPhAQEAAJiYm5M6dO1lmFv8e6jZoTER4BJvWrWLF4gXY53Jg5LhJVK1eU+1oSeZRqjRTpvswd/ZMfuvRjcxZstC73wB+adNO7WhJlhL36Z8cHPMwatJMls7zYfTAXqRLn4EmrTvQpHV7taP9Zx0/dpTw8HCCHj+m3S8t4iwfPWY8deo1UCHZf4tezDAeFRXF+PHj2bRpE1FRUSiKQqpUqWjdujW9e/dOlueQGcaFGmSGccOgBx+DyU5mGP+bXnxSTp06lT/++IMhQ4ZQpEgRNBoNFy9exMfHh1SpUtG5c2e1IwohhDBQelHotm3bxvjx4/nhh78vmOfLl49MmTIxfvx4KXRCCCGSTC/uko2IiMDe3j5Oe548eXj79q0KiYQQQqQUelHo6tWrx4wZM7SDPEPsOfNly5ZRv359FZMJIYQwdHpx6vLNmzf8+eefVKpUCXd3d0xNTblx4waPHz+mUKFCtG7dWrvu8uXLVUwqhBDC0OhFoTM3N6dWLd1pLEqUKKH3I6IIIYTQf3pR6MqWLUv58uWxNaThsIUQQhgEvbhG5+XlxfPnz9WOIYQQIgXSi0Ln4OCAv7+/2jGEEEKkQHpx6tLV1ZV+/fqxcOFCHBwc4gz9NWHCBJWSCSGEMHR6UegCAgIoVqwYgJzCFEIIkaz0YqzL70HGuhRqkLEuDUNK/BiUsS7/pheflEFBQZ9dni1btu+URAghREqjF4WuUqVKn/32oe8TrwohhNBfelHo/j3aSUxMDAEBASxdupRBgwaplEoIIURKoBeFrmTJknHaSpcuTc6cOfHx8aFSpUoqpBJCCJES6MV9dJ/i4ODAzZs31Y4hhBDCgOnFEV18nVFCQkLw9fUlR44cKiQSQgiRUuhFoYuvM4qiKKROnRpvb2+VUgkhhEgJ9KLQxTf1jrGxMa6urlhZWamQSAghREqhFzeMv3v3Dm9vb1q2bEmePHno0KEDp0+fxsHBgfnz55MzZ061IwohhDBQetEZZcKECZw+fRpTU1P279/P+fPnmTRpEg4ODkyaNEnteEIIIQyYXpy6PHLkCLNnz8bJyYkFCxZQtmxZateujYuLCy1atFA7nhBCCAOmF0d0Hz58wM7ODoATJ05QpkwZACwtLYmJiVEzmhBCCAOnF0d0Tk5OHD58GDs7O54/f46npycA69evx8nJSeV0QgghDJleFLqePXvSo0cPoqKiqFWrFg4ODkyYMIFVq1Yxe/ZsteMJIYQwYHrR6xLg9evXPH36FFdXVwCuXr1KmjRp5IhOCCHEV9GbQieEEEJ8C3rRGUUIIYT4VqTQCSGESNGk0AkhhEjRpNAJIYRI0aTQCSGESNGk0AkhhEjRpNClYC4uLmzevBkfHx8qVaqkdhytqKgoli5dmqzbvHbtGj/99BMFCxZk4sSJybrtb+Xj6yO+TFEUtmzZwsuXL79qO61atWLQoEHJlOrbMISMn/Ot39ebN2/GxcUlUY+RQvcf0K5dOzZu3Kh2DK2dO3cyYcKEZN2mr68vZmZm7N69m44dOybrtoX6zp07x6BBgwgLC1M7iviC48ePU6NGDbVj6NCLIcDEt5UmTRrSpEmjdgytbzFGwdu3b8mXLx/29vbJvm2hPhnXwnBkypRJ7QhxyBHdP/j7+9OpUydKlChBwYIFqVy5MosXLwbAx8eHNm3aMH/+fDw9PXFzc6Nly5bcvXtX+/hXr17Ru3dvihcvjoeHB5MnT6Z169b4+Phot9GyZUt69+5N0aJFGTlyJKVLl2bWrFk6OdauXUu5cuWIjo5OcPbg4GC6dOlCkSJF8PT0ZMeOHdpl/z51uXXrVmrWrImbmxvly5dn3LhxREZGapcfP36c+vXr4+bmRq1atdi0aRMuLi4EBgYCUKlSJe0+ffTPtpiYGLy9valQoQIFCxakevXqrFmzBog97TB48GAg9hTHmTNnEryPn1KpUiXOnj3L1q1bcXFx4dGjRyxYsIDKlStTqFAh6taty/bt23Uec+DAAX7++WcKFy6Mm5sbDRo04NixY9rlrVq1Yvjw4fz8888UL148zuOTS0BAAG3atNG+Fr6+vtplGo0GX19fqlWrRsGCBSlatCgdOnTg4cOH2nVcXFxYtWoVjRs3xs3Njdq1a3Pw4EHtch8fH5o1a8bs2bPx8PCgePHiDB48mJCQEADGjx9PlSpVdDK9f/8ed3d3Dh8+nKB9cHFxYePGjbRp0wZ3d3fKlSsX5z39559/0qBBA9zd3alatSrTp0/Xec/Fd7rrY9uZM2do3bo1AJUrV2bz5s1s3ryZqlWrMnbsWIoVK0bXrl2BL7+u38KRI0do0KABhQoVonTp0gwaNIi3b98mKE9kZCTjx4+ndOnSFCtWDG9vbzQaTbLmOHPmjM7fLxCnLb73+6BBg+jTpw9eXl4ULVqU0qVL8/vvv2tft8DAQFxcXPD19aVs2bJUrlyZkJAQndfy5cuX9OzZEw8PD9zd3WnatClnz57V2X9vb2/Kly9PkSJFaNy4McePH9fZr/3791O7dm3c3Nxo3rw5QUFBif/lKEJRFEX58OGDUrZsWWXAgAHKnTt3lICAAGXSpEmKs7OzcuPGDWXmzJlKgQIFlI4dOyp+fn7K1atXlerVqyutWrVSFEVRYmJilEaNGin169dXLl26pFy/fl1p0aKF4uLiosycOVNRFEWZOXOm4uzsrIwdO1Z5+PChEhAQoIwfP16pWrWqTpYmTZooEydOTHD2qKgopWbNmkqTJk2U69evKxcvXlTq1q2rODs7K5s2bVJmzpyp/PDDD4qiKIqfn59SoEABZc+ePcrjx4+Vo0ePKiVKlFBmz56tKIqi3LhxQ8mfP78yceJE5e7du8rOnTuVEiVKKM7OzsqjR48URVGUH374QbtPH/2zbfny5UqlSpWUCxcuKIGBgcqKFSsUZ2dn5dy5c0pYWJiydOlSxdnZWXn27JkSERGRhFdL18uXL5UmTZoovXr1Up49e6ZMnjxZ+eGHH5Q///xTefDggbJx40alSJEiysqVKxVFUZRr164prq6uypIlS5SHDx8qN27cUNq3b6+UKlVKm6dly5aKi4uLsn37duXWrVvKq1evvjrnvzk7OyuFCxdWtmzZojx8+FCZPXu24uzsrJw8eVJRFEVZsmSJUqJECeXQoUNKYGCgcvLkSaVy5cpKly5d4mxj5cqVyt27dxVvb2/F1dVVuXDhgqIoivZ927RpU+X69evK6dOnlcqVKyvt27dXFCX2/fDxtflo7dq1StmyZZXo6OgE70fx4sWVrVu3Kg8fPlTmzp2rODs7K2fPnlUURVGOHDmiuLu7K2vWrFEePHigHDt2TPnxxx+Vnj176mxj06ZNcba7adMmJSIiQtm7d6/i7OysXLlyRQkLC1M2bdqkODs7Kz169FAePnyo+Pv7J/h1HThwYGJfqk96+fKlUrBgQWXlypVKYGCgcv78eaVSpUrKkCFDEpRn+PDhStmyZZXDhw8r/v7+Sp8+fRRnZ+dEZ/xcjtOnT+v8/SqKEqctvvf7wIEDlQIFCijdunVTbt26pRw4cEDx8PBQRowYoSiKojx69EhxdnZWqlWrpty+fVu5evWqoii6r2X37t2Vjh07Kv7+/sr9+/eVQYMGKcWKFVNCQ0MVRVGUPn36KHXr1lVOnz6tBAQEKIsXL1YKFCig/Pnnn4qiKMqFCxcUFxcXxcfHR7l3756yfv16xc3NTXF2dk7U70cK3f+9fPlS8fX1VUJCQrRt4eHhirOzs7JlyxZl5syZiouLi/LmzRvt8qVLlyoFChRQFEVRTp06pTg7Oyt3797VLn/+/Lni5uYWp9C9e/dOu86tW7cUZ2dn5eLFi4qiKMq9e/cUZ2dn5fbt2wnOfvToUcXZ2Vl58OCBtu3GjRvxFrr9+/crBQsW1L4pFUVRrl69qty7d09RFEUZMGCA0rhxY53tL1u2LFGFbuzYsUqtWrWUp0+fapefOHFCefHihaIoivZDKjl9/AALDQ1V3NzclP379+ssnzFjhvZ3cOPGDWXVqlU6y48cOaI4OzsrQUFB2u3Vq1cvWTP+m7OzszJp0iSdtmLFiinz589XFEVRDh48qBw6dEhnube3t1K5cmWdbXh5eems8/PPPyu9e/dWFCX2PVewYEElODhYu/zjvn58r9avX18ZPny4dnliv2h9/PL2T8WLF1fmzZunKIqiNGvWLM7yj38vH99Tnyt0ihL3g/nje8jPz0+7fkJf1+QsdB//zv75Ovn7+yt+fn5fzPP+/XulQIECyvr167XLw8PDlTJlyiQ64+dyJLTQ/fv9PnDgQKV06dLKhw8ftG2rV69WChQooLx//15b6JYtW6bzuH++bnXq1FH69eunhIWFKYqiKO/fv1dOnDihhIeHK/fv39ceSPzTgAEDlJYtWyqKoii9e/dWmjVrprN87Nixif78kGt0/5c+fXqaN2/Ozp07uXHjBg8fPuTmzZsA2lMJGTNmxNbWVvsYa2troqKiALhx4wa2trY4Ojpql2fMmJHcuXPrPE+GDBmwtrbW/tvZ2Rk3Nze2bt1KkSJF2Lp1K+7u7uTJkyfB2f39/bG1tdW5PpUvXz4sLS3jrPvxFEGjRo3IkSOH9pRDwYIFtfvxceLbj0qUKJHgLAAtWrTgwIEDVKhQgXz58lG2bFlq1qxJhgwZErWdpLhz5w4RERH07dsXY+O/z8xHR0cTGRlJeHg4+fLlw9bWlvnz53Pv3j0ePHigfa3/OdFvrly5vnleBwcHnX/b2NgQEREBxJ6SvXLlCjNmzCAgIICAgADu3LlDlixZdB7j4eGh8+8iRYpw4sQJnef452OKFi0KxL5vHB0dadiwIdOnT2fYsGE8efKES5cuMW7cuETtx79nGfn338bVq1d1OkQp/7/mdvfuXXLkyJGo5/qnf/7+Evq6Jqd8+fJRq1YtOnfuTKZMmShbtiwVK1akatWqmJqafjZPQEAAUVFRuLm5abdnYWFB/vz5kzXHhQsXErSN+N7v7u7upEqVSvvvIkWKEBUVRUBAAOnSpfvk4z7q3r07/fv3Z+/evRQrVoxy5cpRq1YtLCwsuHHjBgDNmzfXeUxUVBQ2NjZA7Hu0bNmyOsuLFCnC8uXLE7RPH0mh+7/nz5/TpEkT0qdPT6VKlShXrhxubm5UqFBBu465ufknH29iYpKgc+vxFZ+GDRsybdo0hg4dyo4dO+jQoUOishsZGcX73KamcV9eCwsLli9fzo0bNzh+/DjHjx+nc+fO1KtXjwkTJiR4P/7tn9cTHRwc2LdvH2fPnuXEiRMcPnyYBQsWMGHCBOrXr5/obSfGxw/Q6dOn63zp+Mjc3JyzZ8/Svn17KlasSLFixahduzZhYWF069ZNZ934XqvkZmJiEqft4z7Mnz+f2bNnU79+fUqXLk2bNm04ePAgu3bt0ln/369zTEyMTpE3MzOLs/yfz127dm0mTpzIn3/+ib+/P+7u7omeHiu+v42P+6HRaOjQoUO8r/2nOi4k9Pr0P1+jhL6uyW3KlCl069aNo0ePcvLkSfr370+xYsXo1q3bZ/MYGRkBcTvaxPd3+zU5Pl6//Kf4Cn987/d/v3c+fjb88337ub+TqlWrcuzYMY4dO8bJkydZsmQJs2bNYv369dr9XrVqVZzOch/fv/F9tv07U0JIZ5T/27lzJ2/evGHNmjV07dqVqlWrai8o//uNGB9XV1fev3+v0znl9evXPHjw4IuPrVWrFhERESxZsoQXL15Qq1atRGXPly8f79+/5/bt29q2+/fvazsc/NORI0eYNWsW+fPnp2PHjixfvpyePXuye/du7X5cvXpV5zGXLl3S+beZmZnOtkNCQnTub1q+fDn79u2jbNmyDBgwgB07dlC6dGntc3z8A/8WHB0dMTU1JSgoiFy5cmn/O3LkCIsWLcLY2JjFixfj4eGh7WBUtmxZnjx5AuhX77558+bRrVs3Ro0aRZMmTShcuDD379+Pk/HatWs6/7506RIFChTQ/jsgIID379/rLAe0Rw42NjZUrVqV/fv3s3fvXho0aJCs+5E3b14CAgJ0Xo/g4GAmTZpEaGgoEPc99e+/m4S8Z9R4Xa9cucL48eNxdHTUdlYbP348p0+fZsGCBZ/Nkzt3biwsLLh48aJ2e9HR0dqjvuTK8bFo/PP3e//+/QRt96+//tIpipcuXSJVqlRxzlTFJzIykgkTJvDo0SNq1KjB2LFjOXDgAMbGxhw+fJi8efMCsQcZ/3xvfOxsBLGfR//+/Ll+/XqCsv+TFLr/y5o1K2FhYfzxxx8EBQVx/Phx+vTpA6DTO+xTPDw8KFSoEAMGDODy5cvcvHmTfv36ERYW9sU/Umtra6pWrcqcOXOoXLmy9rA9of793NeuXWPAgAE63+o/MjMzY/bs2SxdupRHjx5x/fp1Dh8+TJEiRYDYe+6uXbvG5MmTCQgIYP/+/cycORP4+8OmcOHC7N69m4sXL3Lnzh2GDBmi8w3v1atXeHl5cfDgQR4/fsyxY8fw8/PTPkfq1KmB2DdseHh4ovb1S6ytrWnatCkzZsxg27ZtPHr0iI0bN+Lt7U3mzJkBsLOz49atW5w/f57AwEA2bdrEjBkzgIS91t+LnZ0dJ06c4M6dO9y7d49p06axb9++OBmXLVvGjh07CAgIYOLEidy6dYtffvlFu/zDhw8MGDAAf39/Tp48iZeXFzVq1CB79uzadRo2bMj+/ft5+PAhNWvWTNb9+PXXX9m7dy+zZs0iICCAU6dOMXjwYN6/f689oitcuDAbNmzAz8+PGzduMGrUKJ2jxI/vmZs3b2qL47+p8bpaWVmxevVqvL29efDgAf7+/uzevRsHBweyZcv22Txp0qShZcuWzJw5k3379nH37l1GjhzJ06dPkzWHq6srqVOnZv78+Tx8+JBjx46xZMmSBG338ePHjB49mrt377Jv3z5mzpxJy5YtdU5nfoq5uTnXrl1j+PDhXL58mcDAQDZv3syHDx8oUqQIefPm5YcffmDkyJEcOnRI21va19dXexmmXbt23Lx5k4kTJxIQEMD27dtZuXJlon8/cury/6pXr85ff/3F77//TkhICNmzZ+fnn3/m4MGDXLt2DTs7uy9uw8fHBy8vL9q0aYOFhQXNmzfn3r17CTrUbtCgATt27EjSt2ljY2N8fX0ZO3Ys7dq1w9LSkk6dOvH48eM465YpU4Zx48axePFipk2bhqWlJRUqVNCOxODs7MysWbOYOnUqS5cuJXfu3LRs2RIfHx/tfvTp04c3b97Qtm1brK2tadeuHe/evdM+R/fu3YmKimLs2LE8f/6cTJky0axZMzp16gRAqVKlKFSoEE2bNsXb25uffvop0fv8OYMHDyZdunTMmDGDZ8+eYWdnR8+ePbWnhHv27MmLFy/o3LkzAHny5GH8+PH079+fa9eu6c2s9pMmTcLLy4uGDRuSJk0aChUqxOjRoxk1ahRBQUFky5YNgKZNm7J06VL8/f1xdXVl0aJFuLq6ardjZ2dHvnz5aNGiBSYmJtSuXZt+/frpPFfp0qVJly4dRYsWTfQXrS+pXr0606ZNw9fXl3nz5pE2bVoqVaqkk2HUqFGMGjWKxo0bkzlzZnr16kVwcLB2ubOzMxUqVOC3336jT58+pE2bNs7zqPG6Ojk54ePjw6xZs1i9ejXGxsaUKlWKBQsWYG1tzatXrz6bp2/fvlhYWODl5UVoaCg//fRTkkYx+lIOb29vJk+eTI0aNXB1dWXgwIEJOqVbuHBhjI2NadSoEdbW1rRu3ZouXbokONe0adOYMGECXbp04f379zg6OjJ58mSKFy+uXT5t2jRGjBjB27dvsbe3Z9y4cdrT3Pny5WPBggV4e3uzcuVK8ubNS+fOnZk8eXLifkGJ6roiPunly5fKoUOHlMjISG1bRESEtvv4l2zatEmpWLGiEhMT8w1TftmVK1eUv/76S6dt+/btSsGCBZWoqCiVUolPia+34j/9s8ft54SEhCiFCxdWTpw4kZzxhAEbOHCgtvejoZMjumRiampK7969adq0Kc2aNSMqKopFixZhbm6Op6fnJx/3119/ce/ePe0pgfhON35Pfn5+eHt7M3HiRPLly8eDBw/w8fGhZs2aSb5ILvTX27dvOX36NHv27CF79uyULl1a7UhCJDv55EomNjY2zJs3j+nTp7Nu3TqMjY0pWrQoy5cvJ3369J983OXLl5k0aRIVK1bUua6ilsaNG/P8+XPGjx/P06dPyZAhAzVr1qRnz55qRxPfQExMDEOHDiV9+vRMnz79m3YUEkItRoqiR93MhBBCiGQmvS6FEEKkaFLohBBCpGhS6IQQQqRoUuiEMDByWV2IxJFCJ/5TWrVqhYuLi85/BQsWpGLFiowePVo77Nu3sHnzZp05wHx8fHBxcUnw44ODg+nYsWO8AwEk1se5xP49B9w/tWrVilatWiVqu0l5THz+/bsS4mvI7QXiPyd//vyMHDlS+++oqCj++usvpk6dip+fH2vWrPku3ex//vlnypcvn+D1T548yZEjR75hIiFSJil04j/HysqKwoUL67SVKFGC0NBQZs6cyZUrV+Is/xayZs1K1qxZv/nzCPFfJ6cuhfi/j3PyBQUFAbGn4fr160fPnj0pXLgwbdu2BSAiIoJJkyZRoUIFChYsSO3atbUzM3yk0WiYM2cOFStWpFChQnTt2jXOadH4Tl1u3bqV+vXrU6hQISpWrMiUKVOIjIxk8+bNDB48GIDKlStrxyYF2LBhAzVr1tSegvXx8YkzDcu+ffuoU6cO7u7u1K9fP0kj5L969YrRo0fzww8/ULBgQUqWLEm3bt3iPb04e/ZsypQpQ5EiRejatSuPHj3SWe7v70+nTp0oWrQoRYsWpVu3bnHWESK5yBGdEP8XEBAAQM6cObVte/bsoU6dOsydOxeNRoOiKHTr1o2LFy/Ss2dPnJyc2L9/P7179yYyMpJ69eoB4O3tzfLly+nSpQuFChViz549TJky5bPPv2rVKry8vPj555/p06cPjx49YtKkSbx9+5bffvuNLl26MHfuXGbNmqUtkL6+vkybNo2WLVsyePBg/Pz88PHx4cmTJ4wfPx6AQ4cO0bNnT2rXrk3//v3x8/Ojf//+ifrdKIpCp06dePv2Lf369SNjxozcunWL6dOnM3LkSBYtWqRd98KFC7x8+ZIRI0YQExPDlClTaN26NTt27MDKyoqAgACaNm2Ko6MjEydOJDo6mrlz59KsWTO2bdv2XSboFf8tUujEf46iKDoTe759+5azZ88yd+5cihQpoj2yg9hpjUaPHq2dMubEiRMcO3aMadOmUaNGDSB21vawsDAmT55MrVq1+PDhAytWrKBt27Z0795du86zZ884duxYvJk0Gg2zZ8+mSpUqjB07VtseFhbGrl27sLa21k5dki9fPnLkyMH79++ZM2cOTZo0YdiwYQCUK1eOtGnTMmzYMNq2bUvevHmZPXs27u7ueHt7a7MAXyy8//Ts2TNSpUrFwIEDtSPPe3h48PB/7d1BSJN/HMfxt1psToeKi1UkxQRxlMXEnA1quOzQJYIOFRoRyylTKYTaIYjaoVOuNhTKrFQw2K08hGQUXTKwJQl1qGgURpgtJ4UE2p7/YfjQw2b/7Q//y/q+wMOe3+95/D6Ph4/7Pc/2/fiRcDismVtQUMCtW7fUZVmLxcLBgwe5e/cuLS0t9Pb2UlhYyODgIMXFxUCye0JTUxMDAwP4fL6M6xIiExJ04q8zOTmpaUwKyVZHDocDv9+veRDFYrFo+qJNTEyQl5eH0+nUhKXL5WJ0dJS3b98yNzfH0tISjY2Nmt+xf//+VYMuGo0Si8XYt2+fZrvb7cbtdqfdZ2pqip8/f+JyuVJqgWQoV1RU8OrVK06dOpVSSzZBZzabGR4eRlEUZmZm+PDhA+/fv+fFixcpvd5qa2s19x6tVisVFRVMTk7S0tLCs2fPqK+vR6/Xq3UXFxdTV1fH06dPM65JiExJ0Im/ztatW7l48SKQbCar0+nYsGGD+u7id0VFRZrX8XgcRVGora1Ne+wvX76ovfnKyso0YytNRtOJx+MAWS3brezj8XhWrWVhYQFFUVJqWWlCm43R0VECgQCfP3+mtLQUq9WKXq9PmWcymVK2lZeXq9clHo9z//79lPuawB+/AF2I/0qCTvx1ioqKqKmp+U/7Go1GDAYDw8PDacc3b97M9PQ0ALFYDIvFoo6tBFM6K81Ov337ptk+Pz/P69ev1e7s6fa5fPkyW7ZsSRk3mUyUlpaSn5/P169fNWN/qiWd58+f4/P5OHbsGG63G7PZDCSbw0YiEc3cdJ9FnJubU8/BaDTicDjUh3t+J62gxP9BnroUIgv19fUsLi6iKAo1NTXqz5s3b+jr62N5eRmbzYZer2dsbEyz7+PHj1c9rsVioaysLGXOvXv38Hg8LC0tpfQq3LFjB2vXrmV2dlZTy5o1awgEAszMzKDT6bDZbDx48EDzjSqPHj3K6rynpqZIJBJ0dXWpIffr1y91qTGRSKhzI5EI379/V1+/fPmST58+0dDQACSv4bt377BarWrN27ZtY3BwkPHx8azqEiIT8u+TEFlwOp3s3LkTr9eL1+ulsrKS6elpQqEQu3fvVpfevF4vV69epbCwkIaGBp48efLHoCsoKKCrqwu/3095eTkul4toNEooFKK5uZmSkhL1Hdz4+Dh79uyhsrKSkydPEgwG+fHjB3a7ndnZWYLBIHl5eVRXVwPQ3d3N8ePH6ezs5PDhw0SjUa5du5bVeW/fvh0Av9/PoUOHWFhYYGRkRP2YwuLiorr0m0gk8Hg8tLe3Mz8/T09PD1VVVRw4cEC9NkeOHKGtrY2jR4+i0+kIh8M8fPiQUCiUVV1CZEKCTogs5Ofn09/fTzAY5Pr168RiMcxmMydOnKCjo0Od19bWhsFgYGhoiKGhIWw2Gz6fjwsXLqx67ObmZgwGAzdv3iQcDrN+/XpaW1tpbW0Fkk85OhwOenp6mJiYoL+/n9OnT7Nu3Tru3LnDwMAAJSUl7Nq1i+7uboxGIwB1dXXcuHGDQCBAZ2cnmzZt4tKlS7S3t2d83na7nfPnz3P79m3GxsYwmUzY7XZ6e3vp6OggEongdDoBaGpqYuPGjZw5c4bl5WUaGxs5d+4cOp0OgOrqakZGRrhy5Qpnz55FURSqqqro6+tj79692f5JhPhX0nhVCCFETpN7dEIIIXKaBJ0QQoicJkEnhBAip0nQCSGEyGkSdEIIIXKaBJ0QQoicJkEnhBAip0nQCSGEyGkSdEIIIXKaBJ0QQoicJkEnhBAip0nQCSGEyGn/AJODuMhY39rQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(test_generator)\n",
    "y_predicted = np.argmax(predictions, axis=1)\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "mat = confusion_matrix(true_labels, y_predicted)\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False, cmap='Blues',\n",
    "            xticklabels=emotions,\n",
    "            yticklabels=emotions)\n",
    "\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('Actual label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5dabc6",
   "metadata": {},
   "source": [
    "### VGGISH transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea852b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4213 images belonging to 7 classes.\n",
      "Found 902 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image data generator for training data\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(96, 64),\n",
    "    batch_size=10,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "# Image data generator for validation data\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(96, 64),\n",
    "    batch_size=10,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "913487cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vggish_model(input_shape, weights_path=None):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # VGGish Convolutional Blocks\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), strides=(1, 1), activation='relu', padding='same', name='conv1')(input_layer)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool1')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), strides=(1, 1), activation='relu', padding='same', name='conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool2')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='same', name='conv3/conv3_1')(x)\n",
    "    x = Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='same', name='conv3/conv3_2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool3')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), strides=(1, 1), activation='relu', padding='same', name='conv4/conv4_1')(x)\n",
    "    x = Conv2D(512, (3, 3), strides=(1, 1), activation='relu', padding='same', name='conv4/conv4_2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool4')(x)\n",
    "\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=x, name='vggish')\n",
    "\n",
    "    # Load pre-trained weights (if available)\n",
    "    if weights_path is not None:\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9d94ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "445b2fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_custom_model(input_shape, num_classes, weights_path=None):\n",
    "    # Build the VGGish model\n",
    "    vggish_model = build_vggish_model(input_shape, weights_path)\n",
    "\n",
    "    # Add your dense layers\n",
    "    x = Flatten()(vggish_model.output)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "\n",
    "    # Add the output dense layer for classification (number of classes)\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create the custom model with VGGish base and your dense layers\n",
    "    custom_model = Model(inputs=vggish_model.input, outputs=output_layer)\n",
    "\n",
    "    return custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cb1462cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# def preprocess_image(image):\n",
    "#     # Convert image to grayscale\n",
    "#     gray_image = np.mean(image, axis=-1, keepdims=True)\n",
    "\n",
    "#     # Resize image to (96, 64)\n",
    "#     resized_image = cv2.resize(gray_image, (64, 96), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "#     # Expand dimensions to match the input shape of VGGish\n",
    "#     preprocessed_image = np.expand_dims(resized_image, axis=-1)\n",
    "\n",
    "#     return preprocessed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d02bf1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomImageDataGenerator(ImageDataGenerator):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super(CustomImageDataGenerator, self).__init__(*args, **kwargs)\n",
    "\n",
    "#     def preprocess_func(self, image):\n",
    "#         return preprocess_image(image, target_size=(96, 64))\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         x, y = super(CustomImageDataGenerator, self).__getitem__(index)\n",
    "#         x = self.preprocess_func(x)\n",
    "#         return x, y\n",
    "\n",
    "# # Image data generator for training data with custom preprocessing\n",
    "# train_datagen_custom = CustomImageDataGenerator(rescale=1.0/255.0)\n",
    "# train_generator_custom = train_datagen_custom.flow_from_directory(\n",
    "#     train_dir,\n",
    "#     target_size=(224, 224),\n",
    "#     batch_size=32,\n",
    "#     class_mode='categorical'\n",
    "# )\n",
    "\n",
    "# # Image data generator for validation data with custom preprocessing\n",
    "# val_datagen_custom = CustomImageDataGenerator(rescale=1.0/255.0)\n",
    "# val_generator_custom = val_datagen_custom.flow_from_directory(\n",
    "#     val_dir,\n",
    "#     target_size=(224, 224),\n",
    "#     batch_size=32,\n",
    "#     class_mode='categorical'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19b2cff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Image Shape: (96, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "# Manually load an image from the train generator\n",
    "batch_X, batch_y = next(train_generator)\n",
    "sample_image = batch_X[0]  # Take the first image from the batch\n",
    "\n",
    "# Check the shape of the sample image\n",
    "print(\"Sample Image Shape:\", sample_image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddeb1b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape for spectrogram images (224, 224, 3)\n",
    "input_shape = (96, 64, 1) #(224, 224, 3)\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "# Path to the downloaded pre-trained VGGish weights\n",
    "vggish_weights_path = 'vggish_audioset_weights_without_fc2.h5'\n",
    "\n",
    "# Build the custom model with VGGish base and dense layers for classification\n",
    "custom_model = build_custom_model(input_shape, num_classes, weights_path=vggish_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "425c61f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vggish\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 96, 64, 1)]       0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 96, 64, 64)        640       \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 48, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 48, 32, 128)       73856     \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 24, 16, 128)       0         \n",
      "                                                                 \n",
      " conv3/conv3_1 (Conv2D)      (None, 24, 16, 256)       295168    \n",
      "                                                                 \n",
      " conv3/conv3_2 (Conv2D)      (None, 24, 16, 256)       590080    \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 12, 8, 256)        0         \n",
      "                                                                 \n",
      " conv4/conv4_1 (Conv2D)      (None, 12, 8, 512)        1180160   \n",
      "                                                                 \n",
      " conv4/conv4_2 (Conv2D)      (None, 12, 8, 512)        2359808   \n",
      "                                                                 \n",
      " pool4 (MaxPooling2D)        (None, 6, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4499712 (17.17 MB)\n",
      "Trainable params: 4499712 (17.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "chch = build_vggish_model(input_shape, weights_path=None)\n",
    "chch.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e5e3a7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_39 (InputLayer)       [(None, 96, 64, 1)]       0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 96, 64, 64)        640       \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 48, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 48, 32, 128)       73856     \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 24, 16, 128)       0         \n",
      "                                                                 \n",
      " conv3/conv3_1 (Conv2D)      (None, 24, 16, 256)       295168    \n",
      "                                                                 \n",
      " conv3/conv3_2 (Conv2D)      (None, 24, 16, 256)       590080    \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 12, 8, 256)        0         \n",
      "                                                                 \n",
      " conv4/conv4_1 (Conv2D)      (None, 12, 8, 512)        1180160   \n",
      "                                                                 \n",
      " conv4/conv4_2 (Conv2D)      (None, 12, 8, 512)        2359808   \n",
      "                                                                 \n",
      " pool4 (MaxPooling2D)        (None, 6, 4, 512)         0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 12288)             0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 512)               6291968   \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10924807 (41.67 MB)\n",
      "Trainable params: 10924807 (41.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model is using pre-trained weights.\n"
     ]
    }
   ],
   "source": [
    "custom_model.summary()\n",
    "\n",
    "# Get the weights of the model\n",
    "weights = custom_model.get_weights()\n",
    "\n",
    "# Check if the weights are not empty\n",
    "if len(weights) > 0:\n",
    "    print(\"Model is using pre-trained weights.\")\n",
    "else:\n",
    "    print(\"Model is NOT using pre-trained weights.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "164a0416",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    create_early_stopping_callback(),\n",
    "    create_model_checkpoint_callback(\"transferLearning_vggish_melspec.h5\"),\n",
    "    create_reduce_lr_callback()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e933ce76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/421 [======>.......................] - ETA: 19:55 - loss: 1.8299 - accuracy: 0.2135"
     ]
    }
   ],
   "source": [
    "custom_model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "custom_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    callbacks=callbacks,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60887ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.save('saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d249a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate_generator(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
